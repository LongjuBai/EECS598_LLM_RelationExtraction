{"micro_pc": 0.07482993197278912, "macro_pc": 0.07482993197278912, "pc_list": {"used for": 0.07482993197278912}, "micro_rc": 0.0825515947467167, "macro_rc": 0.0825515947467167, "rc_list": {"used for": 0.0825515947467167}, "micro_f1": 0.07850133809099019, "macro_f1": 0.07850133809099019, "f1_list": {"used for": 0.07850133809099019}, "num_cases": 551, "accuracy": 0.27223230490018147, "correct_cases": {"0": {"text": "Experimental results are encouraging.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "1": {"text": "We call these misunderstandings miscommunication.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "2": {"text": "The analyzer is called \"Amorph\".", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "4": {"text": "Preliminary modeling and recognition results are presented.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "5": {"text": "Another problem with determiners is their inherent ambiguity.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "6": {"text": "A unique form of reg-ularization is also needed.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "7": {"text": "The results showed the advantages of our method.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "9": {"text": "Turkish has finite-state but nevertheless rather complex morphotactics.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "10": {"text": "We have implemented a restricted domain parser called Plume.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "11": {"text": "Each part is a collection of salient image features.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "12": {"text": "This raises questions about the validity of such approaches.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "13": {"text": "Extension to affine projection enables reconstruction without estimating cameras.", "true": [["affine projection:method", "used for", "reconstruction:task"]], "pred": [["affine projection:method", "used for", "reconstruction:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "14": {"text": "Basic methodology and practical techniques are reported in detail.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "16": {"text": "Basically, there is no exact rule for classifier selection.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "19": {"text": "The classifiers show little gain from information about meeting context.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "24": {"text": "We briefly investigate the weak equivalence of the two formalisms.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "25": {"text": "Unconstrained MPS grammars, unfortunately, are not computationally safe.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "28": {"text": "The result theoretically justifies the effectiveness of features in robust PCA.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "30": {"text": "Such mistakes can slow, and possibly break down, communication.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "31": {"text": "This paper examines the benefits of system combination for unsupervised WSD.", "true": [["system combination:method", "used for", "unsupervised WSD:task"]], "pred": [["system combination:method", "used for", "unsupervised WSD:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "33": {"text": "Manual acquisition of semantic constraints in broad domains is very expensive.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "35": {"text": "These dependencies are not naturally captured by the typical Dirichlet-multinomial formulation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "43": {"text": "We discuss how these might be satisfied by future Natural Language systems.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "45": {"text": "Reflections in image sequences consist of several layers superimposed over each other.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "46": {"text": "Our goal is to recognize and isolate such miscommunications and circumvent them.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "48": {"text": "We give two estimates, a lower one and a higher one.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "52": {"text": "Thus we believe researchers working with novel features should consider trying MLPs.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "53": {"text": "Amorph recognizes NE items in two stages: dictionary lookup and rule application.", "true": [["Amorph:method", "used for", "NE items:other scientific term"]], "pred": [["Amorph:method", "used for", "NE items:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "59": {"text": "We report the performance of the MBR decoders on a Chinese-to-English translation task.", "true": [["MBR decoders:method", "used for", "Chinese-to-English translation task:task"]], "pred": [["MBR decoders:method", "used for", "Chinese-to-English translation task:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "60": {"text": "Even more illuminating was the factors on which the assessors made their decisions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "62": {"text": "Both learners perform well, yielding similar success rates of approx 90%.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "65": {"text": "However, they provide no guarantee of being more efficient than exhaustive search.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "74": {"text": "The signals are assumed to be piecewise stationary with varying variances in different epochs.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "75": {"text": "In this paper, events are defined as event terms and associated event elements.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "76": {"text": "Unlike standard regression problems, the loss is inversely proportional to the regressed-to values.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "78": {"text": "Subjects were given a set of up to six extracts of translated newswire text.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "79": {"text": "Some of the extracts were expert human translations, others were machine translation outputs.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "80": {"text": "We demonstrate the bound on synthetic data for which the ground truth is known.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "87": {"text": "We then turn to a discussion comparing the linguistic expressiveness of the two formalisms.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "95": {"text": "Surprisingly enough, similar scores are obtained in many cases regardless of the quality.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "98": {"text": "The results indicate that there is a mismatch between the expression and perception of emotion.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "101": {"text": "A prototype chip has been designed and fabricated in a 0.5 \u00b5m standard CMOS process.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "103": {"text": "Additionally, they were asked to mark the word at which they made this decision.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "105": {"text": "To improve topical blog post retrieval we incorporate textual credibility indicators in the retrieval process.", "true": [["textual credibility indicators:other scientific term", "used for", "topical blog post retrieval:task"]], "pred": [["textual credibility indicators:other scientific term", "used for", "topical blog post retrieval:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "106": {"text": "The bound depends only on the observable matrices in M' and the noise level.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "109": {"text": "Our experimental results show that the scheme is stable, reproducible and intuitive to use.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "112": {"text": "A purely functional implementation of LR-parsers is given, together with a simple correctness proof.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "113": {"text": "The linguistic structure consists of segments of the discourse into which the utterances naturally aggregate.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "121": {"text": "Objects are represented as a coherent ensemble of parts that are consistent under 3D viewpoint transformations.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "123": {"text": "The analysis is based on the hypothesis that people are better decoders of their own emotions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "125": {"text": "Computing power per area and power consumption is amongst the highest reported for a single chip.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "134": {"text": "We examine the relationship between the two grammatical formalisms: Tree Adjoining Grammars and Head Grammars.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "137": {"text": "These parameters are then quantized into a small number of values without altering the writing intelligibility.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "140": {"text": "Almost all the special cases of and exceptions to phonological and morphological rules have been implemented.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "141": {"text": "Existing work in the area has mostly addressed scenes that consist of static or quasi-static structures.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "146": {"text": "In this paper, we explore what can be said about transparent objects by a moving observer.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "147": {"text": "We show promising results in both the detection and viewpoint classification tasks on these two challenging datasets.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "148": {"text": "The fact that Turkish is an agglutinating free word order language presents a challenge for language theories.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "150": {"text": "Thus the resulting detectors are not robust and highly depend on the choice of the training examples.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "159": {"text": "In this paper, we study the problem of online action detection from the streaming skeleton data.", "true": [["streaming skeleton data:material", "used for", "online action detection:task"]], "pred": [["streaming skeleton data:material", "used for", "online action detection:task"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "160": {"text": "MINPRAN's properties are connrmed experimentally on synthetic data and compare favorably to least median of squares.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "161": {"text": "We evaluate several proposals for constraining them, basing our assessment on computational tractability and explanatory adequacy.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "167": {"text": "Thus, the limitations of the automatic metrics used within MT are also discussed in this regard.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "168": {"text": "In this paper, we propose a new method for the modeling and subtraction of such scenes.", "true": [["method:generic", "used for", "modeling and subtraction of such scenes:task"]], "pred": [["method:generic", "used for", "modeling and subtraction of such scenes:task"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "171": {"text": "We integrate a spoken language understanding system with intelligent mobile agents that mediate between users and information sources.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "174": {"text": "We argue that it is necessary to draw a line between generalizable semantic principles and domain-specific semantic information.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "175": {"text": "This has the advantages of efficiency on grammatical input, and robustness in the face of ungrammatical input.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "176": {"text": "The objects can be complex in that they may be composed of multiple layers with different refractive indices.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "188": {"text": "The attentional state is an abstraction of the focus of attention of the participants as the discourse unfolds.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "193": {"text": "We extensively experiment on two recent large and challenging multi-view datasets and we achieve better than the state-of-the-art.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "194": {"text": "Person re-identification is challenging due to the large variations of pose, illumination, occlusion and camera view.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "197": {"text": "Given a single image, it is difficult to even detect the presence of transparent objects in the scene.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "208": {"text": "Using this approach, we extract parallel data from large Chinese, Arabic, and English non-parallel newspaper corpora.", "true": [["approach:generic", "used for", "parallel data:material"]], "pred": [["approach:generic", "used for", "parallel data:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"\n"}, "218": {"text": "We examine a broad range of texts to show how the distribution of demonstrative forms and functions is genre dependent.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "221": {"text": "We provide an efficient and simple regularized Empirical Risk Minimization -LRB- ERM -RRB- algorithm along with a theoretical generalization result.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "222": {"text": "Our extensive experimental results significantly improve over both uniform sampling and standard stratified sampling which are de-facto the industry standards.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "225": {"text": "Three models are compared, which involve priming of rules between sentences, within sentences, and within coordinate structures.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "227": {"text": "Experimental evidence shows that semantically meaningful segments are inferred, even when image data alone gives rise to ambiguous segmentations.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "230": {"text": "The task of machine translation -LRB- MT -RRB- evaluation is closely related to the task of sentence-level semantic equivalence classification.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "235": {"text": "Instead it assumes that the bad data are randomly -LRB- uniformly -RRB- distributed within the dynamic range of the sensor.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "236": {"text": "We show that none of them satisfies both criteria, and suggest new directions for research on alternative metagrammatical formalisms.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "237": {"text": "However, the distribution is unknown, so it is difficult to use the geodesic distance when comparing two samples.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "240": {"text": "Turkish is an agglutinative language with word structures formed by productive affixations of derivational and inflectional suffixes to root words.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "242": {"text": "When the scene exhibits a persistent dynamic behavior in time, such an assumption is violated and detection performance deteriorates.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "244": {"text": "This enables us to obtain an affine specialization of known projective relations connecting points and lines across two or three views.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "249": {"text": "It also shows that our method significantly outperforms the previous two dependency tree kernels on the 5 ACE relation major types.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "250": {"text": "This paper presents the results of automatically inducing a Combinatory Categorial Grammar -LRB- CCG -RRB- lexicon from a Turkish dependency treebank.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "256": {"text": "However, one can dramatically improve the quality of the learned structure by exploiting simple prior knowledge of the desired solutions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "261": {"text": "The intentional structure captures the discourse-relevant purposes, expressed in each of the linguistic segments as well as relationships among them.", "true": [["intentional structure:other scientific term", "used for", "discourse-relevant purposes:other scientific term"]], "pred": [["intentional structure:other scientific term", "used for", "discourse-relevant purposes:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "262": {"text": "Versions in some other languages known by the user may be displayed, so that improvement sharing is visible and encouraging.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "266": {"text": "Rather than trying to find or define a single\" best\" segmentation, we generate multiple segmentations of an image.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "267": {"text": "Requestors can also instruct the system to notify them when the status of a request changes or when a request is complete.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "268": {"text": "Full digital resolution is maintained even with low-resolution analog-to-digital conversion, owing to random statistics in the analog summation of binary products.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "269": {"text": "We show how features that are imaged through a transparent object behave differently from those that are rigidly attached to the scene.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "271": {"text": "An experimental evaluation of summarization quality shows a close correlation between the automatic parse-based evaluation and a manual evaluation of generated strings.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "274": {"text": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "287": {"text": "The result is a discrete motor control representation of the continuous pen motion, via the quantized levels of the model parameters.", "true": [["discrete motor control representation:method", "used for", "continuous pen motion:other scientific term"]], "pred": [["discrete motor control representation:method", "used for", "continuous pen motion:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "288": {"text": "This piece of work has also laid a foundation for exploring and harvesting English-Chinese bitexts in a larger volume from the Web.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "291": {"text": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "297": {"text": "We present a scanning method that recovers dense sub-pixel camera-projector correspondence without requiring any photometric calibration nor preliminary knowledge of their relative geometry.", "true": [["scanning method:method", "used for", "dense sub-pixel camera-projector correspondence:other scientific term"]], "pred": [["scanning method:method", "used for", "dense sub-pixel camera-projector correspondence:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "300": {"text": "Given a particular concept, or word sense, a topic signature is a set of words that tend to co-occur with it.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "310": {"text": "We discuss the application of synchronous TAGs to concrete examples, mentioning primarily in passing some computational issues that arise in its interpretation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "325": {"text": "The results of this experiment, along with a preliminary analysis of the factors involved in the decision making process will be presented here.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "328": {"text": "We show that the trainable sentence planner performs better than the rule-based systems and the baselines, and as well as the hand-crafted system.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "329": {"text": "The attentional state, being dynamic, records the objects, properties, and relations that are salient at each point of the discourse.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "331": {"text": "But computational linguists seem to be quite dubious about analogies between sentences: they would not be enough numerous to be of any use.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "341": {"text": "Registration of classifier for each noun is limited to the type of unit classifier because other types are open due to the meaning of representation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "342": {"text": "Contrary to most of the existing mixture of viewpoints models, our model establishes explicit correspondences of parts across different viewpoints of the object class.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "344": {"text": "This research is part of a larger study of anaphoric expressions, the results of which will be incorporated into a natural language generation system.", "true": [["anaphoric expressions:other scientific term", "used for", "natural language generation system:method"]], "pred": [["anaphoric expressions:other scientific term", "used for", "natural language generation system:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "345": {"text": "The speakers in the database assigned their own emotions to more specific emotional categories, which led to more extreme values in the activation-valence space.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "349": {"text": "In spite of over two decades of intense research, illumination and pose invariance remain prohibitively challenging aspects of face recognition for most practical applications.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "351": {"text": "These models simulate the reading time advantage for parallel structures found in human data, and also yield a small increase in overall parsing accuracy.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "361": {"text": "Many of the resources used are derived from data created by human beings out of an NLP context, especially regarding MT and reference translations.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "369": {"text": "The subjects were given three minutes per extract to determine whether they believed the sample output to be an expert human translation or a machine translation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "373": {"text": "In this paper, we present methods by which an agent learns action models from its own experience and from its observation of a domain expert.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "378": {"text": "In the simpler case of affine cameras we give neccessary and sufficient constraints on the components of the trifocal tensor, together with a simple geometric interpretation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "397": {"text": "The distribution of nonverbal behaviors differed depending on the type of dialogue move being grounded, and the overall pattern reflected a monitoring of lack of negative feedback.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "399": {"text": "Our preliminary experiments on building a paraphrase corpus have so far been producing promising results, which we have evaluated according to cost-efficiency, exhaustiveness, and reliability.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "400": {"text": "This phenomenon causes many image processing techniques to fail as they assume the presence of only one layer at each examined site e.g. motion estimation and object recognition.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "410": {"text": "Morphemes added to a root word or a stem can convert the word from a nominal to a verbal structure or vice-versa, or can create adverbial constructs.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "411": {"text": "Furthermore, we show how the recently developed efficient subwindow search -LRB- ESS -RRB- procedure -LSB- 11 -RSB- can be integrated into the last stage of our method.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "418": {"text": "This paper analyzes the validity of this assumption by comparing the mismatches between the assessments made by na \u00a8 \u0131ve listeners and by the speakers that generated the data.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "423": {"text": "To overcome this problem, we propose a new, flexible, and scalable way for generating training data that only requires a set of stereo images as input.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "427": {"text": "If is is satisfactory, the errors were probably due to the graph, not to the deconverter, and the graph is sent to deconverters in other languages.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}, "435": {"text": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage, sum-of-pairs, k-means, and k-median.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "436": {"text": "The results of the experiment show that in most of the cases the cooccurrence statistics indeed reflect the semantic constraints and thus provide a basis for a useful disambiguation tool.", "true": [["cooccurrence statistics:other scientific term", "used for", "disambiguation tool:method"]], "pred": [["cooccurrence statistics:other scientific term", "used for", "disambiguation tool:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n"}, "439": {"text": "As new versions are added with appropriate tags and attributes in the original multilingual document, nothing is ever lost, and cooperative working on a document is rendered feasible.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "440": {"text": "It runs in time O -LRB- N 2 + SN log N -RRB-, where S is the number of random samples and N is the number of data points.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "441": {"text": "We show that the light field space is largely bi-linear due to 3D line segments in the scene, and direct tri-angulation of these bilinear subspaces leads to large errors.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "446": {"text": "In the study of expressive speech communication, it is commonly accepted that the emotion perceived by the listener is a good approximation of the intended emotion conveyed by the speaker.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "449": {"text": "We consider two groups of indicators: post level -LRB- determined using information about individual blog posts only -RRB- and blog level -LRB- determined using information from the underlying blogs -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "462": {"text": "Our main result is a first-order upper bound on the distance between any approximate joint triangularizer of the matrices in M' and any exact joint triangularizer of the matrices in M.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "463": {"text": "In particular, it does not depend on optimization specific properties of the triangularizer, such as its proximity to critical points, that are typical of existing bounds in the literature.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "464": {"text": "We want to illustrate a framework less restrictive than earlier ones by allowing a speaker leeway in forming an utterance about a task and in determining the conversational vehicle to deliver it.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "470": {"text": "We are developing a prototype where, in the simplest sharing scenario, naive users interact directly with the text in their language -LRB- L0 -RRB-, and indirectly with the associated graph.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "476": {"text": "Unlike existing interest point detectors, which measure pixel-wise differences in image intensity, our detectors incorporate histogram-based representations, and thus can find image regions that present a distinct distribution in the neighborhood.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "489": {"text": "As an analogy must be valid on the level of form as well as on the level of meaning, we relied on the idea that translation should preserve meaning to test for similar meanings.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "490": {"text": "We demonstrate analytically that MINPRAN distinguishes good ts from ts to random data, and that MINPRAN nds accurate ts and nearly the correct number of inliers, regardless of the percentage of true inliers.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "493": {"text": "In Thai language, it frequently happens that there is fluctuation in the choice of classifier for a given concrete noun, both from the point of view of the whole speech community and individual speakers.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "497": {"text": "The results show that the features in terms of which we formulate our heuristic principles have significant predictive power, and that rules that closely resemble our Horn clauses can be learnt automatically from these features.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "503": {"text": "We consider the problem of approximate joint matrix triangularization when the matrices in M are jointly diagonalizable and real, but we only observe a set M' of noise perturbed versions of the matrices in M.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "513": {"text": "However, when the object becomes partially or totally occluded, such local tracking is prone to failure, especially when common prediction techniques like the Kalman filter do not provide a good estimate of object parameters in future frames.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "519": {"text": "The reality of analogies between words is refuted by noone -LRB- e.g., I walked is to to walk as I laughed is to to laugh, noted I walked: to walk:: I laughed: to laugh -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "521": {"text": "We incorporate the prior on natural images by requiring that the separating hyperplane will not only yield a wide margin, but also that the corresponding positive half space will have a low probability to contain natural images -LRB- the background -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "522": {"text": "Here we suggest a formal perspective on the difficulty in finding such a unification, in the form of an impossibility theorem: for a set of three simple properties, we show that there is no clustering function satisfying all three.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "529": {"text": "Because a speaker and listener cannot be assured to have the same beliefs, contexts, perceptions, backgrounds, or goals, at each point in a conversation, difficulties and mistakes arise when a listener interprets a speaker's utterance.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n(91) \"none\"  \n(92) \"none\"  \n(93) \"none\"  \n(94) \"none\"  \n(95) \"none\"  \n(96) \"none\"  \n(97) \"none\"  \n(98) \"none\"  \n(99) \"none\"  \n(100) \"none\"  \n(101) \"none\"  \n(102) \"none\"  \n(103) \"none\"  \n(104) \"none\"  \n(105) \"none\"  \n(106) \"none\"  \n(107) \"none\"  \n(108) \"none\"  \n(109) \"none\"  \n(110) \"none\"  \n"}, "539": {"text": "In our approach, the slave camera only passively follows the target -LRB- by loose registration with the master -RRB- and bootstraps itself from its own incoming imagery, thus effectively circumventing the problems faced by previous approaches and avoiding the need to perform any model transfer.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}, "545": {"text": "In all of these cases, we expect some form of dependency between the draws: the nucleotide at one position in the DNA strand may depend on the preceding nucleotides, children's names are highly correlated from year to year, and topics in text may be correlated and dynamic.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n"}, "546": {"text": "In this theory, discourse structure is composed of three separate but interrelated components: the structure of the sequence of utterances -LRB- called the linguistic structure -RRB-, a structure of purposes -LRB- called the intentional structure -RRB-, and the state of focus of attention -LRB- called the attentional state -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "548": {"text": "Our method has two major components: a -RRB- a pattern extraction scheme for efficiently harvesting patterns of given size and shape from expert game records and b -RRB- a Bayesian learning algorithm -LRB- in two variants -RRB- that learns a distribution over the values of a move given a board position based on the local pattern context.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}}, "fail_cases": {"3": {"text": "Language resource quality is crucial in NLP.", "true": [], "pred": [["Language resource quality:metric", "used for", "NLP:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "8": {"text": "It is particularly valuable to empirical MT research.", "true": [["It:generic", "used for", "empirical MT research:task"]], "pred": [["It:generic", "used for", "empirical MT research:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "15": {"text": "Translations are produced by means of a beam-search decoder.", "true": [["beam-search decoder:method", "used for", "Translations:other scientific term"]], "pred": [["beam-search decoder:method", "used for", "Translations:material"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "17": {"text": "Therefore, self-assessments will be closer to the intended emotions.", "true": [], "pred": [["self-assessments:generic", "used for", "intended emotions:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "18": {"text": "We investigate independent and relevant event-based extractive mutli-document summarization approaches.", "true": [], "pred": [["approaches:generic", "used for", "independent and relevant event-based extractive mutli-document summarization:task"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "20": {"text": "The paper also promotes a new view for extensional reference.", "true": [], "pred": [["new view:other scientific term", "used for", "extensional reference:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "21": {"text": "Combination methods are an effective way of improving system performance.", "true": [], "pred": [["combination methods:method", "used for", "system performance:metric"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "22": {"text": "Our approach outperforms state-of-the-art trackers on the VIVID benchmark datasets.", "true": [], "pred": [["approach:method", "used for", "VIVID benchmark datasets:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"\n"}, "23": {"text": "We further demonstrate synthesis from a freely translating virtual camera.", "true": [["translating virtual camera:other scientific term", "used for", "synthesis:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "26": {"text": "Deep learning methods have achieved wide success in this task.", "true": [], "pred": [["deep learning methods:method", "used for", "task:generic"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "27": {"text": "Background modeling is an important component of many vision systems.", "true": [], "pred": [["Background modeling:method", "used for", "vision systems:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "29": {"text": "We present a novel approach for automatically acquiring English topic signatures.", "true": [["approach:generic", "used for", "automatically acquiring English topic signatures:task"]], "pred": [["novel approach:method", "used for", "automatically acquiring English topic signatures:task"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "32": {"text": "Finally, the Prolog form is executed to yield the answer.", "true": [], "pred": [["Prolog form:method", "used for", "the answer:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "34": {"text": "It is presented as a generalization of the recursive descent parser.", "true": [["recursive descent parser:method", "used for", "It:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "36": {"text": "The validation of these resources is widely recommended before being used.", "true": [], "pred": [["validation:task", "used for", "these:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "37": {"text": "This paper describes the impact of using different-quality references on evaluation.", "true": [["different-quality references:other scientific term", "used for", "evaluation:generic"]], "pred": [["different-quality references:other scientific term", "used for", "evaluation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"\n"}, "38": {"text": "Extensive experiments demonstrate the utility and performance of the proposed approach.", "true": [], "pred": [["proposed approach:method", "used for", "performance:metric"], ["proposed approach:method", "used for", "experiments:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"used for\"  \n"}, "39": {"text": "We present a new method for detecting interest points using histogram information.", "true": [["method:generic", "used for", "detecting interest points:task"], ["histogram information:other scientific term", "used for", "detecting interest points:task"]], "pred": [["histogram information:other scientific term", "used for", "interest points:other scientific term"], ["method:generic", "used for", "interest points:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"\n"}, "40": {"text": "A random modulation scheme produces near-Bernoulli statistics even for highly correlated inputs.", "true": [["random modulation scheme:method", "used for", "near-Bernoulli statistics:other scientific term"], ["highly correlated inputs:material", "used for", "random modulation scheme:method"]], "pred": [["random modulation scheme:method", "used for", "near-Bernoulli statistics:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "41": {"text": "With independent approach, we identify important contents by frequency of events.", "true": [], "pred": [["independent approach:method", "used for", "important contents:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "42": {"text": "We present Minimum Bayes-Risk -LRB- MBR -RRB- decoding for statistical machine translation.", "true": [["Minimum Bayes-Risk -LRB- MBR -RRB- decoding:method", "used for", "statistical machine translation:task"]], "pred": [["Minimum Bayes-Risk -LRB- MBR -RRB-:method", "used for", "statistical machine translation:task"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "44": {"text": "We suggest a new goal and evaluation criterion for word similarity measures.", "true": [["evaluation criterion:metric", "used for", "word similarity measures:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "47": {"text": "These include demonstrations of synthesis of cyclopean views of extended conversational sequences.", "true": [], "pred": [["synthesis of cyclopean views:method", "used for", "extended conversational sequences:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "49": {"text": "Related work applies MINPRAN to complex range and intensity data 23 -RSB-.", "true": [["MINPRAN:method", "used for", "complex range:other scientific term"], ["MINPRAN:method", "used for", "intensity data:material"]], "pred": [["complex range and intensity data:material", "used for", "MINPRAN:method"], ["MINPRAN:method", "used for", "complex range and intensity data:material"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "50": {"text": "Such a triangulation provides a piecewise-linear interpolant useful for light field super-resolution.", "true": [["triangulation:other scientific term", "used for", "piecewise-linear interpolant:other scientific term"], ["piecewise-linear interpolant:other scientific term", "used for", "light field super-resolution:task"]], "pred": [["piecewise-linear interpolant:other scientific term", "used for", "light field super-resolution:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "51": {"text": "A method for producing such phrases from a word-aligned corpora is proposed.", "true": [["method:generic", "used for", "phrases:generic"]], "pred": [["method:generic", "used for", "phrases:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "54": {"text": "This posterior encodes sparse se-lectional preferences between a head word and its dependents.", "true": [["posterior:generic", "used for", "sparse se-lectional preferences:other scientific term"]], "pred": [["sparse selectional preferences:other scientific term", "used for", "posterior:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "55": {"text": "We have built and will demonstrate an application of this approach called LCS-Marine.", "true": [["approach:generic", "used for", "LCS-Marine:task"]], "pred": [["application:task", "used for", "LCS-Marine:method"], ["application:task", "used for", "this approach:generic"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "56": {"text": "We have conducted numerous simulations to verify the practical feasibility of our algorithm.", "true": [], "pred": [["simulations:task", "used for", "our algorithm:method"], ["our algorithm:method", "used for", "simulations:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "57": {"text": "Machine transliteration/back-transliteration plays an important role in many multilingual speech and language applications.", "true": [["Machine transliteration/back-transliteration:task", "used for", "multilingual speech and language applications:task"]], "pred": [["Machine transliteration/back-transliteration:method", "used for", "multilingual speech and language applications:task"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "58": {"text": "Design challenges, trade-offs and some experimental results are presented in this paper.", "true": [], "pred": [["experimental results:other scientific term", "used for", "this paper:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "61": {"text": "This paper presents a machine learning approach to bare slice disambiguation in dialogue.", "true": [["machine learning approach:method", "used for", "bare slice disambiguation:task"], ["dialogue:material", "used for", "bare slice disambiguation:task"]], "pred": [["machine learning approach:method", "used for", "bare slice disambiguation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "63": {"text": "It models reflection as regions containing two different layers moving over each other.", "true": [["It:generic", "used for", "reflection:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "64": {"text": "We present a strong detector based on combining a set of weak detectors.", "true": [["detectors:generic", "used for", "detector:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "66": {"text": "This paper describes a method for incorporating priming into an incremental probabilistic parser.", "true": [["method:generic", "used for", "priming:other scientific term"], ["priming:other scientific term", "used for", "incremental probabilistic parser:method"]], "pred": [["method:generic", "used for", "incremental probabilistic parser:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "67": {"text": "The seven categories of the scheme are based on rhetorical moves of argumentation.", "true": [["rhetorical moves of argumentation:method", "used for", "scheme:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "68": {"text": "A new algorithm is proposed for novel view generation in one-to-one teleconferencing applications.", "true": [["algorithm:generic", "used for", "novel view generation:task"], ["novel view generation:task", "used for", "one-to-one teleconferencing applications:task"]], "pred": [["novel view generation:task", "used for", "one-to-one teleconferencing applications:task"], ["algorithm:method", "used for", "novel view generation:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n"}, "69": {"text": "For various reasons, UNL graphs are the best candidates in this context.", "true": [], "pred": [["UNL graphs:other scientific term", "used for", "this context:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "70": {"text": "This motor control representation enables successful word spotting and matching of cursive scripts.", "true": [["motor control representation:method", "used for", "word spotting:task"], ["motor control representation:method", "used for", "matching of cursive scripts:task"]], "pred": [["word spotting:task", "used for", "matching of cursive scripts:task"], ["motor control representation:method", "used for", "matching of cursive scripts:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "71": {"text": "Labeled data is replaced by a few hand-crafted rules that encode basic syntactic knowledge.", "true": [["hand-crafted rules:other scientific term", "used for", "syntactic knowledge:other scientific term"]], "pred": [["hand-crafted rules:method", "used for", "basic syntactic knowledge:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "72": {"text": "Listen-Communicate-Show -LRB- LCS -RRB- is a new paradigm for human interaction with data sources.", "true": [["Listen-Communicate-Show -LRB- LCS -RRB-:task", "used for", "human interaction with data sources:task"]], "pred": [["Listen-Communicate-Show -LRB- LCS -RRB-:method", "used for", "human interaction:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"used for\"  \n"}, "73": {"text": "This paper presents an algorithm for selecting an appropriate classifier word for a noun.", "true": [], "pred": [["classifier word:other scientific term", "used for", "noun:other scientific term"], ["algorithm:method", "used for", "noun:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "77": {"text": "Then, we explore whether information about meeting context can aid classifiers' performances.", "true": [], "pred": [["information about meeting context:other scientific term", "used for", "classifiers' performances:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "81": {"text": "The integrated learning system has been experimentally validated in simulated construction and ooce domains.", "true": [], "pred": [["integrated learning system:method", "used for", "simulated construction:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "82": {"text": "Our combination methods rely on predominant senses which are derived automatically from raw text.", "true": [["predominant senses:other scientific term", "used for", "combination methods:method"], ["raw text:material", "used for", "predominant senses:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "83": {"text": "The system is implemented entirely in Prolog, a programming language based on logic.", "true": [["Prolog:other scientific term", "used for", "system:generic"], ["logic:other scientific term", "used for", "programming language:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "84": {"text": "The scheme was implemented by gathering statistics on the output of other linguistic tools.", "true": [], "pred": [["scheme:method", "used for", "output:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "85": {"text": "We present a novel method for discovering parallel sentences in comparable, non-parallel corpora.", "true": [["method:generic", "used for", "discovering parallel sentences:task"], ["comparable, non-parallel corpora:material", "used for", "discovering parallel sentences:task"]], "pred": [["method:generic", "used for", "non-parallel corpora:material"], ["method:generic", "used for", "parallel sentences:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "86": {"text": "This theory provides a framework for describing the processing of utterances in a discourse.", "true": [], "pred": [["theory:other scientific term", "used for", "discourse:other scientific term"], ["processing of utterances:task", "used for", "discourse:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "88": {"text": "The modified graph is then sent to the UNL-L0 deconverter and the result shown.", "true": [["graph:other scientific term", "used for", "UNL-L0 deconverter:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "89": {"text": "We then derive a scalable stochastic gradient descent algorithm for the resulting learning problem.", "true": [["stochastic gradient descent algorithm:method", "used for", "learning problem:generic"]], "pred": [["scalable stochastic gradient descent algorithm:method", "used for", "resulting learning problem:task"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "90": {"text": "We also derive an efficient non-linear extension of WARCA by using the kernel trick.", "true": [["kernel trick:method", "used for", "non-linear extension of WARCA:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "91": {"text": "A model-based approach to on-line cursive handwriting analysis and recognition is presented and evaluated.", "true": [["model-based approach:method", "used for", "on-line cursive handwriting analysis and recognition:task"]], "pred": [["on-line cursive handwriting analysis:task", "used for", "recognition:task"], ["model-based approach:method", "used for", "on-line cursive handwriting analysis:task"], ["model-based approach:method", "used for", "recognition:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"used for\"  \n"}, "92": {"text": "In contrast, object pose estimation using these approaches has received relatively less attention.", "true": [["approaches:generic", "used for", "object pose estimation:task"]], "pred": [["these approaches:generic", "used for", "object pose estimation:task"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "93": {"text": "Light fields are image-based representations that use densely sampled rays as a scene description.", "true": [], "pred": [["Light fields:other scientific term", "used for", "scene description:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "94": {"text": "GLOSSER is designed to support reading and learning to read in a foreign language.", "true": [["GLOSSER:method", "used for", "reading and learning:task"]], "pred": [["reading:task", "used for", "GLOSSER:method"], ["learning to read:task", "used for", "GLOSSER:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "96": {"text": "First, it uses several kinds of dictionaries to segment and tag Japanese character strings.", "true": [["dictionaries:other scientific term", "used for", "it:generic"], ["dictionaries:other scientific term", "used for", "Japanese character strings:other scientific term"]], "pred": [["segment:task", "used for", "Japanese character strings:material"], ["tag:task", "used for", "Japanese character strings:material"], ["Japanese character strings:material", "used for", "segment:task"], ["Japanese character strings:material", "used for", "tag:task"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"used for\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "97": {"text": "A domain independent model is proposed for the automated interpretation of nominal compounds in English.", "true": [["domain independent model:method", "used for", "automated interpretation of nominal compounds:task"]], "pred": [["automated interpretation:task", "used for", "nominal compounds:other scientific term"], ["nominal compounds:other scientific term", "used for", "automated interpretation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "99": {"text": "This model was shown to be more appropriate for blind separation of natural speech signals.", "true": [["model:generic", "used for", "blind separation of natural speech signals.:task"]], "pred": [["model:method", "used for", "blind separation of natural speech signals:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "100": {"text": "We evaluate the proposed methods through several transliteration/backtransliteration experiments for English/Chinese and English/Japanese language pairs.", "true": [["transliteration/backtransliteration:task", "used for", "English/Chinese and English/Japanese language pairs:material"]], "pred": [["transliteration/backtransliteration experiments:task", "used for", "English/Chinese:material"], ["transliteration/backtransliteration experiments:task", "used for", "English/Japanese:material"], ["transliteration/backtransliteration experiments:task", "used for", "proposed methods:method"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "102": {"text": "This paper solves a specialized regression problem to obtain sampling probabilities for records in databases.", "true": [["specialized regression problem:task", "used for", "sampling probabilities:other scientific term"], ["sampling probabilities:other scientific term", "used for", "records:material"]], "pred": [["specialized regression problem:task", "used for", "sampling probabilities:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "104": {"text": "Branch and bound strategies have previously attempted to curb this complexity whilst maintaining global optimality.", "true": [["Branch and bound strategies:method", "used for", "complexity:generic"]], "pred": [["Branch and bound strategies:method", "used for", "global optimality:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "107": {"text": "To our knowledge, this is the first a posteriori bound for joint matrix decomposition.", "true": [["posteriori bound:other scientific term", "used for", "joint matrix decomposition:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "108": {"text": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision.", "true": [["Learned confidence measures:method", "used for", "outlier removal:task"], ["Learned confidence measures:method", "used for", "quality improvement:task"]], "pred": [["learned confidence measures:other scientific term", "used for", "stereo vision:other scientific term"], ["learned confidence measures:other scientific term", "used for", "quality improvement:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "110": {"text": "To evaluate our proposed model, we build a large streaming video dataset with annotations.", "true": [], "pred": [["large streaming video dataset:material", "used for", "model:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "111": {"text": "A search restriction especially useful for the translation direction from German to English is presented.", "true": [], "pred": [["search restriction:method", "used for", "translation direction:other scientific term"], ["German:material", "used for", "translation direction:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "114": {"text": "Our experiments clearly indicate the potential of this dynamic representation for complete cursive handwriting recognition.", "true": [["dynamic representation:method", "used for", "cursive handwriting recognition:task"]], "pred": [["complete cursive handwriting recognition:task", "used for", "experiments:generic"], ["dynamic representation:method", "used for", "complete cursive handwriting recognition:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "115": {"text": "Recent progress in computer vision has been driven by high-capacity models trained on large datasets.", "true": [["high-capacity models:method", "used for", "computer vision:task"], ["large datasets:material", "used for", "high-capacity models:method"]], "pred": [["high-capacity models:method", "used for", "computer vision:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "116": {"text": "These mattes are implied by a set of hypothesized object boundary fragments in the scene.", "true": [["hypothesized object boundary fragments:other scientific term", "used for", "mattes:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "117": {"text": "They improve the reconstruction results and enforce their consistency with a priori knowledge about object shape.", "true": [["They:generic", "used for", "reconstruction:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "118": {"text": "The request is passed to a mobile, intelligent agent for execution at the appropriate database.", "true": [], "pred": [["intelligent agent:method", "used for", "request:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "119": {"text": "An extension of our method to space-time interest point detection for action classification is also presented.", "true": [["method:generic", "used for", "space-time interest point detection:task"], ["space-time interest point detection:task", "used for", "action classification:task"]], "pred": [["space-time interest point detection:method", "used for", "method:generic"], ["method:generic", "used for", "space-time interest point detection:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n"}, "120": {"text": "The polarization of the objects of the elementary structures controls the saturation of the final structure.", "true": [], "pred": [["polarization:other scientific term", "used for", "saturation:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "122": {"text": "Our approach is among the first to propose a generative proba-bilistic framework for 3D object categorization.", "true": [["generative proba-bilistic framework:method", "used for", "3D object categorization:task"]], "pred": [["approach:generic", "used for", "3D object categorization:task"], ["generative probabilistic framework:method", "used for", "3D object categorization:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "124": {"text": "We use gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities.", "true": [], "pred": [["gray-level band-pass white noise patterns:material", "used for", "indirect lighting:other scientific term"], ["gray-level band-pass white noise patterns:material", "used for", "scene discontinuities:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "126": {"text": "This probably occurs because each model has different strengths and weaknesses for modeling the knowledge sources.", "true": [["model:generic", "used for", "knowledge sources:material"]], "pred": [["model:other scientific term", "used for", "modeling the knowledge sources:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "127": {"text": "The psycholinguistic literature provides evidence for syntactic priming, i.e., the tendency to repeat structures.", "true": [["psycholinguistic literature:other scientific term", "used for", "syntactic priming:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "128": {"text": "This enables us to generate a huge amount of training data in a fully automated manner.", "true": [], "pred": [["training data:material", "used for", "fully automated manner:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "129": {"text": "The goal of this work is the enrichment of human-machine interactions in a natural language environment.", "true": [], "pred": [["enrichment:task", "used for", "human-machine interactions:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "130": {"text": "Chat-80 has been designed to be both efficient and easily adaptable to a variety of applications.", "true": [], "pred": [["Chat-80:method", "used for", "variety of applications:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"used for\"  \n"}, "131": {"text": "Our technique is based on an improved, dynamic-programming, stereo algorithm for efficient novel-view generation.", "true": [["technique:generic", "used for", "novel-view generation:task"], ["dynamic-programming, stereo algorithm:method", "used for", "technique:generic"]], "pred": [["efficient novel-view generation:task", "used for", "technique:method"], ["technique:method", "used for", "efficient novel-view generation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n"}, "132": {"text": "This paper presents an automatic scheme for collecting statistics on cooccurrence patterns in a large corpus.", "true": [], "pred": [["automatic scheme:method", "used for", "cooccurrence patterns:other scientific term"], ["automatic scheme:method", "used for", "statistics:metric"], ["automatic scheme:method", "used for", "large corpus:material"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n"}, "133": {"text": "Memo-functions also facilitate a simple way to construct a very compact representation of the parse forest.", "true": [["Memo-functions:method", "used for", "parse forest:other scientific term"]], "pred": [["Memo-functions:method", "used for", "compact representation:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "135": {"text": "We propose a novel metric learning formulation called Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-.", "true": [], "pred": [["Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-:method", "used for", "metric learning formulation:method"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "136": {"text": "We present a variant of TAGs, called synchronous TAGs, which characterize correspondences between languages.", "true": [], "pred": [["variant of TAGs:method", "used for", "correspondences between languages:other scientific term"], ["synchronous TAGs:method", "used for", "correspondences between languages:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "138": {"text": "With the rise of deep archi-tectures, the prime focus has been on object category recognition.", "true": [["deep archi-tectures:method", "used for", "object category recognition:task"]], "pred": [["deep architectures:other scientific term", "used for", "object category recognition:task"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "139": {"text": "Similar results were previously obtained with MSG -LRB- Modulation-filtered Spec-troGram -RRB- auditory features -LSB- 2 -RSB-.", "true": [], "pred": [["MSG -LRB- Modulation-filtered Spec-troGram -RRB- auditory features:other scientific term", "used for", "results:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "142": {"text": "The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes.", "true": [["approach:generic", "used for", "cluttered scenes:other scientific term"]], "pred": [["proposed approach:method", "used for", "cluttered scenes:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "143": {"text": "This work proposes a new research direction to address the lack of structures in traditional n-gram models.", "true": [], "pred": [["new research direction:task", "used for", "lack of structures:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "144": {"text": "Experiment results on ACE corpora show that this spectral clustering based approach outperforms the other clustering methods.", "true": [], "pred": [["Experiment results:material", "used for", "spectral clustering based approach:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "145": {"text": "The perception of transparent objects from images is known to be a very hard problem in vision.", "true": [["images:material", "used for", "perception of transparent objects:task"]], "pred": [["perception of transparent objects:task", "used for", "vision:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "149": {"text": "In this paper we discuss object detection when only a small number of training examples are given.", "true": [], "pred": [["this paper:generic", "used for", "object detection:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"\n"}, "151": {"text": "Subpixel accuracy is achieved by considering several zero-crossings defined by the difference between pairs of unstructured patterns.", "true": [["zero-crossings:other scientific term", "used for", "Subpixel accuracy:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "152": {"text": "We analyzed eye gaze, head nods and attentional focus in the context of a direction-giving task.", "true": [], "pred": [["direction-giving task:task", "used for", "eye gaze:other scientific term"], ["direction-giving task:task", "used for", "head nods:other scientific term"], ["direction-giving task:task", "used for", "attentional focus:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "153": {"text": "Moreover, a cost zero solution always exists and can only be excluded by hard budget constraints.", "true": [["hard budget constraints:other scientific term", "used for", "cost zero solution:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "154": {"text": "We present results on addressee identification in four-participants face-to-face meetings using Bayesian Network and Naive Bayes classifiers.", "true": [["Bayesian Network:method", "used for", "addressee identification in four-participants face-to-face meetings:task"], ["Naive Bayes classifiers:method", "used for", "addressee identification in four-participants face-to-face meetings:task"]], "pred": [["four-participants face-to-face meetings:material", "used for", "addressee identification:task"], ["Bayesian Network:method", "used for", "addressee identification:task"], ["Naive Bayes classifiers:method", "used for", "addressee identification:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"used for\"  \n(20) \"used for\"  \n"}, "155": {"text": "This distribution has numerous applications in computer Go, including serving as an efficient stand-alone Go player.", "true": [["distribution:generic", "used for", "computer Go:other scientific term"]], "pred": [["applications:task", "used for", "computer Go:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "156": {"text": "We investigate several voting - and arbiter-based combination strategies over a diverse pool of unsupervised WSD systems.", "true": [["voting - and arbiter-based combination strategies:method", "used for", "unsupervised WSD systems:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "157": {"text": "This paper gives an overall account of a prototype natural language question answering system, called Chat-80.", "true": [], "pred": [["Chat-80:material", "used for", "prototype natural language question answering system:method"], ["This paper:generic", "used for", "prototype natural language question answering system:method"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n"}, "158": {"text": "Human action recognition from well-segmented 3D skeleton data has been intensively studied and attracting an increasing attention.", "true": [["well-segmented 3D skeleton data:material", "used for", "Human action recognition:task"]], "pred": [["Human action recognition:task", "used for", "well-segmented 3D skeleton data:material"], ["well-segmented 3D skeleton data:material", "used for", "Human action recognition:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "162": {"text": "There are four language pairs currently supported by GLOSSER: English-Bulgarian, English-Estonian, English-Hungarian and French-Dutch.", "true": [["language pairs:generic", "used for", "GLOSSER:method"]], "pred": [["GLOSSER:method", "used for", "four language pairs:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"used for\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "163": {"text": "The program is operational on UNIX and Windows '95 platforms, and has undergone a pilot user-study.", "true": [], "pred": [["program:generic", "used for", "UNIX:material"], ["program:generic", "used for", "Windows '95:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "164": {"text": "In practice, the current deep embedding methods use the Euclidean distance for the training and test.", "true": [["Euclidean distance:other scientific term", "used for", "deep embedding methods:method"]], "pred": [["training:task", "used for", "deep embedding methods:method"], ["training:task", "used for", "Euclidean distance:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "165": {"text": "Our proposed approach builds on recent advances in spectral clustering, image matting, and boundary detection.", "true": [["spectral clustering:method", "used for", "approach:generic"], ["image matting:method", "used for", "approach:generic"], ["boundary detection:method", "used for", "approach:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "166": {"text": "Indeed, automatic evaluations need high-quality data that allow the comparison of both automatic and human translations.", "true": [], "pred": [["high-quality data:material", "used for", "automatic evaluations:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "169": {"text": "Fast algorithms for nearest neighbor -LRB- NN -RRB- search have in large part focused on 2 distance.", "true": [["Fast algorithms:generic", "used for", "nearest neighbor -LRB- NN -RRB- search:task"]], "pred": [["Fast algorithms:method", "used for", "nearest neighbor -LRB- NN -RRB-:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "170": {"text": "Structural or numerical constraints can then be added locally to the reconstruction process through a constrained optimization scheme.", "true": [["Structural or numerical constraints:other scientific term", "used for", "reconstruction process:method"], ["constrained optimization scheme:method", "used for", "Structural or numerical constraints:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "172": {"text": "Using LCS-Marine, tactical personnel can converse with their logistics system to place a supply or information request.", "true": [], "pred": [["LCS-Marine:method", "used for", "tactical personnel:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "173": {"text": "In particular, we make extensive use of Pustejovsky's principles concerning the predicative information associated with nominals.", "true": [], "pred": [["Pustejovsky's principles:other scientific term", "used for", "predicative information:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "177": {"text": "With relevant approach, we identify important contents by PageRank algorithm on the event map constructed from documents.", "true": [["PageRank algorithm:method", "used for", "relevant approach:method"], ["event map:other scientific term", "used for", "PageRank algorithm:method"], ["documents:material", "used for", "event map:other scientific term"]], "pred": [["PageRank algorithm:method", "used for", "important contents:other scientific term"], ["PageRank algorithm:method", "used for", "relevant approach:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "178": {"text": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance.", "true": [], "pred": [["statistical approach:method", "used for", "expected loss of translation errors:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "179": {"text": "Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions.", "true": [["MBR decoding:method", "used for", "statistical MT:method"], ["MBR decoding:method", "used for", "loss functions:other scientific term"]], "pred": [["MBR decoding:method", "used for", "specific loss functions:other scientific term"], ["MBR decoding:method", "used for", "statistical MT performance:metric"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "180": {"text": "Both classifiers perform the best when conversational context and utterance features are combined with speaker's gaze information.", "true": [["conversational context:other scientific term", "used for", "classifiers:method"], ["utterance features:other scientific term", "used for", "classifiers:method"], ["speaker's gaze information:other scientific term", "used for", "classifiers:method"]], "pred": [["classifiers:method", "used for", "conversational context:other scientific term"], ["classifiers:method", "used for", "utterance features:other scientific term"], ["classifiers:method", "used for", "speaker's gaze information:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "181": {"text": "This, the first experiment in a series of experiments, looks at the intelligibility of MT output.", "true": [], "pred": [["first experiment:task", "used for", "intelligibility:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "182": {"text": "We extract a set of heuristic principles from a corpus-based sample and formulate them as probabilistic Horn clauses.", "true": [["corpus-based sample:material", "used for", "heuristic principles:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "183": {"text": "In particular, we obtain a probability distribution over legal moves for professional play in a given position.", "true": [], "pred": [["probability distribution:other scientific term", "used for", "legal moves:other scientific term"], ["probability distribution:other scientific term", "used for", "professional play:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "184": {"text": "The applicability of many current information extraction techniques is severely limited by the need for supervised training data.", "true": [["supervised training data:material", "used for", "information extraction techniques:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "185": {"text": "Furthermore, the subtask of regression optimization provides the ability to forecast the action prior to its occurrence.", "true": [], "pred": [["subtask of regression optimization:task", "used for", "forecast the action:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "186": {"text": "Experimental results on our dataset and the public G3D dataset both demonstrate very promising performance of our scheme.", "true": [], "pred": [["our scheme:method", "used for", "promising performance:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "187": {"text": "We apply cluster analysis on the sampled parameter space to redetect the object and renew the local tracker.", "true": [["cluster analysis:method", "used for", "sampled parameter space:other scientific term"], ["cluster analysis:method", "used for", "local tracker:method"]], "pred": [["cluster analysis:method", "used for", "object:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "189": {"text": "We provide a unified account of sentence-level and text-level anaphora within the framework of a dependency-based grammar model.", "true": [["dependency-based grammar model:method", "used for", "sentence-level and text-level anaphora:other scientific term"]], "pred": [["unified account:method", "used for", "sentence-level and text-level anaphora:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "190": {"text": "In this paper, we discuss language model adaptation methods given a word list and a raw corpus.", "true": [["word list:other scientific term", "used for", "language model adaptation methods:method"], ["raw corpus:material", "used for", "language model adaptation methods:method"]], "pred": [["word list:material", "used for", "language model adaptation methods:method"], ["raw corpus:material", "used for", "language model adaptation methods:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "191": {"text": "Many practical modeling problems involve discrete data that are best represented as draws from multinomial or categorical distributions.", "true": [["discrete data:material", "used for", "modeling problems:task"], ["multinomial or categorical distributions:method", "used for", "modeling problems:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "192": {"text": "A general procedure for the estimation and quantization of these cycloidal motion parameters for arbitrary handwriting is presented.", "true": [["cycloidal motion parameters:other scientific term", "used for", "arbitrary handwriting:material"]], "pred": [["general procedure:method", "used for", "cycloidal motion parameters:other scientific term"], ["general procedure:method", "used for", "arbitrary handwriting:other scientific term"], ["estimation:task", "used for", "cycloidal motion parameters:other scientific term"], ["quantization:task", "used for", "cycloidal motion parameters:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "195": {"text": "We further propose a parameter training algorithm for the present model based on a decision tree-based context clustering.", "true": [["parameter training algorithm:method", "used for", "model:generic"], ["decision tree-based context clustering:method", "used for", "parameter training algorithm:method"]], "pred": [["parameter training algorithm:method", "used for", "present model:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "196": {"text": "The NCA is created statistically from a large corpus and recomposed under concept hierarchy constraints and frequency of occurrences.", "true": [["concept hierarchy constraints:other scientific term", "used for", "NCA:method"], ["frequency of occurrences:other scientific term", "used for", "NCA:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "198": {"text": "We present a novel model-based approach to recover the shapes and the poses of transparent objects from known motion.", "true": [["model-based approach:method", "used for", "shapes and the poses of transparent objects:other scientific term"], ["known motion:other scientific term", "used for", "shapes and the poses of transparent objects:other scientific term"]], "pred": [["model-based approach:method", "used for", "shapes:other scientific term"], ["model-based approach:method", "used for", "poses:other scientific term"], ["model-based approach:method", "used for", "known motion:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "199": {"text": "This paper proposes to use a convolution kernel over parse trees to model syntactic structure information for relation extraction.", "true": [["convolution kernel over parse trees:method", "used for", "syntactic structure information:other scientific term"], ["syntactic structure information:other scientific term", "used for", "relation extraction:task"]], "pred": [["convolution kernel:method", "used for", "syntactic structure information:other scientific term"], ["relation extraction:task", "used for", "syntactic structure information:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "200": {"text": "We compare our results to state of the art methods such as mi-cro phase shifting and modulated phase shifting.", "true": [], "pred": [["state of the art methods:method", "used for", "results:generic"], ["mi-cro phase shifting:method", "used for", "results:generic"], ["modulated phase shifting:method", "used for", "results:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "201": {"text": "It uses a powerful pattern-matching language to classify grs into frames hierarchically in a way that mirrors inheritance-based lexica.", "true": [["pattern-matching language:other scientific term", "used for", "It:generic"], ["pattern-matching language:other scientific term", "used for", "grs:other scientific term"]], "pred": [["powerful pattern-matching language:method", "used for", "frames:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "202": {"text": "We provide a principled and provable solution for this problem; it is parameterless and requires no data insights.", "true": [["principled and provable solution:method", "used for", "problem:generic"]], "pred": [["it:generic", "used for", "this problem:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "203": {"text": "We evaluate the demands that task dialogues collected using this technique, place upon a prototype Natural Language system.", "true": [["task dialogues:material", "used for", "prototype Natural Language system:method"], ["technique:generic", "used for", "task dialogues:material"]], "pred": [["this technique:method", "used for", "task dialogues:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"\n"}, "204": {"text": "A language learning experiment showed that assessors can differentiate native from non-native language essays in less than 100 words.", "true": [], "pred": [["non-native language essays:material", "used for", "language learning experiment:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "205": {"text": "We tested this to see if similar criteria could be elicited from duplicating the experiment using machine translation output.", "true": [], "pred": [["experiment:task", "used for", "similar criteria:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "206": {"text": "This work presents an automated technique for detecting reflections in image sequences by analyzing motion trajectories of feature points.", "true": [["technique:generic", "used for", "detecting reflections in image sequences:task"], ["motion trajectories:other scientific term", "used for", "technique:generic"]], "pred": [["motion trajectories:other scientific term", "used for", "reflections:other scientific term"], ["automated technique:method", "used for", "reflections:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "207": {"text": "As a Monte Carlo approach, ASA stochastically samples the parameter space, in contrast to local deterministic search.", "true": [], "pred": [["Monte Carlo approach:method", "used for", "parameter space:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "209": {"text": "This paper presents a phrase-based statistical machine translation method, based on non-contiguous phrases, i.e. phrases with gaps.", "true": [["non-contiguous phrases:material", "used for", "phrase-based statistical machine translation method:method"]], "pred": [["phrase-based statistical machine translation method:method", "used for", "non-contiguous phrases:other scientific term"], ["phrase-based statistical machine translation method:method", "used for", "phrases with gaps:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "210": {"text": "Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data.", "true": [], "pred": [["proposed method:method", "used for", "experimental results:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"\n"}, "211": {"text": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels.", "true": [["data-dependent bandwidth:other scientific term", "used for", "ambiguities:other scientific term"], ["data-dependent bandwidth:other scientific term", "used for", "density estimation:task"], ["kernels:method", "used for", "density estimation:task"]], "pred": [["data-dependent bandwidth:method", "used for", "density estimation:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "212": {"text": "In this paper, we present our approach for using information extraction annotations to augment document retrieval for distillation.", "true": [["information extraction annotations:other scientific term", "used for", "document retrieval for distillation:task"]], "pred": [["document retrieval:task", "used for", "distillation:task"], ["information extraction annotations:material", "used for", "document retrieval:task"], ["approach:generic", "used for", "document retrieval:task"], ["approach:generic", "used for", "distillation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "213": {"text": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships.", "true": [["representation:generic", "used for", "three-dimensional objects:other scientific term"]], "pred": [["novel representation:method", "used for", "three-dimensional objects:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "214": {"text": "It has also been studied in the framework of Japanese information extraction -LRB- -LSB- 3 -RSB- -RRB- in recent years.", "true": [["Japanese information extraction:task", "used for", "It:generic"]], "pred": [["It:generic", "used for", "Japanese information extraction -LRB- -LSB- 3 -RSB- -RRB-:method"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "215": {"text": "Our approach is based on the iterative deformation of a 3--D surface mesh to minimize an objective function.", "true": [["iterative deformation of a 3--D surface mesh:method", "used for", "approach:generic"], ["iterative deformation of a 3--D surface mesh:method", "used for", "objective function:other scientific term"]], "pred": [["iterative deformation:method", "used for", "approach:generic"], ["approach:generic", "used for", "iterative deformation:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "216": {"text": "The model is evaluated on English and Czech newspaper texts, and is then validated on French broadcast news transcriptions.", "true": [], "pred": [["English and Czech newspaper texts:material", "used for", "model:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "217": {"text": "At the core of the externally digital architecture is a high-density, low-power analog array performing binary-binary partial matrix-vector multiplication.", "true": [["binary-binary partial matrix-vector multiplication:method", "used for", "high-density, low-power analog array:other scientific term"]], "pred": [["binary-binary partial matrix-vector multiplication:task", "used for", "low-power analog array:method"], ["low-power analog array:method", "used for", "binary-binary partial matrix-vector multiplication:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "219": {"text": "Specifically, we show how to incorporate a simple prior on the distribution of natural images into support vector machines.", "true": [["prior on the distribution of natural images:other scientific term", "used for", "support vector machines:method"]], "pred": [["distribution of natural images:other scientific term", "used for", "support vector machines:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "220": {"text": "Based on these results, we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state.", "true": [["verbal and nonverbal grounding acts:other scientific term", "used for", "ECA:method"], ["verbal and nonverbal grounding acts:other scientific term", "used for", "dialogue state:other scientific term"]], "pred": [["ECA:method", "used for", "dialogue state:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "223": {"text": "Topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic.", "true": [], "pred": [["topical blog post retrieval:task", "used for", "given topic:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "224": {"text": "We describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models.", "true": [["language models:method", "used for", "them:generic"]], "pred": [["retrieval approach:method", "used for", "indicators:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "226": {"text": "The combined approach is formulated in the framework of Bayesian statistics to account for the robust-ness requirement in image understanding.", "true": [["approach:generic", "used for", "robust-ness requirement in image understanding:task"], ["Bayesian statistics:method", "used for", "approach:generic"]], "pred": [["combined approach:method", "used for", "image understanding:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n"}, "228": {"text": "Experiments using the SemCor and Senseval-3 data sets demonstrate that our ensembles yield significantly better results when compared with state-of-the-art.", "true": [], "pred": [["ensembles:method", "used for", "significantly better results:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "229": {"text": "We propose a multi-task end-to-end Joint Classification-Regression Recurrent Neural Network to better explore the action type and temporal localiza-tion information.", "true": [["multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method", "used for", "action type:other scientific term"], ["multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method", "used for", "temporal localiza-tion information:other scientific term"]], "pred": [["multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method", "used for", "action type:other scientific term"], ["multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method", "used for", "temporal localization information:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "231": {"text": "Our technique gives a substantial improvement in paraphrase classification accuracy over all of the other models used in the experiments.", "true": [], "pred": [["paraphrase classification:task", "used for", "technique:method"], ["technique:method", "used for", "accuracy:metric"], ["technique:method", "used for", "experiments:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "232": {"text": "In this paper We experimentally evaluate a trainable sentence planner for a spoken dialogue system by eliciting subjective human judgments.", "true": [["trainable sentence planner:method", "used for", "spoken dialogue system:method"]], "pred": [["trainable sentence planner:method", "used for", "spoken dialogue system:method"], ["trainable sentence planner:method", "used for", "subjective human judgments:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "233": {"text": "Thus, our method can be applied with great benefit to language pairs for which only scarce resources are available.", "true": [["scarce resources:material", "used for", "method:generic"]], "pred": [["method:generic", "used for", "scarce resources:material"], ["method:generic", "used for", "language pairs:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "234": {"text": "We report experiments conducted on a multilingual corpus to estimate the number of analogies among the sentences that it contains.", "true": [], "pred": [["multilingual corpus:material", "used for", "experiments:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "238": {"text": "Thus the ASR system is designed to deal with what we refer to as Word Spotting and Noise Spotting capabilities.", "true": [["ASR system:method", "used for", "Word Spotting:task"], ["ASR system:method", "used for", "Noise Spotting capabilities:task"]], "pred": [["Word Spotting:task", "used for", "ASR system:method"], ["Noise Spotting:task", "used for", "ASR system:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "239": {"text": "Unfortunately, creating large datasets with pixel-level labels has been extremely costly due to the amount of human effort required.", "true": [], "pred": [["human effort:other scientific term", "used for", "pixel-level labels:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "241": {"text": "The surface realizations of morphological constructions are constrained and modified by a number of phonetic rules such as vowel harmony.", "true": [["phonetic rules:other scientific term", "used for", "surface realizations of morphological constructions:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "243": {"text": "It is based on a weakly supervised dependency parser that can model speech syntax without relying on any annotated training corpus.", "true": [["weakly supervised dependency parser:task", "used for", "speech syntax:other scientific term"]], "pred": [["weakly supervised dependency parser:method", "used for", "speech syntax:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "245": {"text": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy.", "true": [["it:generic", "used for", "real scenes:material"], ["it:generic", "used for", "shapes of the objects:other scientific term"]], "pred": [["it:generic", "used for", "real scenes:material"], ["it:generic", "used for", "transparent objects:material"], ["it:generic", "used for", "shapes of the objects:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"used for\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "246": {"text": "We propose a novel probabilistic framework for learning visual models of 3D object categories by combining appearance information and geometric constraints.", "true": [["probabilistic framework:method", "used for", "visual models of 3D object categories:task"], ["appearance information:other scientific term", "used for", "probabilistic framework:method"], ["geometric constraints:other scientific term", "used for", "probabilistic framework:method"]], "pred": [["probabilistic framework:method", "used for", "visual models of 3D object categories:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "247": {"text": "Furthermore, we propose the use of standard parser evaluation methods for automatically evaluating the summarization quality of sentence condensation systems.", "true": [], "pred": [["sentence condensation systems:task", "used for", "summarization quality:metric"], ["standard parser evaluation methods:method", "used for", "sentence condensation systems:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "248": {"text": "In the case of natural speech signals, the method is shown to have separation accuracy better than the state-of-the-art methods.", "true": [["method:generic", "used for", "natural speech signals:other scientific term"], ["methods:generic", "used for", "natural speech signals:other scientific term"]], "pred": [["method:generic", "used for", "natural speech signals:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "251": {"text": "The experiments show that the system is able to detect scf types with 70% precision and 66% recall rate.", "true": [], "pred": [["system:generic", "used for", "experiments:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "252": {"text": "We demonstrate our approach with multiple PTZ camera sequences in typical outdoor surveillance settings and show a comparison with state-of-the-art approaches.", "true": [["approach:generic", "used for", "outdoor surveillance settings:other scientific term"], ["multiple PTZ camera sequences:other scientific term", "used for", "approach:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "253": {"text": "This paper presents a critical discussion of the various approaches that have been used in the evaluation of Natural Language systems.", "true": [["approaches:generic", "used for", "evaluation of Natural Language systems:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "254": {"text": "We investigate the problem of learning to predict moves in the board game of Go from game records of expert players.", "true": [["game records of expert players:material", "used for", "board game of Go:task"]], "pred": [["learning to predict moves:task", "used for", "board game of Go:material"], ["learning to predict moves:task", "used for", "game records of expert players:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "255": {"text": "In order to build robust automatic abstracting systems, there is a need for better training resources than are currently available.", "true": [["training resources:material", "used for", "automatic abstracting systems:task"]], "pred": [["better training resources:material", "used for", "robust automatic abstracting systems:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "257": {"text": "Our numerical hybrid local and global mode-seeking tracker is validated on challenging airborne videos with heavy occlusion and large camera motions.", "true": [], "pred": [["numerical hybrid local and global mode-seeking tracker:method", "used for", "heavy occlusion:other scientific term"], ["numerical hybrid local and global mode-seeking tracker:method", "used for", "large camera motions:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "258": {"text": "Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams.", "true": [["algorithm:generic", "used for", "spatial and temporal artefacts:other scientific term"], ["spatial and temporal artefacts:other scientific term", "used for", "long stereo video streams:material"]], "pred": [["new algorithm:method", "used for", "long stereo video streams:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"\n"}, "259": {"text": "To a large extent, these statistics reflect semantic constraints and thus are used to disambiguate anaphora references and syntactic ambiguities.", "true": [["semantic constraints:other scientific term", "used for", "anaphora references:other scientific term"], ["semantic constraints:other scientific term", "used for", "syntactic ambiguities:other scientific term"]], "pred": [["statistics:other scientific term", "used for", "anaphora references:other scientific term"], ["statistics:other scientific term", "used for", "syntactic ambiguities:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "260": {"text": "In this paper we explore a new theory of discourse structure that stresses the role of purpose and processing in discourse.", "true": [], "pred": [["new theory of discourse structure:other scientific term", "used for", "discourse:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "263": {"text": "A central goal of this research is to merge approaches from pivot MT, interactive MT, and multilingual text authoring.", "true": [], "pred": [["merge approaches:task", "used for", "pivot MT:method"], ["central goal:generic", "used for", "research:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "264": {"text": "Therefore, the study presented in this paper may be useful in inspiring new designs of deep models for person re-identification.", "true": [["deep models:method", "used for", "person re-identification:task"]], "pred": [["person re-identification:task", "used for", "study:generic"], ["deep models:method", "used for", "person re-identification:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"used for\"\n"}, "265": {"text": "A critical step in encoding sound for neuronal processing occurs when the analog pressure wave is coded into discrete nerve-action potentials.", "true": [["encoding sound:task", "used for", "neuronal processing:task"], ["discrete nerve-action potentials:other scientific term", "used for", "analog pressure wave:other scientific term"]], "pred": [["encoding sound:task", "used for", "neuronal processing:task"], ["encoding sound:task", "used for", "discrete nerve-action potentials:other scientific term"], ["neuronal processing:task", "used for", "discrete nerve-action potentials:other scientific term"], ["critical step:generic", "used for", "neuronal processing:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"used for\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "270": {"text": "A generative framework is used for learning a model that captures the relative position of parts within each of the discretized viewpoints.", "true": [["generative framework:method", "used for", "model:generic"]], "pred": [["generative framework:method", "used for", "model:method"], ["generative framework:method", "used for", "relative position of parts:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "272": {"text": "This paper describes a novel system for acquiring adjectival subcategorization frames -LRB- scfs -RRB- and associated frequency information from English corpus data.", "true": [["system:generic", "used for", "acquiring adjectival subcategorization frames -LRB- scfs -RRB-:task"]], "pred": [["novel system:method", "used for", "adjectival subcategorization frames -LRB- scfs -RRB-:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "273": {"text": "Our study reveals that the proposed method not only reduces an extensive system development effort but also improves the transliteration accuracy significantly.", "true": [], "pred": [["proposed method:method", "used for", "transliteration accuracy:metric"], ["proposed method:method", "used for", "system development effort:task"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "275": {"text": "The goal is to sample a small set of records over which evaluating aggregate queries can be done both efficiently and accurately.", "true": [], "pred": [["small set of records:material", "used for", "evaluating aggregate queries:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "276": {"text": "We show that there is a closed-form -LRB- analytical -RRB- solution for one part of the Kullback-Leibler distance, viz the cross-entropy.", "true": [["closed-form -LRB- analytical -RRB- solution:method", "used for", "Kullback-Leibler distance:method"], ["closed-form -LRB- analytical -RRB- solution:method", "used for", "cross-entropy:method"]], "pred": [["closed-form -LRB- analytical -RRB- solution:method", "used for", "cross-entropy:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "277": {"text": "Finally, a novel feature weighting and selection function is presented, which yields superior feature vectors and better word similarity performance.", "true": [["feature weighting and selection function:method", "used for", "feature vectors:other scientific term"], ["feature weighting and selection function:method", "used for", "word similarity:task"]], "pred": [["feature weighting and selection function:method", "used for", "superior feature vectors:metric"], ["feature weighting and selection function:method", "used for", "word similarity performance:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "278": {"text": "With the aid of a logic-based grammar formalism called extraposition grammars, Chat-80 translates English questions into the Prolog subset of logic.", "true": [["extraposition grammars:method", "used for", "Chat-80:method"]], "pred": [["Chat-80:method", "used for", "extraposition grammars:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "279": {"text": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog, cf. query optimisation in a relational database.", "true": [["planning algorithm:method", "used for", "logical expression:other scientific term"], ["relational database:material", "used for", "query optimisation:method"]], "pred": [["planning algorithm:method", "used for", "logical expression:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "280": {"text": "Our results show that MT evaluation techniques are able to produce useful features for paraphrase classification and to a lesser extent entailment.", "true": [["MT evaluation techniques:method", "used for", "features:other scientific term"], ["MT evaluation techniques:method", "used for", "paraphrase classification:task"], ["MT evaluation techniques:method", "used for", "entailment:task"]], "pred": [["paraphrase classification:task", "used for", "MT evaluation techniques:method"], ["entailment:task", "used for", "MT evaluation techniques:method"], ["paraphrase classification:task", "used for", "useful features:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "281": {"text": "An experiment was performed to resolve references of the pronoun \"it\" in sentences that were randomly selected from the corpus.", "true": [], "pred": [["experiment:task", "used for", "pronoun:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "282": {"text": "We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system.", "true": [["it:generic", "used for", "statistical machine translation system:method"]], "pred": [["extracted data:material", "used for", "state-of-the-art statistical machine translation system:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "283": {"text": "The theory of attention, intention, and aggregation of utterances is illustrated in the paper with a number of example discourses.", "true": [], "pred": [["paper:generic", "used for", "example discourses:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "284": {"text": "This method allows us to avoid these problems and go directly to capturing the statistical behavior of specific words in the application.", "true": [], "pred": [["method:generic", "used for", "specific words:material"], ["method:generic", "used for", "application:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"used for\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "285": {"text": "Unlike other techniques that handle large outlier percentages, MINPRAN does not rely on a known error bound for the good data.", "true": [["techniques:generic", "used for", "large outlier percentages:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "286": {"text": "By slow modulations of the amplitudes and phase lags of the two oscillators, a general pen trajectory can be efficiently encoded.", "true": [], "pred": [["phase lags:other scientific term", "used for", "general pen trajectory:other scientific term"], ["general pen trajectory:other scientific term", "used for", "efficiently encoded:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"used for\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "289": {"text": "In this paper, we explore geometric structures of 3D lines in ray space for improving light field triangulation and stereo matching.", "true": [["geometric structures of 3D lines:task", "used for", "light field triangulation:task"], ["geometric structures of 3D lines:task", "used for", "stereo matching:task"]], "pred": [["light field triangulation:task", "used for", "geometric structures of 3D lines:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "290": {"text": "The triangulation problem aims to fill in the ray space with continuous and non-overlapping simplices anchored at sampled points -LRB- rays -RRB-.", "true": [], "pred": [["triangulation problem:task", "used for", "continuous and non-overlapping simplices:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "292": {"text": "In this paper, we present an approach to rapidly creating pixel-accurate semantic label maps for images extracted from modern computer games.", "true": [["approach:generic", "used for", "pixel-accurate semantic label maps:other scientific term"], ["pixel-accurate semantic label maps:other scientific term", "used for", "images:material"]], "pred": [["images:material", "used for", "pixel-accurate semantic label maps:method"], ["approach:generic", "used for", "pixel-accurate semantic label maps:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "293": {"text": "Towards the modeling of the dynamic characteristics, optical flow is computed and utilized as a feature in a higher dimensional space.", "true": [["optical flow:other scientific term", "used for", "modeling of the dynamic characteristics:task"], ["optical flow:other scientific term", "used for", "feature:other scientific term"], ["feature:other scientific term", "used for", "modeling of the dynamic characteristics:task"]], "pred": [["modeling of the dynamic characteristics:task", "used for", "optical flow:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "294": {"text": "We have demonstrated this capability in several field exercises with the Marines and are currently developing applications of this technology in new domains.", "true": [], "pred": [["applications:task", "used for", "technology:other scientific term"], ["applications:task", "used for", "new domains:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "295": {"text": "We present an application of ambiguity packing and stochastic disambiguation techniques for Lexical-Functional Grammars -LRB- LFG -RRB- to the domain of sentence condensation.", "true": [["ambiguity packing and stochastic disambiguation techniques:method", "used for", "Lexical-Functional Grammars -LRB- LFG -RRB-:method"], ["ambiguity packing and stochastic disambiguation techniques:method", "used for", "sentence condensation:task"]], "pred": [["Lexical-Functional Grammars -LRB- LFG -RRB-:other scientific term", "used for", "sentence condensation:task"], ["ambiguity packing:method", "used for", "sentence condensation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n"}, "296": {"text": "This paper presents necessary and sufficient conditions for the use of demonstrative expressions in English and discusses implications for current discourse processing algorithms.", "true": [["implications:generic", "used for", "discourse processing algorithms:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "298": {"text": "We discuss several applications of the result to the problem of distributional approximation of probabilistic context-free grammars by means of probabilistic finite automata.", "true": [["probabilistic finite automata:method", "used for", "distributional approximation:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "299": {"text": "This paper considers the problem of reconstructing the motion of a 3D articulated tree from 2D point correspondences subject to some temporal prior.", "true": [["2D point correspondences:other scientific term", "used for", "reconstructing the motion of a 3D articulated tree:task"]], "pred": [["problem:task", "used for", "reconstructing the motion of a 3D articulated tree:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "301": {"text": "An important area of learning in autonomous agents is the ability to learn domain-speciic models of actions to be used by planning systems.", "true": [["learning in autonomous agents:task", "used for", "domain-speciic models of actions:method"], ["planning systems:task", "used for", "domain-speciic models of actions:method"]], "pred": [["domain-specific models of actions:method", "used for", "planning systems:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "302": {"text": "Training instances are generated from experience and observation, and a variant of GOLEM is used to learn action models from these instances.", "true": [["GOLEM:method", "used for", "action models:method"]], "pred": [["variant of GOLEM:method", "used for", "action models:method"], ["training instances:material", "used for", "action models:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "303": {"text": "The automated segmentation of images into semantically meaningful parts requires shape information since low-level feature analysis alone often fails to reach this goal.", "true": [["images:material", "used for", "automated segmentation:task"]], "pred": [["automated segmentation:task", "used for", "images:material"], ["automated segmentation:task", "used for", "semantically meaningful parts:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "304": {"text": "In this paper, we describe a search procedure for statistical machine translation -LRB- MT -RRB- based on dynamic programming -LRB- DP -RRB-.", "true": [["search procedure:generic", "used for", "statistical machine translation -LRB- MT -RRB-:task"], ["dynamic programming -LRB- DP -RRB-:method", "used for", "statistical machine translation -LRB- MT -RRB-:task"]], "pred": [["search procedure:method", "used for", "statistical machine translation -LRB- MT -RRB-:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "305": {"text": "The experimental tests are carried out on the Verbmobil task -LRB- German-English, 8000-word vocabulary -RRB-, which is a limited-domain spoken-language task.", "true": [], "pred": [["experimental tests:task", "used for", "limited-domain spoken-language task:task"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "306": {"text": "Various properties of discourse are described, and explanations for the behaviour of cue phrases, referring expressions, and interruptions are explored.", "true": [], "pred": [["explanations:generic", "used for", "behaviour:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "307": {"text": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks.", "true": [["loss:other scientific term", "used for", "Mahalanobis distance:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "308": {"text": "In this sentence-by-sentence error correction method, however, the annotator encounters grammatically complicated positions and this results in a decrease of productivity.", "true": [], "pred": [["sentence-by-sentence error correction method:method", "used for", "decrease of productivity:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "309": {"text": "MINPRAN, a new robust operator, nds good ts in data sets where more than 50% of the points are outliers.", "true": [], "pred": [["MINPRAN:method", "used for", "robust operator:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "311": {"text": "In addition, we improve the learning by a metric weight constraint, so that the learned metric has a better generalization ability.", "true": [["metric weight constraint:other scientific term", "used for", "learning:generic"]], "pred": [["learned metric:other scientific term", "used for", "better generalization ability:other scientific term"], ["metric weight constraint:method", "used for", "better generalization ability:other scientific term"], ["learning:task", "used for", "better generalization ability:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "312": {"text": "This poster paper describes a full scale two-level morphological description -LRB- Karttunen, 1983; Koskenniemi, 1983 -RRB- of Turkish word structures.", "true": [["full scale two-level morphological description:task", "used for", "Turkish word structures:material"]], "pred": [["full scale two-level morphological description:method", "used for", "Turkish word structures:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "313": {"text": "Experiments on the PASCAL VOC 2006 dataset show an acceleration of more than 50% by our method compared to standard cascade evaluation.", "true": [], "pred": [["our method:method", "used for", "acceleration:metric"], ["our method:method", "used for", "PASCAL VOC 2006 dataset:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n"}, "314": {"text": "Here we develop an approach for 1 distance that begins with an explicit and exactly distance-preserving embedding of the points into 2 2.", "true": [["approach:generic", "used for", "1 distance:other scientific term"]], "pred": [["1 distance:other scientific term", "used for", "approach:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "315": {"text": "We rigorously establish the correctness of the methodology and show by experimentation using LSH that it is competitive in practice with available alternatives.", "true": [], "pred": [["it:generic", "used for", "experimentation:task"], ["methodology:method", "used for", "experimentation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"used for\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"used for\"  \n(30) \"none\"  \n"}, "316": {"text": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices.", "true": [["anisotropic meshing:method", "used for", "reconstruction:task"], ["non-quadratic approach:method", "used for", "regularization:other scientific term"], ["non-quadratic approach:method", "used for", "reconstruction:task"], ["triangulations:other scientific term", "used for", "reconstruction:task"]], "pred": [["anisotropic meshing:method", "used for", "triangulations:other scientific term"], ["anisotropic meshing:method", "used for", "satisfactory reconstruction results:metric"], ["non-quadratic approach to regularization:method", "used for", "satisfactory reconstruction results:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"used for\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "317": {"text": "This model is meant to account for productive rules of interpretation which are inferred from the morpho-syntactic and semantic characteristics of the nominal constituents.", "true": [["model:generic", "used for", "productive rules of interpretation:other scientific term"], ["morpho-syntactic and semantic characteristics:other scientific term", "used for", "productive rules of interpretation:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "318": {"text": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation in very high dimensions, suitable for efficient implementation of kernels in image processing.", "true": [["mixed-signal paradigm:method", "used for", "high-resolution parallel inner-product computation:task"], ["mixed-signal paradigm:method", "used for", "kernels:method"], ["kernels:method", "used for", "image processing:task"]], "pred": [["high-resolution parallel inner-product computation:task", "used for", "image processing:task"], ["mixed-signal paradigm:method", "used for", "kernels:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "319": {"text": "The approach is validated with real image data, and with experimental results from a CID/DRAM analog array prototype in 0.5 cents m CMOS.", "true": [], "pred": [["approach:generic", "used for", "real image data:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "320": {"text": "The problem of blind separation of underdetermined instantaneous mixtures of independent signals is addressed through a method relying on nonstationarity of the original signals.", "true": [["method:generic", "used for", "blind separation of underdetermined instantaneous mixtures of independent signals:task"], ["nonstationarity:other scientific term", "used for", "method:generic"]], "pred": [["method:generic", "used for", "blind separation of underdetermined instantaneous mixtures of independent signals:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "321": {"text": "In this paper, we present our work on the detection of question-answer pairs in an email conversation for the task of email summarization.", "true": [["detection of question-answer pairs:task", "used for", "email summarization:task"], ["email conversation:material", "used for", "detection of question-answer pairs:task"]], "pred": [["email conversation:material", "used for", "email summarization:task"], ["our work:generic", "used for", "email summarization:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "322": {"text": "We propose a novel approach to associate objects across multiple PTZ cameras that can be used to perform camera handoff in wide-area surveillance scenarios.", "true": [["approach:generic", "used for", "camera handoff in wide-area surveillance scenarios:task"]], "pred": [["camera handoff:task", "used for", "wide-area surveillance scenarios:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "323": {"text": "We conclude that previous approaches have neglected to evaluate systems in the context of their use, e.g. solving a task requiring data retrieval.", "true": [["systems:generic", "used for", "task:generic"]], "pred": [["systems:generic", "used for", "data retrieval:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "324": {"text": "First, we investigate how well the addressee of a dialogue act can be predicted based on gaze, utterance and conversational context features.", "true": [["gaze:other scientific term", "used for", "addressee of a dialogue act:other scientific term"], ["utterance:other scientific term", "used for", "addressee of a dialogue act:other scientific term"], ["conversational context features:other scientific term", "used for", "addressee of a dialogue act:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "326": {"text": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players.", "true": [["It:generic", "used for", "move selector:method"], ["It:generic", "used for", "move sorter:method"], ["It:generic", "used for", "training tool:task"], ["move selector:method", "used for", "game tree search:method"], ["move sorter:method", "used for", "game tree search:method"], ["training tool:task", "used for", "Go players:other scientific term"]], "pred": [["game tree search:task", "used for", "move selector:method"], ["game tree search:task", "used for", "move sorter:method"], ["move selector:method", "used for", "Go players:generic"], ["training tool:method", "used for", "Go players:generic"], ["move selector:method", "used for", "game tree search:task"], ["move sorter:method", "used for", "game tree search:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"used for\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"used for\"  \n(19) \"used for\"  \n(20) \"none\"  \n"}, "327": {"text": "This paper highlights a particular class of miscommunication--reference problems--by describing a case study and techniques for avoiding failures of reference.", "true": [["techniques:generic", "used for", "failures of reference:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "330": {"text": "This processing description specifies in these recognition tasks the role of information from the discourse and from the participants' knowledge of the domain.", "true": [], "pred": [["recognition tasks:task", "used for", "processing description:other scientific term"], ["processing description:other scientific term", "used for", "recognition tasks:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "332": {"text": "Our core motivation is that minimizing a weighted rank loss is a natural criterion for many problems in computer vision such as person re-identification.", "true": [["weighted rank loss:other scientific term", "used for", "computer vision:task"], ["weighted rank loss:other scientific term", "used for", "person re-identification:task"]], "pred": [["problems in computer vision:task", "used for", "person re-identification:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "333": {"text": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB-.", "true": [["OA:method", "used for", "phase locking in the auditory nerve -LRB- AN -RRB-:task"], ["OA:method", "used for", "features:other scientific term"], ["AN fibers -LRB- ANFs -RRB-:other scientific term", "used for", "features:other scientific term"]], "pred": [["auditory nerve -LRB- AN -RRB-:other scientific term", "used for", "phase locking:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "334": {"text": "Multi-layer perceptrons -LRB- MLPs -RRB- performed much better than standard Gaussian mixture models -LRB- GMMs -RRB- for both our ANF-based and ON-based auditory features.", "true": [["Multi-layer perceptrons -LRB- MLPs -RRB-:method", "used for", "ANF-based and ON-based auditory features:other scientific term"], ["Gaussian mixture models -LRB- GMMs -RRB-:method", "used for", "ANF-based and ON-based auditory features:other scientific term"]], "pred": [["Multi-layer perceptrons -LRB- MLPs -RRB-:method", "used for", "ANF-based auditory features:other scientific term"], ["Multi-layer perceptrons -LRB- MLPs -RRB-:method", "used for", "ON-based auditory features:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "335": {"text": "It is demonstrated qualitatively and quantitatively on a dataset of scenes and is suitable for current work in unsupervised object discovery without top-down knowledge.", "true": [["It:generic", "used for", "unsupervised object discovery:task"]], "pred": [["dataset of scenes:material", "used for", "current work in unsupervised object discovery:task"], ["It:generic", "used for", "current work in unsupervised object discovery:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "336": {"text": "This paper deals with the problem of generating the fundamental frequency -LRB- F0 -RRB- contour of speech from a text input for text-to-speech synthesis.", "true": [["fundamental frequency -LRB- F0 -RRB- contour of speech:other scientific term", "used for", "text-to-speech synthesis:task"], ["text input:material", "used for", "fundamental frequency -LRB- F0 -RRB- contour of speech:other scientific term"]], "pred": [["problem:task", "used for", "text-to-speech synthesis:method"], ["speech:material", "used for", "text-to-speech synthesis:method"], ["text input:material", "used for", "text-to-speech synthesis:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "337": {"text": "The strong description and modeling properties of differential features make them useful tools that can be efficiently used as constraints for 3--D reconstruction.", "true": [["them:generic", "used for", "3--D reconstruction:task"]], "pred": [["differential features:other scientific term", "used for", "constraints:other scientific term"], ["differential features:other scientific term", "used for", "tools:generic"], ["differential features:other scientific term", "used for", "3--D reconstruction:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "338": {"text": "This paper presents an unsupervised learning approach to disambiguate various relations between named entities by use of various lexical and syntactic features from the contexts.", "true": [["unsupervised learning approach:method", "used for", "relations between named entities:other scientific term"], ["lexical and syntactic features:other scientific term", "used for", "unsupervised learning approach:method"]], "pred": [["unsupervised learning approach:method", "used for", "named entities:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "339": {"text": "Finally, we show how the estimation of the tensors from point correspondences is achieved through factorization, and discuss the estimation from line correspondences.", "true": [["point correspondences:other scientific term", "used for", "estimation of the tensors:task"], ["factorization:method", "used for", "tensors:generic"], ["line correspondences:other scientific term", "used for", "estimation:generic"]], "pred": [["estimation of the tensors:task", "used for", "factorization:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "340": {"text": "As far as we can do in the rule-based approach is to give a default rule to pick up a corresponding classifier of each noun.", "true": [], "pred": [["classifier:other scientific term", "used for", "noun:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "343": {"text": "Overall summarization quality of the proposed system is state-of-the-art, with guaranteed grammaticality of the system output due to the use of a constraint-based parser/generator.", "true": [["constraint-based parser/generator:method", "used for", "system:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "346": {"text": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing.", "true": [["features:other scientific term", "used for", "lexical similarity:other scientific term"], ["features:other scientific term", "used for", "question-answer pairing:task"], ["structure of email-threads:other scientific term", "used for", "features:other scientific term"]], "pred": [["features:other scientific term", "used for", "structure of email-threads:other scientific term"], ["question-answer pairing:task", "used for", "features:other scientific term"], ["features:other scientific term", "used for", "question-answer pairing:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"used for\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "347": {"text": "SVMs are known to be robust to overfitting; however, a few training examples usually do not represent well the structure of the class.", "true": [["SVMs:method", "used for", "overfitting:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "348": {"text": "Sentence boundary detection in speech is important for enriching speech recognition output, making it easier for humans to read and downstream modules to process.", "true": [["Sentence boundary detection:task", "used for", "speech recognition output:other scientific term"], ["speech:material", "used for", "Sentence boundary detection:task"]], "pred": [["sentence boundary detection:task", "used for", "speech recognition output:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "350": {"text": "We use novel priors, generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion.", "true": [["priors:other scientific term", "used for", "sparse and dense detection maps:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "352": {"text": "This paper describes FERRET, an interactive question-answering -LRB- Q/A -RRB- system designed to address the challenges of integrating automatic Q/A applications into real-world environments.", "true": [["FERRET:method", "used for", "integrating automatic Q/A applications into real-world environments:task"]], "pred": [["FERRET:method", "used for", "interactive question-answering -LRB- Q/A -RRB-:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "353": {"text": "In this paper, we introduce an annotation scheme for scientific articles which can be used to build such a resource in a consistent way.", "true": [["annotation scheme:method", "used for", "scientific articles:material"], ["annotation scheme:method", "used for", "resource:generic"]], "pred": [["annotation scheme:method", "used for", "resource:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "354": {"text": "These mistakes can lead to various kinds of misunderstandings between speaker and listener, including reference failures or failure to understand the speaker's intention.", "true": [], "pred": [["mistakes:other scientific term", "used for", "misunderstandings:other scientific term"], ["failure to understand the speaker's intention:task", "used for", "misunderstandings:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "355": {"text": "The distinction among these components is essential to provide an adequate explanation of such discourse phenomena as cue phrases, referring expressions, and interruptions.", "true": [], "pred": [["distinction:other scientific term", "used for", "discourse phenomena:other scientific term"], ["distinction:other scientific term", "used for", "adequate explanation:generic"], ["discourse phenomena:other scientific term", "used for", "adequate explanation:generic"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"used for\"  \n(32) \"none\"  \n(33) \"used for\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "356": {"text": "Coedition of a natural language text and its representation in some interlingual form seems the best and simplest way to share text revision across languages.", "true": [["Coedition:task", "used for", "text revision:other scientific term"], ["natural language text:material", "used for", "Coedition:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "357": {"text": "In the experiments, we used a variety of methods for preparing a segmented corpus and compared the language models by their speech recognition accuracies.", "true": [["methods:generic", "used for", "preparing a segmented corpus:task"]], "pred": [["variety of methods:method", "used for", "speech recognition accuracies:metric"], ["variety of methods:method", "used for", "experiments:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "358": {"text": "Metagrammatical formalisms that combine context-free phrase structure rules and metarules -LRB- MPS grammars -RRB- allow concise statement of generalizations about the syntax of natural languages.", "true": [], "pred": [["Metagrammatical formalisms:method", "used for", "generalizations about the syntax of natural languages:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n"}, "359": {"text": "We instead present a simple but effective algorithm to first map bilinear subspaces to line constraints and then apply Constrained Delaunay Triangulation -LRB- CDT -RRB-.", "true": [], "pred": [["algorithm:method", "used for", "Constrained Delaunay Triangulation -LRB- CDT -RRB-:method"], ["algorithm:method", "used for", "line constraints:other scientific term"], ["Constrained Delaunay Triangulation -LRB- CDT -RRB-:method", "used for", "line constraints:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "360": {"text": "We also found that OA is crucial for auditory processing by onset neurons -LRB- ONs -RRB- in the next neuronal stage, the auditory brainstem.", "true": [["OA:method", "used for", "auditory processing:task"], ["onset neurons -LRB- ONs -RRB-:other scientific term", "used for", "OA:method"]], "pred": [["auditory processing:task", "used for", "OA:other scientific term"], ["auditory processing:task", "used for", "onset neurons -LRB- ONs -RRB-:other scientific term"], ["auditory processing:task", "used for", "auditory brainstem:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "362": {"text": "We have previously introduced a statistical model describing the generating process of speech F0 contours, based on the discrete-time version of the Fujisaki model.", "true": [["statistical model:method", "used for", "speech F0 contours:other scientific term"], ["Fujisaki model:method", "used for", "statistical model:method"]], "pred": [["statistical model:method", "used for", "generating process of speech F0 contours:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"\n"}, "363": {"text": "We introduce a method to accelerate the evaluation of object detection cascades with the help of a divide-and-conquer procedure in the space of candidate regions.", "true": [["method:generic", "used for", "evaluation of object detection cascades:task"], ["divide-and-conquer procedure:method", "used for", "method:generic"]], "pred": [["method:generic", "used for", "object detection cascades:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "364": {"text": "Information distillation aims to extract relevant pieces of information related to a given query from massive, possibly multilingual, audio and textual document sources.", "true": [], "pred": [["information distillation:task", "used for", "relevant pieces of information:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "365": {"text": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese.", "true": [["approach:generic", "used for", "Multi-lingual Evaluation Task -LRB- MET -RRB-:task"], ["Multi-lingual Evaluation Task -LRB- MET -RRB-:task", "used for", "Japanese text:material"], ["morphological analysis problem:task", "used for", "task:generic"], ["Japanese:material", "used for", "morphological analysis problem:task"]], "pred": [["morphological analysis problem:task", "used for", "Japanese text:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "366": {"text": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns, and exhibit strong invariance to rotation, illumination variation, and blur.", "true": [["detectors:generic", "used for", "large-scale structures:other scientific term"], ["detectors:generic", "used for", "distinctive textured patterns:other scientific term"], ["detectors:generic", "used for", "rotation:other scientific term"], ["detectors:generic", "used for", "illumination variation:other scientific term"], ["detectors:generic", "used for", "blur:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "367": {"text": "This paper proposes a generic mathematical formalism for the combination of various structures: strings, trees, dags, graphs, and products of them.", "true": [], "pred": [["generic mathematical formalism:method", "used for", "various structures:other scientific term"], ["generic mathematical formalism:method", "used for", "products of them:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "368": {"text": "We consider the problem of computing the Kullback-Leibler distance, also called the relative entropy, between a probabilistic context-free grammar and a probabilistic finite automaton.", "true": [], "pred": [["computing:task", "used for", "Kullback-Leibler distance:other scientific term"], ["computing:task", "used for", "relative entropy:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"used for\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "370": {"text": "We evaluated the topic signatures on a WSD task, where we trained a second-order vector cooccurrence algorithm on standard WSD datasets, with promising results.", "true": [["WSD datasets:material", "used for", "second-order vector cooccurrence algorithm:method"]], "pred": [["second-order vector cooccurrence algorithm:method", "used for", "topic signatures:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "371": {"text": "Joint matrix triangularization is often used for estimating the joint eigenstructure of a set M of matrices, with applications in signal processing and machine learning.", "true": [["Joint matrix triangularization:task", "used for", "joint eigenstructure:other scientific term"], ["joint eigenstructure:other scientific term", "used for", "signal processing:task"], ["joint eigenstructure:other scientific term", "used for", "machine learning:task"]], "pred": [["signal processing:task", "used for", "joint matrix triangularization:method"], ["machine learning:task", "used for", "joint matrix triangularization:method"], ["joint matrix triangularization:method", "used for", "joint eigenstructure:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"used for\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "372": {"text": "However, acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction, active sensing devices and/or synthetic scenes.", "true": [["manual interaction:other scientific term", "used for", "task:generic"], ["active sensing devices:other scientific term", "used for", "task:generic"], ["synthetic scenes:other scientific term", "used for", "task:generic"]], "pred": [["training data:material", "used for", "tedious and time consuming task:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "374": {"text": "By employing a joint classification and regression optimization objective, this network is capable of automatically localizing the start and end points of actions more accurately.", "true": [["joint classification and regression optimization objective:other scientific term", "used for", "network:generic"]], "pred": [["start and end points of actions:task", "used for", "network:method"], ["joint classification and regression optimization objective:method", "used for", "start and end points of actions:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n"}, "375": {"text": "We train a maximum entropy classifier that, given a pair of sentences, can reliably determine whether or not they are translations of each other.", "true": [], "pred": [["pair of sentences:material", "used for", "translations:task"], ["maximum entropy classifier:method", "used for", "pair of sentences:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n"}, "376": {"text": "When a segment is found to be an NE item, this information is added to the segment and it is used to generate the final output.", "true": [], "pred": [["segment:other scientific term", "used for", "final output:other scientific term"], ["NE item:other scientific term", "used for", "final output:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "377": {"text": "Building on previous work at Carnegie-Mellon University e.g. -LSB- 4, 5, 8 -RSB-, Plume's approach to parsing is based on semantic caseframe instantiation.", "true": [["Plume's approach:method", "used for", "parsing:task"], ["semantic caseframe instantiation:other scientific term", "used for", "Plume's approach:method"]], "pred": [["Plume's approach to parsing:method", "used for", "semantic caseframe instantiation:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "379": {"text": "Given a new image, detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects.", "true": [["image:material", "used for", "detection:task"], ["image:material", "used for", "classification:task"], ["position:other scientific term", "used for", "detection:task"], ["position:other scientific term", "used for", "classification:task"], ["viewpoint:other scientific term", "used for", "detection:task"], ["viewpoint:other scientific term", "used for", "classification:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "380": {"text": "Using the IEMOCAP database, discrete -LRB- categorical -RRB- and continuous -LRB- attribute -RRB- emotional assessments evaluated by the actors and na \u00a8 \u0131ve listeners are compared.", "true": [["IEMOCAP database:material", "used for", "discrete -LRB- categorical -RRB- and continuous -LRB- attribute -RRB- emotional assessments:task"]], "pred": [["IEMOCAP database:material", "used for", "discrete -LRB- categorical -RRB- emotional assessments:other scientific term"], ["IEMOCAP database:material", "used for", "continuous -LRB- attribute -RRB- emotional assessments:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"used for\"  \n(22) \"used for\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "381": {"text": "A separation method is proposed that is nearly statistically efficient -LRB- approaching the corresponding Cram\u00e9r-Rao lower bound -RRB-, if the separated signals obey the assumed model.", "true": [], "pred": [["separation method:method", "used for", "separated signals:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "382": {"text": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision, and that it can handle many challenges of active reconstruction systems.", "true": [["method:generic", "used for", "scene geometry:other scientific term"], ["it:generic", "used for", "active reconstruction systems:task"]], "pred": [["our method:method", "used for", "scene geometry:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "383": {"text": "We believe that these evaluation techniques will provide information about both the human language learning process, the translation process and the development of machine translation systems.", "true": [["evaluation techniques:generic", "used for", "human language learning process:task"], ["evaluation techniques:generic", "used for", "translation process:task"], ["evaluation techniques:generic", "used for", "machine translation systems:task"]], "pred": [["translation process:task", "used for", "evaluation techniques:method"], ["development of machine translation systems:task", "used for", "evaluation techniques:method"], ["evaluation techniques:method", "used for", "information:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "384": {"text": "Hitherto, smooth motion has been encouraged using a trajectory basis, yielding a hard combinatorial problem with time complexity growing exponentially in the number of frames.", "true": [["trajectory basis:other scientific term", "used for", "smooth motion:other scientific term"]], "pred": [["trajectory basis:method", "used for", "smooth motion:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "385": {"text": "Given an object model and a black-box measure of similarity between the model and candidate targets, we consider visual object tracking as a numerical optimization problem.", "true": [["numerical optimization problem:task", "used for", "visual object tracking:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "386": {"text": "In order to perform an exhaustive comparison, we also evaluate a hand-crafted template-based generation component, two rule-based sentence planners, and two baseline sentence planners.", "true": [], "pred": [["exhaustive comparison:task", "used for", "hand-crafted template-based generation component:method"], ["exhaustive comparison:task", "used for", "rule-based sentence planners:method"], ["exhaustive comparison:task", "used for", "baseline sentence planners:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "387": {"text": "In this work, we study how Convolutional Neural Networks -LRB- CNN -RRB- architectures can be adapted to the task of simultaneous object recognition and pose estimation.", "true": [["Convolutional Neural Networks -LRB- CNN -RRB- architectures:method", "used for", "object recognition:task"], ["Convolutional Neural Networks -LRB- CNN -RRB- architectures:method", "used for", "pose estimation:task"]], "pred": [["Convolutional Neural Networks -LRB- CNN -RRB-:method", "used for", "task of simultaneous object recognition and pose estimation:task"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "388": {"text": "Based on our analysis, we further develop a novel line-assisted graph-cut -LRB- LAGC -RRB- algorithm that effectively encodes 3D line constraints into light field stereo matching.", "true": [], "pred": [["line-assisted graph-cut -LRB- LAGC -RRB-:method", "used for", "light field stereo matching:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"used for\"  \n"}, "389": {"text": "The description has been implemented using the PC-KIMMO environment -LRB- Antworth, 1990 -RRB- and is based on a root word lexicon of about 23,000 roots words.", "true": [["PC-KIMMO environment:method", "used for", "description:generic"], ["root word lexicon:material", "used for", "description:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "390": {"text": "To associate a sequence of the Fujisaki-model parameters with a text input based on statistical learning, this paper proposes extending this model to a context-dependent one.", "true": [["text input:material", "used for", "Fujisaki-model parameters:other scientific term"], ["statistical learning:method", "used for", "Fujisaki-model parameters:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "391": {"text": "Bayesian inference then samples the rules, disambiguating and combining them to create complex tree structures that maximize a discriminative model's posterior on a target unlabeled corpus.", "true": [["Bayesian inference:method", "used for", "rules:other scientific term"], ["them:generic", "used for", "complex tree structures:other scientific term"], ["complex tree structures:other scientific term", "used for", "discriminative model's posterior:other scientific term"], ["unlabeled corpus:material", "used for", "discriminative model's posterior:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "392": {"text": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms, such as rewriting systems, dependency grammars, TAG, HPSG and LFG.", "true": [["formalism:generic", "used for", "grammar formalisms:method"]], "pred": [["formalism:other scientific term", "used for", "grammar formalisms:other scientific term"], ["formalism:other scientific term", "used for", "rewriting systems:other scientific term"], ["formalism:other scientific term", "used for", "dependency grammars:other scientific term"], ["formalism:other scientific term", "used for", "TAG:other scientific term"], ["formalism:other scientific term", "used for", "HPSG:other scientific term"], ["formalism:other scientific term", "used for", "LFG:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"used for\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "393": {"text": "In comparison with previous works, in this paper it is assumed that the signals are not i.i.d. in each epoch, but obey a first-order autoregressive model.", "true": [["first-order autoregressive model:method", "used for", "signals:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "394": {"text": "We explored possible ways to obtain a compact lexicon, consistent with CCG principles, from a treebank which is an order of magnitude smaller than Penn WSJ.", "true": [], "pred": [["treebank:material", "used for", "compact lexicon:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "395": {"text": "In this paper, a novel framework for machine transliteration/backtransliteration that allows us to carry out direct orthographical mapping -LRB- DOM -RRB- between two different languages is presented.", "true": [["framework:generic", "used for", "machine transliteration/backtransliteration:task"], ["machine transliteration/backtransliteration:task", "used for", "direct orthographical mapping -LRB- DOM -RRB-:method"]], "pred": [["novel framework:method", "used for", "direct orthographical mapping -LRB- DOM -RRB-:method"], ["machine transliteration/backtransliteration:task", "used for", "direct orthographical mapping -LRB- DOM -RRB-:method"], ["novel framework:method", "used for", "machine transliteration/backtransliteration:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n"}, "396": {"text": "Under this framework, a joint source-channel transliteration model, also called n-gram transliteration model -LRB- n-gram TM -RRB-, is further proposed to model the transliteration process.", "true": [["framework:generic", "used for", "joint source-channel transliteration model:method"], ["n-gram transliteration model -LRB- n-gram TM -RRB-:method", "used for", "transliteration process:method"]], "pred": [["transliteration process:task", "used for", "joint source-channel transliteration model:method"], ["joint source-channel transliteration model:method", "used for", "transliteration process:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n"}, "398": {"text": "In the second half of the paper, we report a laboratory study using the Wizard of Oz technique to identify NL requirements for carrying out this task.", "true": [["Wizard of Oz technique:method", "used for", "NL requirements:other scientific term"], ["Wizard of Oz technique:method", "used for", "task:generic"]], "pred": [["carrying out this task:task", "used for", "laboratory study:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "401": {"text": "Experiments on the TREC Blog track test set show that both groups of credibility indicators significantly improve retrieval effectiveness; the best performance is achieved when combining them.", "true": [], "pred": [["credibility indicators:other scientific term", "used for", "retrieval effectiveness:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "402": {"text": "Topic signatures can be useful in a number of Natural Language Processing -LRB- NLP -RRB- applications, such as Word Sense Disambiguation -LRB- WSD -RRB- and Text Summarisation.", "true": [["Topic signatures:other scientific term", "used for", "Natural Language Processing -LRB- NLP -RRB- applications:task"], ["Topic signatures:other scientific term", "used for", "Word Sense Disambiguation -LRB- WSD -RRB-:task"], ["Topic signatures:other scientific term", "used for", "Text Summarisation:task"]], "pred": [["topic signatures:other scientific term", "used for", "Natural Language Processing -LRB- NLP -RRB-:other scientific term"], ["topic signatures:other scientific term", "used for", "applications:generic"], ["Natural Language Processing -LRB- NLP -RRB-:other scientific term", "used for", "applications:generic"], ["topic signatures:other scientific term", "used for", "Word Sense Disambiguation -LRB- WSD -RRB-:task"], ["topic signatures:other scientific term", "used for", "Text Summarisation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"used for\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "403": {"text": "The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm.", "true": [["view points:other scientific term", "used for", "approach:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "404": {"text": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge.", "true": [["method:method", "used for", "shape constrained image segmentation:task"], ["mixtures of feature distributions:other scientific term", "used for", "method:method"], ["mixtures of feature distributions:other scientific term", "used for", "color:other scientific term"], ["mixtures of feature distributions:other scientific term", "used for", "texture:other scientific term"], ["mixtures of feature distributions:other scientific term", "used for", "probabilistic shape knowledge:other scientific term"]], "pred": [["mixtures of feature distributions:method", "used for", "color:other scientific term"], ["mixtures of feature distributions:method", "used for", "texture:other scientific term"], ["shape constrained image segmentation:task", "used for", "color:other scientific term"], ["shape constrained image segmentation:task", "used for", "texture:other scientific term"], ["shape constrained image segmentation:task", "used for", "probabilistic shape knowledge:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"used for\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "405": {"text": "Extended CF grammars -LRB- grammars with regular expressions at the right hand side -RRB- can be parsed with a simple modification of the LR-parser for normal CF grammars.", "true": [["LR-parser:method", "used for", "Extended CF grammars:method"], ["LR-parser:method", "used for", "CF grammars:method"]], "pred": [["LR-parser:method", "used for", "grammars with regular expressions:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "406": {"text": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features.", "true": [["Kernel space embedding:other scientific term", "used for", "inarbitrary distance measures:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "407": {"text": "In this paper, we propose to concentrate on correcting the positions in which the words in the list appear by taking a word as a correction unit.", "true": [], "pred": [["correcting the positions:task", "used for", "words in the list:material"], ["words in the list:material", "used for", "correcting the positions:task"], ["this paper:generic", "used for", "correcting the positions:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "408": {"text": "In this paper, we propose a novel moderate positive sample mining method to train robust CNN for person re-identification, dealing with the problem of large variation.", "true": [["moderate positive sample mining method:method", "used for", "robust CNN:method"], ["robust CNN:method", "used for", "person re-identification:task"]], "pred": [["person re-identification:task", "used for", "novel moderate positive sample mining method:method"], ["person re-identification:task", "used for", "robust CNN:method"], ["novel moderate positive sample mining method:method", "used for", "person re-identification:task"], ["robust CNN:method", "used for", "person re-identification:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"used for\"  \n"}, "409": {"text": "We propose a novel step toward the unsupervised seg-mentation of whole objects by combining\" hints\" of partial scene segmentation offered by multiple soft, binary mattes.", "true": [["partial scene segmentation:task", "used for", "unsupervised seg-mentation of whole objects:task"], ["soft, binary mattes:other scientific term", "used for", "partial scene segmentation:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "412": {"text": "We show how this can efficiently be combined with random-projection based methods for 2 NN search, such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees.", "true": [["random-projection based methods:method", "used for", "NN search:task"]], "pred": [["2 NN search:task", "used for", "random-projection based methods:method"], ["random-projection based methods:method", "used for", "2 NN search:task"], ["locality-sensitive hashing -LRB- LSH -RRB-:method", "used for", "2 NN search:task"], ["random projection trees:method", "used for", "2 NN search:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"used for\"  \n(12) \"used for\"  \n"}, "413": {"text": "Second, based on the information resulting from the dictionary lookup stage, a set of rules is applied to the segmented strings in order to identify NE items.", "true": [["dictionary lookup stage:method", "used for", "rules:other scientific term"], ["rules:other scientific term", "used for", "NE items:other scientific term"]], "pred": [["set of rules:method", "used for", "NE items:other scientific term"], ["dictionary lookup stage:method", "used for", "information:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "414": {"text": "We explain this distinction and we show how this model may be applied to the interpretation of compounds in real texts, provided that complementary semantic information are retrieved.", "true": [["model:generic", "used for", "interpretation of compounds:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "415": {"text": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives, relative clauses, and interrogatives in a general manner.", "true": [["Plume:method", "used for", "passives:other scientific term"], ["Plume:method", "used for", "relative clauses:other scientific term"], ["Plume:method", "used for", "interrogatives:other scientific term"]], "pred": [["this paper:generic", "used for", "detailed design:generic"], ["Plume:method", "used for", "passives:other scientific term"], ["Plume:method", "used for", "relative clauses:other scientific term"], ["Plume:method", "used for", "interrogatives:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"used for\"  \n(15) \"used for\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "416": {"text": "Our system incorporates a linguistic parser/generator for LFG, a transfer component for parse reduction operating on packed parse forests, and a maximum-entropy model for stochastic output selection.", "true": [["linguistic parser/generator:method", "used for", "LFG:method"], ["transfer component:method", "used for", "parse reduction:task"], ["packed parse forests:other scientific term", "used for", "parse reduction:task"], ["maximum-entropy model:method", "used for", "stochastic output selection:task"]], "pred": [["linguistic parser/generator for LFG:method", "used for", "system:generic"], ["transfer component for parse reduction:method", "used for", "system:generic"], ["maximum-entropy model:method", "used for", "system:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"used for\"  \n(17) \"used for\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "417": {"text": "Thus, in this paper, we study the problem of robust PCA with side information, where both prior structure and features of entities are exploited for recovery.", "true": [["side information:other scientific term", "used for", "robust PCA:method"], ["prior structure:other scientific term", "used for", "recovery:task"], ["features of entities:other scientific term", "used for", "recovery:task"]], "pred": [["side information:other scientific term", "used for", "robust PCA:task"], ["prior structure:other scientific term", "used for", "robust PCA:task"], ["features of entities:other scientific term", "used for", "robust PCA:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"used for\"  \n(17) \"used for\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "419": {"text": "The system incorporates a decision-tree classifier for 30 scf types which tests for the presence of grammatical relations -LRB- grs -RRB- in the output of a robust statistical parser.", "true": [["decision-tree classifier:method", "used for", "grammatical relations -LRB- grs -RRB-:other scientific term"]], "pred": [["decision-tree classifier:method", "used for", "output of a robust statistical parser:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "420": {"text": "A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition.", "true": [["tool:generic", "used for", "linguistic annotation of scfs:task"], ["training and test data:material", "used for", "subcategorization acquisition:task"]], "pred": [["tool:method", "used for", "linguistic annotation:method"], ["subcategorization acquisition:task", "used for", "linguistic annotation:method"], ["training and test data:material", "used for", "subcategorization acquisition:task"], ["tool:method", "used for", "subcategorization acquisition:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"used for\"  \n(30) \"none\"  \n"}, "421": {"text": "This model mimics the way in which images are processed in the visual pathway, rendering a feasible alternative for the implementation of early vision applications in standard technologies.", "true": [["visual pathway:method", "used for", "images:material"]], "pred": [["early vision applications:task", "used for", "visual pathway:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "422": {"text": "In this paper, we evaluate the use of a conditional random field -LRB- CRF -RRB- for this task and relate results with this model to our prior work.", "true": [["conditional random field -LRB- CRF -RRB-:method", "used for", "task:generic"]], "pred": [["this model:generic", "used for", "task:generic"], ["conditional random field -LRB- CRF -RRB-:method", "used for", "task:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "424": {"text": "Online action detection goes one step further and is more challenging, which identifies the action type and localizes the action positions on the fly from the untrimmed stream.", "true": [["Online action detection:task", "used for", "action type:other scientific term"], ["Online action detection:task", "used for", "action positions:other scientific term"], ["untrimmed stream:material", "used for", "Online action detection:task"]], "pred": [["online action detection:task", "used for", "action positions:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "425": {"text": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU, NIST, WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment.", "true": [["MT evaluation methods:metric", "used for", "classifiers:method"], ["classifiers:method", "used for", "semantic equivalence:task"], ["classifiers:method", "used for", "entailment:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "426": {"text": "We also introduce a novel classification method based on PER which leverages part of speech information of the words contributing to the word matches and non-matches in the sentence.", "true": [["PER:metric", "used for", "classification method:method"], ["PER:metric", "used for", "part of speech information:other scientific term"], ["part of speech information:other scientific term", "used for", "word matches and non-matches:task"]], "pred": [["classification method:method", "used for", "PER:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "428": {"text": "For example, nucleotides in a DNA sequence, children's names in a given state and year, and text documents are all commonly modeled with multinomial distributions.", "true": [["multinomial distributions:method", "used for", "nucleotides in a DNA sequence:material"], ["multinomial distributions:method", "used for", "text documents:material"]], "pred": [["nucleotides in a DNA sequence:material", "used for", "multinomial distributions:other scientific term"], ["children's names in a given state and year:material", "used for", "multinomial distributions:other scientific term"], ["text documents:material", "used for", "multinomial distributions:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "429": {"text": "Based on this, MINPRAN uses random sampling to search for the t and the number of inliers to the t that are least likely to have occurred randomly.", "true": [["random sampling:method", "used for", "MINPRAN:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "430": {"text": "We take advantage of the fact that some of the distillation queries can be associated with annotation elements introduced for the NIST Automatic Content Extraction -LRB- ACE -RRB- task.", "true": [], "pred": [["NIST Automatic Content Extraction -LRB- ACE -RRB-:task", "used for", "task:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "431": {"text": "While Plume is well adapted to simple declarative and imperative utterances, it handles passives, relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage.", "true": [["Plume:method", "used for", "declarative and imperative utterances:material"], ["it:generic", "used for", "passives:other scientific term"], ["it:generic", "used for", "relative clauses:other scientific term"], ["it:generic", "used for", "interrogatives:other scientific term"]], "pred": [["Plume:method", "used for", "simple declarative and imperative utterances:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"used for\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "432": {"text": "In addition to the high accuracy of the model, the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results.", "true": [["smoothing:method", "used for", "unlexicalized parser:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "433": {"text": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions.", "true": [["convex problem:task", "used for", "side information:other scientific term"], ["method:generic", "used for", "low rank matrix:other scientific term"]], "pred": [["proposed method:method", "used for", "robust PCA:method"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "434": {"text": "Evaluation on the ACE 2003 corpus shows that the convolution kernel over parse trees can achieve comparable performance with the previous best-reported feature-based methods on the 24 ACE relation subtypes.", "true": [], "pred": [["convolution kernel over parse trees:method", "used for", "24 ACE relation subtypes:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "437": {"text": "For LR -LRB- 0 -RRB- grammars, our algorithm is closely related to the recursive ascent parsers recently discovered by Kruse-man Aretz -LSB- 1 -RSB- and Roberts -LSB- 2 -RSB-.", "true": [["algorithm:generic", "used for", "LR -LRB- 0 -RRB- grammars:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "438": {"text": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB's binding theory, while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model.", "true": [["Criteria:generic", "used for", "anaphora resolution within sentence boundaries:task"], ["GB's binding theory:method", "used for", "Criteria:generic"], ["those:generic", "used for", "text-level anaphora:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "442": {"text": "b -RRB- The UV procedure is based on three different confidence tests, two based on acoustic measures and one founded on linguistic information, applied in a hierarchical structure.", "true": [["confidence tests:method", "used for", "UV procedure:method"], ["confidence tests:method", "used for", "hierarchical structure:other scientific term"], ["acoustic measures:metric", "used for", "two:generic"], ["linguistic information:other scientific term", "used for", "one:generic"]], "pred": [["UV procedure:method", "used for", "three different confidence tests:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "443": {"text": "It works by calculating eigenvectors of an adjacency graph's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors.", "true": [["It:generic", "used for", "submanifold:other scientific term"], ["eigenvectors:other scientific term", "used for", "It:generic"], ["high dimensionality space:other scientific term", "used for", "submanifold:other scientific term"], ["cluster number estimation:task", "used for", "It:generic"], ["cluster number estimation:task", "used for", "eigenvectors:other scientific term"]], "pred": [["cluster number estimation:task", "used for", "eigenvectors:other scientific term"], ["It:generic", "used for", "cluster number estimation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"used for\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "444": {"text": "We test our algorithm on the detection task and the viewpoint classification task by using\" car\" category from both the Savarese et al. 2007 and PASCAL VOC 2006 datasets.", "true": [["algorithm:generic", "used for", "detection task:task"], ["algorithm:generic", "used for", "viewpoint classification task:task"]], "pred": [["detection task:task", "used for", "algorithm:method"], ["viewpoint classification task:task", "used for", "algorithm:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "445": {"text": "In particular, our guarantee suggests that a substantial amount of low rank matrices, which cannot be recovered by standard robust PCA, become re-coverable by our proposed method.", "true": [["method:generic", "used for", "low rank matrices:other scientific term"]], "pred": [["our proposed method:method", "used for", "low rank matrices:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "447": {"text": "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel.", "true": [["syntactic structure features:other scientific term", "used for", "relation extraction:task"], ["convolution tree kernel:method", "used for", "features:generic"]], "pred": [["relation extraction:task", "used for", "syntactic structure features:other scientific term"], ["syntactic structure features:other scientific term", "used for", "relation extraction:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "448": {"text": "In previous work, we have developed hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers that integrate textual and prosodic knowledge sources for detecting sentence boundaries.", "true": [["hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers:method", "used for", "detecting sentence boundaries:task"], ["textual and prosodic knowledge sources:material", "used for", "hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers:method"]], "pred": [["detecting sentence boundaries:task", "used for", "hidden Markov model -LRB- HMM -RRB-:method"], ["detecting sentence boundaries:task", "used for", "maximum entropy -LRB- Maxent -RRB- classifiers:method"], ["textual and prosodic knowledge sources:other scientific term", "used for", "detecting sentence boundaries:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "450": {"text": "Although hidden Markov models -LRB- HMMs -RRB- provide a suitable generative model for field structured text, general unsupervised HMM learning fails to learn useful structure in either of our domains.", "true": [["hidden Markov models -LRB- HMMs -RRB-:method", "used for", "generative model:method"], ["generative model:method", "used for", "field structured text:material"]], "pred": [["generative model:other scientific term", "used for", "field structured text:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "451": {"text": "We also show that a good-quality MT system can be built from scratch by starting with a very small parallel corpus -LRB- 100,000 words -RRB- and exploiting a large non-parallel corpus.", "true": [["parallel corpus:material", "used for", "MT system:method"], ["non-parallel corpus:material", "used for", "MT system:method"]], "pred": [["large non-parallel corpus:material", "used for", "good-quality MT system:method"], ["good-quality MT system:method", "used for", "large non-parallel corpus:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "452": {"text": "For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions, i.e. functions that memorize the results of previous invocations.", "true": [["parser:method", "used for", "non-LR grammars:method"], ["memo-functions:method", "used for", "parser:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "453": {"text": "The resultant bilingual corpus, 10.4 M English words and 18.3 M Chinese characters, is an authoritative and comprehensive text collection covering the specific and special domain of HK laws.", "true": [], "pred": [["bilingual corpus:material", "used for", "specific and special domain of HK laws:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "454": {"text": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours.", "true": [["algorithm:generic", "used for", "Fujisaki-model parameters:other scientific term"], ["statistical methods:method", "used for", "algorithm:generic"], ["raw F0 contours:other scientific term", "used for", "Fujisaki-model parameters:other scientific term"]], "pred": [["model:method", "used for", "Fujisaki-model parameters:other scientific term"], ["efficient algorithm:method", "used for", "Fujisaki-model parameters:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "455": {"text": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation, the proposed method requires fewer evaluations of the classifier functions, thereby speeding up the search.", "true": [["exhaustive procedure:method", "used for", "cascade evaluation:task"], ["method:generic", "used for", "search:task"]], "pred": [["search:task", "used for", "proposed method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "456": {"text": "In addition, we conduct synthetic experiments as well as a real application on noisy image classification to show that our method also improves the performance in practice by exploiting side information.", "true": [["side information:other scientific term", "used for", "method:generic"]], "pred": [["synthetic experiments:task", "used for", "our method:method"], ["real application:task", "used for", "our method:method"], ["noisy image classification:task", "used for", "our method:method"], ["our method:method", "used for", "performance:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"used for\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "457": {"text": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB-, based on studies on the vertebrate retina, has permitted the realization of complex programmable spatio-temporal dynamics in VLSI.", "true": [["bio-inspired model:method", "used for", "analog programmable array processor -LRB- APAP -RRB-:task"], ["bio-inspired model:method", "used for", "complex programmable spatio-temporal dynamics:other scientific term"], ["vertebrate retina:other scientific term", "used for", "bio-inspired model:method"]], "pred": [["bio-inspired model:method", "used for", "complex programmable spatio-temporal dynamics:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "458": {"text": "In this paper we propose a logical formalism, which, among other things, is suitable for representing determiners without forcing a particular interpretation when their meaning is still not clear.", "true": [["logical formalism:method", "used for", "determiners:task"]], "pred": [["logical formalism:method", "used for", "determiners:other scientific term"], ["logical formalism:method", "used for", "interpretation:other scientific term"], ["logical formalism:method", "used for", "meaning:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "459": {"text": "We investigate the verbal and nonverbal means for grounding, and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction.", "true": [["verbal and nonverbal means:method", "used for", "grounding:task"], ["design:generic", "used for", "embodied conversational agents:method"], ["common ground:task", "used for", "human-computer interaction:task"]], "pred": [["human-computer interaction:task", "used for", "design for embodied conversational agents:method"], ["verbal and nonverbal means:other scientific term", "used for", "grounding:other scientific term"], ["design for embodied conversational agents:method", "used for", "grounding:other scientific term"], ["design for embodied conversational agents:method", "used for", "common ground:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "460": {"text": "The new criterion--meaning-entailing substitutability--fits the needs of semantic-oriented NLP applications and can be evaluated directly -LRB- independent of an application -RRB- at a good level of human agreement.", "true": [["meaning-entailing substitutability:metric", "used for", "semantic-oriented NLP applications:task"]], "pred": [["criterion:other scientific term", "used for", "meaning-entailing substitutability:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "461": {"text": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results, proposing an objective measure for evaluating feature vector quality.", "true": [["distributional word feature vectors:other scientific term", "used for", "word similarity:task"]], "pred": [["distributional word feature vectors:material", "used for", "evaluating feature vector quality:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"used for\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "465": {"text": "Owing to these variations, the pedestrian data is distributed as highly-curved manifolds in the feature space, despite the current convolutional neural networks -LRB- CNN -RRB-'s capability of feature extraction.", "true": [["highly-curved manifolds:method", "used for", "pedestrian data:material"], ["convolutional neural networks -LRB- CNN -RRB-:method", "used for", "feature extraction:other scientific term"]], "pred": [["convolutional neural networks -LRB- CNN -RRB-:method", "used for", "capability of feature extraction:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "466": {"text": "We experimentally show that using the ACE events to constrain the document set returned by an information retrieval engine significantly improves the precision at various recall rates for two different query templates.", "true": [], "pred": [["ACE events:material", "used for", "information retrieval engine:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "467": {"text": "Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB-.", "true": [["morphological analysis:task", "used for", "Japanese text processing:task"]], "pred": [["morphological analysis:task", "used for", "Japanese text:material"], ["morphological analysis:task", "used for", "Japanese text processing:task"], ["Japanese text:material", "used for", "morphological analysis:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "468": {"text": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes, in terms of repeatability and distinctiveness.", "true": [["histogram-based interest point detectors:method", "used for", "matching textured scenes:task"]], "pred": [["matching textured scenes:task", "used for", "histogram-based interest point detectors:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "469": {"text": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination, pose and head motion variation.", "true": [["method:generic", "used for", "fully automatic recognition system:method"]], "pred": [["fully automatic recognition system:method", "used for", "proposed method:method"], ["proposed method:method", "used for", "fully automatic recognition system:method"], ["evaluation:task", "used for", "fully automatic recognition system:method"], ["fully automatic recognition system:method", "used for", "evaluation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"used for\"  \n(56) \"none\"  \n"}, "471": {"text": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them.", "true": [], "pred": [["nine standard person re-identification datasets:material", "used for", "new method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "472": {"text": "A statistical translation model is also presented that deals such phrases, as well as a training method based on the maximization of translation accuracy, as measured with the NIST evaluation metric.", "true": [["statistical translation model:method", "used for", "phrases:generic"], ["maximization of translation accuracy:metric", "used for", "training method:method"]], "pred": [["maximization of translation accuracy:task", "used for", "statistical translation model:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "473": {"text": "On the other hand, the manifold learning methods suggest to use the Euclidean distance in the local range, combining with the graphical relationship between samples, for approximating the geodesic distance.", "true": [["Euclidean distance:other scientific term", "used for", "manifold learning methods:method"], ["Euclidean distance:other scientific term", "used for", "geodesic distance:other scientific term"], ["graphical relationship:other scientific term", "used for", "geodesic distance:other scientific term"]], "pred": [["Euclidean distance:other scientific term", "used for", "geodesic distance:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "474": {"text": "Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification, and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification.", "true": [["robust deep metrics:other scientific term", "used for", "person re-identification:task"], ["deep model:method", "used for", "person re-identification:task"], ["state-of-the-art methods:generic", "used for", "person re-identification:task"]], "pred": [["person re-identification:task", "used for", "deep model:method"], ["deep model:method", "used for", "robust deep metrics:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"used for\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "475": {"text": "Our morphological analyzer has done all the necessary work for the recognition and classification of proper names, numerical and temporal expressions, i.e. Named Entity -LRB- NE -RRB- items in the Japanese text.", "true": [["morphological analyzer:method", "used for", "recognition and classification of proper names, numerical and temporal expressions:task"]], "pred": [["morphological analyzer:method", "used for", "Named Entity -LRB- NE -RRB-:other scientific term"], ["recognition and classification:task", "used for", "Named Entity -LRB- NE -RRB-:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"used for\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "477": {"text": "In this paper we specialize the projective unifocal, bifo-cal, and trifocal tensors to the affine case, and show how the tensors obtained relate to the registered tensors encountered in previous work.", "true": [["projective unifocal, bifo-cal, and trifocal tensors:method", "used for", "affine case:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "478": {"text": "While previous approaches relied on geometric, appearance, or correlation-based information for establishing correspondences between static cameras, they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras.", "true": [["geometric, appearance, or correlation-based information:other scientific term", "used for", "approaches:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}, "479": {"text": "Towards this goal, we also propose a novel Multiple Instance Learning -LRB- MIL -RRB- formulation for the problem based on the logistic softmax function of covariance-based region features within a MAP estimation framework.", "true": [["logistic softmax function of covariance-based region features:other scientific term", "used for", "Multiple Instance Learning -LRB- MIL -RRB- formulation:method"], ["MAP estimation framework:method", "used for", "Multiple Instance Learning -LRB- MIL -RRB- formulation:method"]], "pred": [["logistic softmax function:other scientific term", "used for", "problem:generic"], ["Multiple Instance Learning -LRB- MIL -RRB-:method", "used for", "problem:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "480": {"text": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7% on all three databases -RRB-, significantly out-performing state-of-the-art commercial software and methods from the literature.", "true": [], "pred": [["system:generic", "used for", "challenging data set:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "481": {"text": "The system is trained on 181,000 expert games and shows excellent prediction performance as indicated by its ability to perfectly predict the moves made by professional Go players in 34% of test positions.", "true": [["expert games:material", "used for", "system:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "482": {"text": "In this situation, the general method is to segment the raw corpus automatically using a word list, correct the output sentences by hand, and build a model from the segmented corpus.", "true": [["method:generic", "used for", "raw corpus:material"], ["word list:other scientific term", "used for", "method:generic"], ["segmented corpus:material", "used for", "model:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "483": {"text": "In this model, on-line handwriting is considered as a modulation of a simple cycloidal pen motion, described by two coupled oscillations with a constant linear drift along the line of the writing.", "true": [["model:generic", "used for", "on-line handwriting:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "484": {"text": "Using these ideas together, the resulting tagger gives a 97.24% accuracy on the Penn Treebank WSJ, an error reduction of 4.4% on the best previous single automatically learned tagging result.", "true": [], "pred": [["tagger:method", "used for", "best previous single automatically learned tagging result:other scientific term"], ["tagger:method", "used for", "97.24% accuracy:metric"], ["tagger:method", "used for", "error reduction of 4.4%:metric"], ["tagger:method", "used for", "Penn Treebank WSJ:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"used for\"  \n(20) \"none\"  \n"}, "485": {"text": "In this paper, we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2, higher than previously reported results on the NEGRA corpus.", "true": [["unlexicalized parser:method", "used for", "German:material"], ["smoothing:method", "used for", "unlexicalized parser:method"], ["suffix analysis:method", "used for", "unlexicalized parser:method"]], "pred": [["unlexicalized parser:method", "used for", "labelled bracket F-score:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "486": {"text": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese, and also exploits the large amount of Chinese text available in corpora and on the Web.", "true": [], "pred": [["word senses:other scientific term", "used for", "method:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"used for\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "487": {"text": "We demonstrate that for certain field structured extraction tasks, such as classified advertisements and bibliographic citations, small amounts of prior knowledge can be used to learn effective models in a primarily unsupervised fashion.", "true": [["prior knowledge:other scientific term", "used for", "field structured extraction tasks:task"]], "pred": [["field structured extraction tasks:task", "used for", "effective models:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "488": {"text": "Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm.", "true": [["technique:generic", "used for", "search algorithm:method"]], "pred": [["novel technique:method", "used for", "efficient search algorithm:method"], ["traveling salesman problem:task", "used for", "DP-based solution:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "491": {"text": "From this point of view, selecting suitable positive -LRB- i.e. intra-class -RRB- training samples within a local range is critical for training the CNN embedding, especially when the data has large intra-class variations.", "true": [], "pred": [["training the CNN embedding:task", "used for", "suitable positive -LRB- i.e. intra-class -RRB- training samples:material"], ["training the CNN embedding:task", "used for", "local range:other scientific term"], ["local range:other scientific term", "used for", "training the CNN embedding:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"used for\"  \n(20) \"none\"  \n"}, "492": {"text": "We propose to incorporate a priori geometric constraints in a 3--D stereo reconstruction scheme to cope with the many cases where image information alone is not sufficient to accurately recover 3--D shape.", "true": [["image information:other scientific term", "used for", "3--D shape:other scientific term"]], "pred": [["a priori geometric constraints:other scientific term", "used for", "3--D shape:other scientific term"], ["3--D stereo reconstruction scheme:method", "used for", "image information:other scientific term"], ["3--D stereo reconstruction scheme:method", "used for", "3--D shape:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "494": {"text": "We propose a corpus-based method -LRB- Biber,1993; Nagao,1993; Smadja,1993 -RRB- which generates Noun Classifier Associations -LRB- NCA -RRB- to overcome the problems in classifier assignment and semantic construction of noun phrase.", "true": [["corpus-based method:method", "used for", "Noun Classifier Associations -LRB- NCA -RRB-:method"], ["corpus-based method:method", "used for", "classifier assignment:task"], ["corpus-based method:method", "used for", "semantic construction of noun phrase:task"], ["Noun Classifier Associations -LRB- NCA -RRB-:method", "used for", "classifier assignment:task"], ["Noun Classifier Associations -LRB- NCA -RRB-:method", "used for", "semantic construction of noun phrase:task"]], "pred": [["corpus-based method:method", "used for", "Noun Classifier Associations -LRB- NCA -RRB-:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "495": {"text": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings, word-to-word alignments from an MT system, and syntactic structure from parse-trees of source and target language sentences.", "true": [["linguistic information:other scientific term", "used for", "loss functions:other scientific term"], ["word-to-word alignments:other scientific term", "used for", "loss functions:other scientific term"], ["syntactic structure:other scientific term", "used for", "loss functions:other scientific term"]], "pred": [["hierarchy of loss functions:method", "used for", "linguistic information:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "496": {"text": "The purpose of this research is to test the efficacy of applying automated evaluation techniques, originally devised for the evaluation of human language learners, to the output of machine translation -LRB- MT -RRB- systems.", "true": [["automated evaluation techniques:method", "used for", "evaluation of human language learners:task"]], "pred": [["automated evaluation techniques:method", "used for", "human language learners:other scientific term"], ["automated evaluation techniques:method", "used for", "efficacy:metric"], ["automated evaluation techniques:method", "used for", "research:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "498": {"text": "Inspired by recent work which reconstructs general trajectories using compact high-pass filters, we develop a dynamic programming approach which scales linearly in the number of frames, leveraging the intrinsically local nature of filter interactions.", "true": [], "pred": [["dynamic programming approach:method", "used for", "general trajectories:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "499": {"text": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently.", "true": [["regularizer:method", "used for", "low-rank matrix optimization:task"], ["regularizer:method", "used for", "or-thonormality:other scientific term"]], "pred": [["new type of regularizer:method", "used for", "matrix rank degeneration:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"used for\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "500": {"text": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech, out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present.", "true": [], "pred": [["Utterance Verification -LRB- UV -RRB-:task", "used for", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"], ["Utterance Verification -LRB- UV -RRB-:task", "used for", "spontaneous speech:other scientific term"], ["Utterance Verification -LRB- UV -RRB-:task", "used for", "out-of-vocabulary -LRB- OOV -RRB- words:other scientific term"], ["Utterance Verification -LRB- UV -RRB-:task", "used for", "acoustic noises:other scientific term"], ["Automatic Speech Recognition -LRB- ASR -RRB- System:method", "used for", "real applications:generic"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"used for\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"used for\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "501": {"text": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications, where the goal is to decompose the data matrix to a low rank part plus a sparse residual.", "true": [["robust principal component analysis -LRB- robust PCA -RRB- problem:method", "used for", "machine learning applications:task"]], "pred": [["machine learning applications:task", "used for", "robust principal component analysis -LRB- robust PCA -RRB-:other scientific term"], ["data matrix:material", "used for", "robust principal component analysis -LRB- robust PCA -RRB-:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"used for\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "502": {"text": "We identify three important requirements which arose from the task that we gave our subjects: operators specific to the task of database access, complex contextual reference and reference to the structure of the information source.", "true": [], "pred": [["three important requirements:other scientific term", "used for", "task:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "504": {"text": "During normal tracking conditions when the object is visible from frame to frame, local optimization is used to track the local mode of the similarity measure in a parameter space of translation, rotation and scale.", "true": [["local optimization:method", "used for", "local mode of the similarity measure:other scientific term"], ["parameter space of translation, rotation and scale:other scientific term", "used for", "local mode of the similarity measure:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "505": {"text": "Techniques for automatically training modules of a natural language generator have recently been proposed, but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches.", "true": [["Techniques:generic", "used for", "automatically training modules:method"]], "pred": [["techniques:method", "used for", "natural language generator:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "506": {"text": "In this paper we present a new UV procedure with two major features: a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises.", "true": [["Confidence tests:method", "used for", "decoded string hypotheses:other scientific term"]], "pred": [["UV procedure:method", "used for", "decoded string hypotheses:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "507": {"text": "This reflects contemporary methods for unsupervised object discovery from groups of images, and it allows us to define intuitive evaluation met-rics for our sets of segmentations based on the accurate and parsimonious delineation of scene objects.", "true": [["contemporary methods:generic", "used for", "unsupervised object discovery:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "508": {"text": "Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples, and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples.", "true": [], "pred": [["experiments on real data sets:task", "used for", "detector:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "509": {"text": "These methods diier from previous work in the area in two ways: the use of an action model formalism which is better suited to the needs of a re-active agent, and successful implementation of noise-handling mechanisms.", "true": [["action model formalism:method", "used for", "methods:metric"], ["action model formalism:method", "used for", "re-active agent:method"], ["noise-handling mechanisms:method", "used for", "methods:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "510": {"text": "In this paper we present our recent work on harvesting English-Chinese bitexts of the laws of Hong Kong from the Web and aligning them to the subparagraph level via utilizing the numbering system in the legal text hierarchy.", "true": [], "pred": [["English-Chinese bitexts:material", "used for", "laws of Hong Kong:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "511": {"text": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax, for instance, to the task of semantic interpretation or automatic translation of natural language.", "true": [["TAGs:method", "used for", "semantic interpretation:task"], ["TAGs:method", "used for", "automatic translation of natural language:task"]], "pred": [["application of TAGs:task", "used for", "semantic interpretation:task"], ["application of TAGs:task", "used for", "automatic translation of natural language:task"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "512": {"text": "Towards deep analysis of compositional classes of paraphrases, we have examined a class-oriented framework for collecting paraphrase examples, in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement.", "true": [["class-oriented framework:method", "used for", "compositional classes of paraphrases:task"], ["class-oriented framework:method", "used for", "paraphrase examples:material"], ["automatic candidate generation:method", "used for", "sentential paraphrases:material"], ["manual judgement:method", "used for", "sentential paraphrases:material"]], "pred": [["class-oriented framework:method", "used for", "automatic candidate generation:method"], ["class-oriented framework:method", "used for", "manual judgement:method"], ["class-oriented framework:method", "used for", "compositional classes of paraphrases:other scientific term"], ["paraphrase examples:material", "used for", "sentential paraphrases:material"], ["class-oriented framework:method", "used for", "paraphrase examples:material"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"used for\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "514": {"text": "Given the video streams acquired by two cameras placed on either side of a computer monitor, the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact.", "true": [["cameras:other scientific term", "used for", "video streams:material"], ["algorithm:generic", "used for", "eye contact:other scientific term"], ["virtual camera:other scientific term", "used for", "images:material"]], "pred": [["proposed algorithm:method", "used for", "virtual camera:method"], ["eye contact:task", "used for", "proposed algorithm:method"], ["arbitrary position:other scientific term", "used for", "eye contact:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"used for\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "515": {"text": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations.", "true": [["layers of distributed representations:method", "used for", "object pose information:other scientific term"]], "pred": [["layers:other scientific term", "used for", "object pose information:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "516": {"text": "Experimental results from a real telephone application on a natural number recognition task show an 50% reduction in recognition errors with a moderate 12% rejection rate of correct utterances and a low 1.5% rate of false acceptance.", "true": [], "pred": [["real telephone application:material", "used for", "natural number recognition task:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"used for\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "517": {"text": "FERRET utilizes a novel approach to Q/A known as predictive questioning which attempts to identify the questions -LRB- and answers -RRB- that users need by analyzing how a user interacts with a system while gathering information related to a particular scenario.", "true": [["approach:generic", "used for", "FERRET:method"], ["approach:generic", "used for", "Q/A:method"]], "pred": [["Q/A:other scientific term", "used for", "questions:other scientific term"], ["Q/A:other scientific term", "used for", "answers:other scientific term"], ["FERRET:method", "used for", "Q/A:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"used for\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n"}, "518": {"text": "Discourse processing requires recognizing how the utterances of the discourse aggregate into segments, recognizing the intentions expressed in the discourse and the relationships among intentions, and tracking the discourse through the operation of the mechanisms associated with attentional state.", "true": [], "pred": [["discourse processing:task", "used for", "utterances:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"used for\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "520": {"text": "This allows us to use our method to act not only as a faster procedure for cascade evaluation, but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions, in particular kernel-ized support vector machines.", "true": [["method:generic", "used for", "cascade evaluation:task"], ["method:generic", "used for", "branch-and-bound object detection:task"], ["nonlinear quality functions:other scientific term", "used for", "branch-and-bound object detection:task"]], "pred": [["efficient branch-and-bound object detection:task", "used for", "kernel-ized support vector machines:method"], ["method:generic", "used for", "efficient branch-and-bound object detection:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "523": {"text": "In both domains, we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples, and that semi-supervised methods can make good use of small amounts of labeled data.", "true": [["unlabeled examples:material", "used for", "unsupervised methods:method"], ["labeled examples:material", "used for", "supervised methods:method"], ["labeled data:material", "used for", "semi-supervised methods:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "524": {"text": "Specifically, by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork, the proposed model automatically captures the complex long-range temporal dynamics, which naturally avoids the typical sliding window design and thus ensures high computational efficiency.", "true": [["deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork:method", "used for", "model:generic"]], "pred": [["deep Long Short-Term Memory -LRB- LSTM -RRB-:method", "used for", "complex long-range temporal dynamics:other scientific term"], ["proposed model:method", "used for", "complex long-range temporal dynamics:other scientific term"], ["proposed model:method", "used for", "high computational efficiency:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"used for\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "525": {"text": "On the internal side, liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary, a morphosyntactic parser of L0, and a canonical graph2tree transformation.", "true": [["resources:generic", "used for", "liaisons:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "526": {"text": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-, including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples.", "true": [["components:generic", "used for", "intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-:task"], ["disambiguated morphological analysis:method", "used for", "aligned bilingual corpus:material"], ["lemmatized indexing:method", "used for", "aligned bilingual corpus:material"]], "pred": [["demonstration:method", "used for", "Applied Natural Language Processing:method"], ["demonstration:method", "used for", "intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "527": {"text": "Although the study of clustering is centered around an intuitively compelling goal, it has been very difficult to develop a unified framework for reasoning about it at a technical level, and profoundly diverse approaches to clustering abound in the research community.", "true": [["unified framework:method", "used for", "reasoning:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "528": {"text": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset, and run two different machine learning algorithms: SLIPPER, a rule-based learning algorithm, and TiMBL, a memory-based system.", "true": [], "pred": [["domain independent features:method", "used for", "machine learning algorithms:method"], ["input dataset:material", "used for", "domain independent features:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"used for\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}, "530": {"text": "The two main contributions of this paper are: i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming, that encourages correct occlusion labeling; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface.", "true": [["three-plane graph:method", "used for", "dense-stereo dynamic-programming:method"], ["dense-stereo dynamic-programming:method", "used for", "occlusion labeling:task"], ["compact geometric derivation:other scientific term", "used for", "novel-view synthesis:task"], ["direct projection of the minimum-cost surface:method", "used for", "compact geometric derivation:other scientific term"]], "pred": [["three-plane graph:method", "used for", "dense-stereo dynamic-programming:method"], ["novel-view synthesis:task", "used for", "compact geometric derivation:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"used for\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "531": {"text": "To recover from these inevitable tracking failures, we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB-, a method that avoids becoming trapped at local modes and is much faster than exhaustive search.", "true": [["global optimization problem:task", "used for", "object detection:task"], ["Adaptive Simulated Annealing -LRB- ASA -RRB-:method", "used for", "it:generic"]], "pred": [["object detection:task", "used for", "Adaptive Simulated Annealing -LRB- ASA -RRB-:method"], ["Adaptive Simulated Annealing -LRB- ASA -RRB-:method", "used for", "object detection:task"], ["Adaptive Simulated Annealing -LRB- ASA -RRB-:method", "used for", "global optimization problem:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"used for\"  \n(28) \"used for\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "532": {"text": "Furthermore, this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB-; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space.", "true": [["algorithm:generic", "used for", "temporal maintenance of a background model:task"], ["algorithm:generic", "used for", "rendering of occlusions:task"], ["algorithm:generic", "used for", "temporal artefacts -LRB- flicker -RRB-:other scientific term"], ["cost aggregation algorithm:method", "used for", "three-dimensional matching cost space:other scientific term"]], "pred": [["temporal maintenance:task", "used for", "rendering of occlusions:task"], ["rendering of occlusions:task", "used for", "novel algorithm:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"used for\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "533": {"text": "In the Object Recognition task, there exists a di-chotomy between the categorization of objects and estimating object pose, where the former necessitates a view-invariant representation, while the latter requires a representation capable of capturing pose information over different categories of objects.", "true": [["view-invariant representation:method", "used for", "former:generic"], ["representation:generic", "used for", "latter:generic"], ["representation:generic", "used for", "pose information:other scientific term"]], "pred": [["Object Recognition task:task", "used for", "categorization of objects:task"], ["Object Recognition task:task", "used for", "estimating object pose:task"], ["Object Recognition task:task", "used for", "view-invariant representation:method"], ["Object Recognition task:task", "used for", "representation capable of capturing pose information:method"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "534": {"text": "While current approaches are developed by only considering the low rank plus sparse structure, in many applications, side information of row and/or column entities may also be given, and it is still unclear to what extent could such information help robust PCA.", "true": [["low rank plus sparse structure:other scientific term", "used for", "approaches:generic"], ["information:generic", "used for", "robust PCA:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "535": {"text": "Determiners play an important role in conveying the meaning of an utterance, but they have often been disregarded, perhaps because it seemed more important to devise methods to grasp the global meaning of a sentence, even if not in a precise way.", "true": [], "pred": [["methods:method", "used for", "global meaning:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "536": {"text": "In general, our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech, although it is interesting to note that the best results are achieved by three-way voting among the classifiers.", "true": [["classifiers:method", "used for", "three-way voting:method"]], "pred": [["NIST sentence boundary detection task:task", "used for", "HMM:method"], ["NIST sentence boundary detection task:task", "used for", "Max-ent models:method"], ["CRF model:method", "used for", "speech:other scientific term"], ["HMM:method", "used for", "speech:other scientific term"], ["Max-ent models:method", "used for", "speech:other scientific term"], ["CRF model:method", "used for", "NIST sentence boundary detection task:task"], ["HMM:method", "used for", "NIST sentence boundary detection task:task"], ["Max-ent models:method", "used for", "NIST sentence boundary detection task:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"used for\"  \n(17) \"used for\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"used for\"  \n(22) \"none\"  \n(23) \"used for\"  \n(24) \"none\"  \n(25) \"used for\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"used for\"  \n(54) \"used for\"  \n(55) \"used for\"  \n(56) \"none\"  \n"}, "537": {"text": "The objective of this work is to recognize faces using video sequences both for training and recognition input, in a realistic, unconstrained setup in which lighting, pose and user motion pattern have a wide variability and face images are of low resolution.", "true": [], "pred": [["training:task", "used for", "video sequences:material"], ["recognition input:task", "used for", "video sequences:material"], ["training:task", "used for", "recognition input:task"], ["video sequences:material", "used for", "training:task"], ["face images:material", "used for", "training:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"used for\"  \n(70) \"none\"  \n(71) \"used for\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n(91) \"none\"  \n(92) \"none\"  \n(93) \"none\"  \n(94) \"none\"  \n(95) \"none\"  \n(96) \"none\"  \n(97) \"none\"  \n(98) \"none\"  \n(99) \"none\"  \n(100) \"none\"  \n(101) \"none\"  \n(102) \"none\"  \n(103) \"none\"  \n(104) \"none\"  \n(105) \"none\"  \n(106) \"none\"  \n(107) \"none\"  \n(108) \"none\"  \n(109) \"none\"  \n(110) \"none\"  \n(111) \"none\"  \n(112) \"none\"  \n(113) \"none\"  \n(114) \"none\"  \n(115) \"none\"  \n(116) \"none\"  \n(117) \"none\"  \n(118) \"none\"  \n(119) \"none\"  \n(120) \"none\"  \n(121) \"none\"  \n(122) \"none\"  \n(123) \"none\"  \n(124) \"none\"  \n(125) \"none\"  \n(126) \"none\"  \n(127) \"none\"  \n(128) \"none\"  \n(129) \"none\"  \n(130) \"none\"  \n(131) \"none\"  \n(132) \"none\"  \n(133) \"none\"  \n(134) \"none\"  \n(135) \"none\"  \n(136) \"none\"  \n(137) \"none\"  \n(138) \"none\"  \n(139) \"none\"  \n(140) \"none\"  \n(141) \"none\"  \n(142) \"none\"  \n(143) \"none\"  \n(144) \"none\"  \n(145) \"none\"  \n(146) \"\n"}, "538": {"text": "Establishing a \"best\" correspondence between the\" UNL-tree + L0\" and the\" MS-L0 structure\", a lattice, may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible.", "true": [["dictionary:material", "used for", "lattice:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "540": {"text": "Among other experiments, we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data.", "true": [["approach:generic", "used for", "learned confidence measures:method"], ["automatically generated training data:material", "used for", "them:generic"]], "pred": [["learned confidence measures:method", "used for", "performance:metric"], ["automatically generated training data:material", "used for", "learned confidence measures:method"], ["KITTI2012 dataset:material", "used for", "performance:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"used for\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"used for\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "541": {"text": "Here, we leverage a logistic stick-breaking representation and recent innovations in P\u00f3lya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods, enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead.", "true": [["logistic stick-breaking representation:method", "used for", "multinomial distribution:method"], ["P\u00f3lya-gamma augmentation:task", "used for", "multinomial distribution:method"], ["Bayesian inference techniques:method", "used for", "Gaussian models:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "542": {"text": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction, allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint.", "true": [["Multi-view constraints:other scientific term", "used for", "matching:task"], ["Multi-view constraints:other scientific term", "used for", "reconstruction:task"], ["normalized representation:method", "used for", "matching:task"], ["normalized representation:method", "used for", "reconstruction:task"], ["images:material", "used for", "acquisition of true three-dimensional affine and Euclidean models:task"]], "pred": [["matching:task", "used for", "multiple images:material"], ["reconstruction:task", "used for", "multiple images:material"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n"}, "543": {"text": "The formalism's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language, or to their translates in another natural language; in summary, we intend it to allow TAGs to be used beyond their role in syntax proper.", "true": [["logical form language:other scientific term", "used for", "semantics:other scientific term"], ["TAGs:method", "used for", "syntax proper:other scientific term"]], "pred": [["formalism:other scientific term", "used for", "natural languages:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "544": {"text": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus, so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB-.", "true": [["pool models:method", "used for", "inner hair cell synapse:other scientific term"], ["visual inspection:method", "used for", "offset adaptation -LRB- OA -RRB- model:method"], ["automatic speech recognition -LRB- ASR -RRB-:method", "used for", "offset adaptation -LRB- OA -RRB- model:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "547": {"text": "While sentence extraction as an approach to summarization has been shown to work in documents of certain genres, because of the conversational nature of email communication where utterances are made in relation to one made previously, sentence extraction may not capture the necessary segments of dialogue that would make a summary coherent.", "true": [["sentence extraction:method", "used for", "summarization:task"]], "pred": [["summarization:task", "used for", "sentence extraction:method"], ["sentence extraction:method", "used for", "summary:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"used for\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "549": {"text": "We present a new part-of-speech tagger that demonstrates the following ideas: -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation, -LRB- ii -RRB- broad use of lexical features, including jointly conditioning on multiple consecutive words, -LRB- iii -RRB- effective use of priors in conditional loglinear models, and -LRB- iv -RRB- fine-grained modeling of unknown word features.", "true": [["tag contexts:other scientific term", "used for", "part-of-speech tagger:method"], ["dependency network representation:method", "used for", "tag contexts:other scientific term"], ["lexical features:other scientific term", "used for", "part-of-speech tagger:method"], ["priors in conditional loglinear models:other scientific term", "used for", "part-of-speech tagger:method"], ["fine-grained modeling of unknown word features:method", "used for", "part-of-speech tagger:method"]], "pred": [["part-of-speech tagger:method", "used for", "lexical features:other scientific term"], ["part-of-speech tagger:method", "used for", "multiple consecutive words:other scientific term"], ["part-of-speech tagger:method", "used for", "priors in conditional loglinear models:other scientific term"], ["part-of-speech tagger:method", "used for", "unknown word features:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"used for\"  \n(17) \"used for\"  \n(18) \"used for\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "550": {"text": "In particular there are three areas of novelty: -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation, learnt offline, to generalize in the presence of extreme illumination changes; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses; and -LRB- iii -RRB- we introduce an accurate video sequence\" reillumination\" algorithm to achieve robustness to face motion patterns in video.", "true": [["photometric model:method", "used for", "image formation:task"], ["statistical model:method", "used for", "generic face appearance variation:task"], ["statistical model:method", "used for", "extreme illumination changes:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}}, "missing_cases": {"8": [["It:generic", "used for", "empirical MT research:task"]], "15": [["beam-search decoder:method", "used for", "Translations:other scientific term"]], "23": [["translating virtual camera:other scientific term", "used for", "synthesis:task"]], "29": [["approach:generic", "used for", "automatically acquiring English topic signatures:task"]], "34": [["recursive descent parser:method", "used for", "It:generic"]], "37": [["different-quality references:other scientific term", "used for", "evaluation:generic"]], "39": [["histogram information:other scientific term", "used for", "detecting interest points:task"], ["method:generic", "used for", "detecting interest points:task"]], "40": [["highly correlated inputs:material", "used for", "random modulation scheme:method"]], "42": [["Minimum Bayes-Risk -LRB- MBR -RRB- decoding:method", "used for", "statistical machine translation:task"]], "44": [["evaluation criterion:metric", "used for", "word similarity measures:metric"]], "49": [["MINPRAN:method", "used for", "complex range:other scientific term"], ["MINPRAN:method", "used for", "intensity data:material"]], "50": [["triangulation:other scientific term", "used for", "piecewise-linear interpolant:other scientific term"]], "51": [["method:generic", "used for", "phrases:generic"]], "54": [["posterior:generic", "used for", "sparse se-lectional preferences:other scientific term"]], "55": [["approach:generic", "used for", "LCS-Marine:task"]], "57": [["Machine transliteration/back-transliteration:task", "used for", "multilingual speech and language applications:task"]], "61": [["dialogue:material", "used for", "bare slice disambiguation:task"]], "63": [["It:generic", "used for", "reflection:other scientific term"]], "64": [["detectors:generic", "used for", "detector:generic"]], "66": [["method:generic", "used for", "priming:other scientific term"], ["priming:other scientific term", "used for", "incremental probabilistic parser:method"]], "67": [["rhetorical moves of argumentation:method", "used for", "scheme:generic"]], "68": [["algorithm:generic", "used for", "novel view generation:task"]], "70": [["motor control representation:method", "used for", "word spotting:task"]], "71": [["hand-crafted rules:other scientific term", "used for", "syntactic knowledge:other scientific term"]], "72": [["Listen-Communicate-Show -LRB- LCS -RRB-:task", "used for", "human interaction with data sources:task"]], "82": [["predominant senses:other scientific term", "used for", "combination methods:method"], ["raw text:material", "used for", "predominant senses:other scientific term"]], "83": [["Prolog:other scientific term", "used for", "system:generic"], ["logic:other scientific term", "used for", "programming language:other scientific term"]], "85": [["comparable, non-parallel corpora:material", "used for", "discovering parallel sentences:task"], ["method:generic", "used for", "discovering parallel sentences:task"]], "88": [["graph:other scientific term", "used for", "UNL-L0 deconverter:method"]], "89": [["stochastic gradient descent algorithm:method", "used for", "learning problem:generic"]], "90": [["kernel trick:method", "used for", "non-linear extension of WARCA:method"]], "91": [["model-based approach:method", "used for", "on-line cursive handwriting analysis and recognition:task"]], "92": [["approaches:generic", "used for", "object pose estimation:task"]], "94": [["GLOSSER:method", "used for", "reading and learning:task"]], "96": [["dictionaries:other scientific term", "used for", "Japanese character strings:other scientific term"], ["dictionaries:other scientific term", "used for", "it:generic"]], "97": [["domain independent model:method", "used for", "automated interpretation of nominal compounds:task"]], "99": [["model:generic", "used for", "blind separation of natural speech signals.:task"]], "100": [["transliteration/backtransliteration:task", "used for", "English/Chinese and English/Japanese language pairs:material"]], "102": [["sampling probabilities:other scientific term", "used for", "records:material"], ["specialized regression problem:task", "used for", "sampling probabilities:other scientific term"]], "104": [["Branch and bound strategies:method", "used for", "complexity:generic"]], "107": [["posteriori bound:other scientific term", "used for", "joint matrix decomposition:task"]], "108": [["Learned confidence measures:method", "used for", "outlier removal:task"], ["Learned confidence measures:method", "used for", "quality improvement:task"]], "114": [["dynamic representation:method", "used for", "cursive handwriting recognition:task"]], "115": [["high-capacity models:method", "used for", "computer vision:task"], ["large datasets:material", "used for", "high-capacity models:method"]], "116": [["hypothesized object boundary fragments:other scientific term", "used for", "mattes:generic"]], "117": [["They:generic", "used for", "reconstruction:task"]], "119": [["method:generic", "used for", "space-time interest point detection:task"], ["space-time interest point detection:task", "used for", "action classification:task"]], "122": [["generative proba-bilistic framework:method", "used for", "3D object categorization:task"]], "126": [["model:generic", "used for", "knowledge sources:material"]], "127": [["psycholinguistic literature:other scientific term", "used for", "syntactic priming:other scientific term"]], "131": [["dynamic-programming, stereo algorithm:method", "used for", "technique:generic"], ["technique:generic", "used for", "novel-view generation:task"]], "133": [["Memo-functions:method", "used for", "parse forest:other scientific term"]], "138": [["deep archi-tectures:method", "used for", "object category recognition:task"]], "142": [["approach:generic", "used for", "cluttered scenes:other scientific term"]], "145": [["images:material", "used for", "perception of transparent objects:task"]], "151": [["zero-crossings:other scientific term", "used for", "Subpixel accuracy:metric"]], "153": [["hard budget constraints:other scientific term", "used for", "cost zero solution:method"]], "154": [["Bayesian Network:method", "used for", "addressee identification in four-participants face-to-face meetings:task"], ["Naive Bayes classifiers:method", "used for", "addressee identification in four-participants face-to-face meetings:task"]], "155": [["distribution:generic", "used for", "computer Go:other scientific term"]], "156": [["voting - and arbiter-based combination strategies:method", "used for", "unsupervised WSD systems:method"]], "162": [["language pairs:generic", "used for", "GLOSSER:method"]], "164": [["Euclidean distance:other scientific term", "used for", "deep embedding methods:method"]], "165": [["boundary detection:method", "used for", "approach:generic"], ["image matting:method", "used for", "approach:generic"], ["spectral clustering:method", "used for", "approach:generic"]], "169": [["Fast algorithms:generic", "used for", "nearest neighbor -LRB- NN -RRB- search:task"]], "170": [["Structural or numerical constraints:other scientific term", "used for", "reconstruction process:method"], ["constrained optimization scheme:method", "used for", "Structural or numerical constraints:other scientific term"]], "177": [["PageRank algorithm:method", "used for", "relevant approach:method"], ["documents:material", "used for", "event map:other scientific term"], ["event map:other scientific term", "used for", "PageRank algorithm:method"]], "179": [["MBR decoding:method", "used for", "loss functions:other scientific term"], ["MBR decoding:method", "used for", "statistical MT:method"]], "180": [["conversational context:other scientific term", "used for", "classifiers:method"], ["speaker's gaze information:other scientific term", "used for", "classifiers:method"], ["utterance features:other scientific term", "used for", "classifiers:method"]], "182": [["corpus-based sample:material", "used for", "heuristic principles:method"]], "184": [["supervised training data:material", "used for", "information extraction techniques:method"]], "187": [["cluster analysis:method", "used for", "local tracker:method"], ["cluster analysis:method", "used for", "sampled parameter space:other scientific term"]], "189": [["dependency-based grammar model:method", "used for", "sentence-level and text-level anaphora:other scientific term"]], "190": [["word list:other scientific term", "used for", "language model adaptation methods:method"]], "191": [["discrete data:material", "used for", "modeling problems:task"], ["multinomial or categorical distributions:method", "used for", "modeling problems:task"]], "192": [["cycloidal motion parameters:other scientific term", "used for", "arbitrary handwriting:material"]], "195": [["decision tree-based context clustering:method", "used for", "parameter training algorithm:method"], ["parameter training algorithm:method", "used for", "model:generic"]], "196": [["concept hierarchy constraints:other scientific term", "used for", "NCA:method"], ["frequency of occurrences:other scientific term", "used for", "NCA:method"]], "198": [["known motion:other scientific term", "used for", "shapes and the poses of transparent objects:other scientific term"], ["model-based approach:method", "used for", "shapes and the poses of transparent objects:other scientific term"]], "199": [["convolution kernel over parse trees:method", "used for", "syntactic structure information:other scientific term"], ["syntactic structure information:other scientific term", "used for", "relation extraction:task"]], "201": [["pattern-matching language:other scientific term", "used for", "It:generic"], ["pattern-matching language:other scientific term", "used for", "grs:other scientific term"]], "202": [["principled and provable solution:method", "used for", "problem:generic"]], "203": [["task dialogues:material", "used for", "prototype Natural Language system:method"], ["technique:generic", "used for", "task dialogues:material"]], "206": [["motion trajectories:other scientific term", "used for", "technique:generic"], ["technique:generic", "used for", "detecting reflections in image sequences:task"]], "209": [["non-contiguous phrases:material", "used for", "phrase-based statistical machine translation method:method"]], "211": [["data-dependent bandwidth:other scientific term", "used for", "ambiguities:other scientific term"], ["data-dependent bandwidth:other scientific term", "used for", "density estimation:task"], ["kernels:method", "used for", "density estimation:task"]], "212": [["information extraction annotations:other scientific term", "used for", "document retrieval for distillation:task"]], "213": [["representation:generic", "used for", "three-dimensional objects:other scientific term"]], "214": [["Japanese information extraction:task", "used for", "It:generic"]], "215": [["iterative deformation of a 3--D surface mesh:method", "used for", "approach:generic"], ["iterative deformation of a 3--D surface mesh:method", "used for", "objective function:other scientific term"]], "217": [["binary-binary partial matrix-vector multiplication:method", "used for", "high-density, low-power analog array:other scientific term"]], "219": [["prior on the distribution of natural images:other scientific term", "used for", "support vector machines:method"]], "220": [["verbal and nonverbal grounding acts:other scientific term", "used for", "ECA:method"], ["verbal and nonverbal grounding acts:other scientific term", "used for", "dialogue state:other scientific term"]], "224": [["language models:method", "used for", "them:generic"]], "226": [["Bayesian statistics:method", "used for", "approach:generic"], ["approach:generic", "used for", "robust-ness requirement in image understanding:task"]], "229": [["multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method", "used for", "temporal localiza-tion information:other scientific term"]], "233": [["scarce resources:material", "used for", "method:generic"]], "238": [["ASR system:method", "used for", "Noise Spotting capabilities:task"], ["ASR system:method", "used for", "Word Spotting:task"]], "241": [["phonetic rules:other scientific term", "used for", "surface realizations of morphological constructions:task"]], "243": [["weakly supervised dependency parser:task", "used for", "speech syntax:other scientific term"]], "246": [["appearance information:other scientific term", "used for", "probabilistic framework:method"], ["geometric constraints:other scientific term", "used for", "probabilistic framework:method"], ["probabilistic framework:method", "used for", "visual models of 3D object categories:task"]], "248": [["method:generic", "used for", "natural speech signals:other scientific term"], ["methods:generic", "used for", "natural speech signals:other scientific term"]], "252": [["approach:generic", "used for", "outdoor surveillance settings:other scientific term"], ["multiple PTZ camera sequences:other scientific term", "used for", "approach:generic"]], "253": [["approaches:generic", "used for", "evaluation of Natural Language systems:task"]], "254": [["game records of expert players:material", "used for", "board game of Go:task"]], "255": [["training resources:material", "used for", "automatic abstracting systems:task"]], "258": [["algorithm:generic", "used for", "spatial and temporal artefacts:other scientific term"], ["spatial and temporal artefacts:other scientific term", "used for", "long stereo video streams:material"]], "259": [["semantic constraints:other scientific term", "used for", "anaphora references:other scientific term"], ["semantic constraints:other scientific term", "used for", "syntactic ambiguities:other scientific term"]], "265": [["discrete nerve-action potentials:other scientific term", "used for", "analog pressure wave:other scientific term"]], "270": [["generative framework:method", "used for", "model:generic"]], "272": [["system:generic", "used for", "acquiring adjectival subcategorization frames -LRB- scfs -RRB-:task"]], "276": [["closed-form -LRB- analytical -RRB- solution:method", "used for", "Kullback-Leibler distance:method"], ["closed-form -LRB- analytical -RRB- solution:method", "used for", "cross-entropy:method"]], "277": [["feature weighting and selection function:method", "used for", "feature vectors:other scientific term"], ["feature weighting and selection function:method", "used for", "word similarity:task"]], "278": [["extraposition grammars:method", "used for", "Chat-80:method"]], "279": [["relational database:material", "used for", "query optimisation:method"]], "280": [["MT evaluation techniques:method", "used for", "entailment:task"], ["MT evaluation techniques:method", "used for", "features:other scientific term"], ["MT evaluation techniques:method", "used for", "paraphrase classification:task"]], "282": [["it:generic", "used for", "statistical machine translation system:method"]], "285": [["techniques:generic", "used for", "large outlier percentages:metric"]], "289": [["geometric structures of 3D lines:task", "used for", "light field triangulation:task"], ["geometric structures of 3D lines:task", "used for", "stereo matching:task"]], "292": [["approach:generic", "used for", "pixel-accurate semantic label maps:other scientific term"], ["pixel-accurate semantic label maps:other scientific term", "used for", "images:material"]], "293": [["feature:other scientific term", "used for", "modeling of the dynamic characteristics:task"], ["optical flow:other scientific term", "used for", "feature:other scientific term"], ["optical flow:other scientific term", "used for", "modeling of the dynamic characteristics:task"]], "295": [["ambiguity packing and stochastic disambiguation techniques:method", "used for", "Lexical-Functional Grammars -LRB- LFG -RRB-:method"], ["ambiguity packing and stochastic disambiguation techniques:method", "used for", "sentence condensation:task"]], "296": [["implications:generic", "used for", "discourse processing algorithms:method"]], "298": [["probabilistic finite automata:method", "used for", "distributional approximation:task"]], "299": [["2D point correspondences:other scientific term", "used for", "reconstructing the motion of a 3D articulated tree:task"]], "301": [["learning in autonomous agents:task", "used for", "domain-speciic models of actions:method"], ["planning systems:task", "used for", "domain-speciic models of actions:method"]], "302": [["GOLEM:method", "used for", "action models:method"]], "303": [["images:material", "used for", "automated segmentation:task"]], "304": [["dynamic programming -LRB- DP -RRB-:method", "used for", "statistical machine translation -LRB- MT -RRB-:task"], ["search procedure:generic", "used for", "statistical machine translation -LRB- MT -RRB-:task"]], "307": [["loss:other scientific term", "used for", "Mahalanobis distance:task"]], "311": [["metric weight constraint:other scientific term", "used for", "learning:generic"]], "312": [["full scale two-level morphological description:task", "used for", "Turkish word structures:material"]], "314": [["approach:generic", "used for", "1 distance:other scientific term"]], "316": [["anisotropic meshing:method", "used for", "reconstruction:task"], ["non-quadratic approach:method", "used for", "reconstruction:task"], ["non-quadratic approach:method", "used for", "regularization:other scientific term"], ["triangulations:other scientific term", "used for", "reconstruction:task"]], "317": [["model:generic", "used for", "productive rules of interpretation:other scientific term"], ["morpho-syntactic and semantic characteristics:other scientific term", "used for", "productive rules of interpretation:other scientific term"]], "318": [["kernels:method", "used for", "image processing:task"], ["mixed-signal paradigm:method", "used for", "high-resolution parallel inner-product computation:task"], ["mixed-signal paradigm:method", "used for", "kernels:method"]], "320": [["nonstationarity:other scientific term", "used for", "method:generic"]], "321": [["detection of question-answer pairs:task", "used for", "email summarization:task"], ["email conversation:material", "used for", "detection of question-answer pairs:task"]], "322": [["approach:generic", "used for", "camera handoff in wide-area surveillance scenarios:task"]], "323": [["systems:generic", "used for", "task:generic"]], "324": [["conversational context features:other scientific term", "used for", "addressee of a dialogue act:other scientific term"], ["gaze:other scientific term", "used for", "addressee of a dialogue act:other scientific term"], ["utterance:other scientific term", "used for", "addressee of a dialogue act:other scientific term"]], "326": [["It:generic", "used for", "move selector:method"], ["It:generic", "used for", "move sorter:method"], ["It:generic", "used for", "training tool:task"], ["move selector:method", "used for", "game tree search:method"], ["move sorter:method", "used for", "game tree search:method"], ["training tool:task", "used for", "Go players:other scientific term"]], "327": [["techniques:generic", "used for", "failures of reference:task"]], "332": [["weighted rank loss:other scientific term", "used for", "computer vision:task"], ["weighted rank loss:other scientific term", "used for", "person re-identification:task"]], "333": [["AN fibers -LRB- ANFs -RRB-:other scientific term", "used for", "features:other scientific term"], ["OA:method", "used for", "features:other scientific term"], ["OA:method", "used for", "phase locking in the auditory nerve -LRB- AN -RRB-:task"]], "334": [["Gaussian mixture models -LRB- GMMs -RRB-:method", "used for", "ANF-based and ON-based auditory features:other scientific term"], ["Multi-layer perceptrons -LRB- MLPs -RRB-:method", "used for", "ANF-based and ON-based auditory features:other scientific term"]], "335": [["It:generic", "used for", "unsupervised object discovery:task"]], "336": [["fundamental frequency -LRB- F0 -RRB- contour of speech:other scientific term", "used for", "text-to-speech synthesis:task"], ["text input:material", "used for", "fundamental frequency -LRB- F0 -RRB- contour of speech:other scientific term"]], "337": [["them:generic", "used for", "3--D reconstruction:task"]], "338": [["lexical and syntactic features:other scientific term", "used for", "unsupervised learning approach:method"], ["unsupervised learning approach:method", "used for", "relations between named entities:other scientific term"]], "339": [["factorization:method", "used for", "tensors:generic"], ["line correspondences:other scientific term", "used for", "estimation:generic"], ["point correspondences:other scientific term", "used for", "estimation of the tensors:task"]], "343": [["constraint-based parser/generator:method", "used for", "system:generic"]], "346": [["features:other scientific term", "used for", "lexical similarity:other scientific term"], ["structure of email-threads:other scientific term", "used for", "features:other scientific term"]], "347": [["SVMs:method", "used for", "overfitting:other scientific term"]], "348": [["Sentence boundary detection:task", "used for", "speech recognition output:other scientific term"], ["speech:material", "used for", "Sentence boundary detection:task"]], "350": [["priors:other scientific term", "used for", "sparse and dense detection maps:other scientific term"]], "352": [["FERRET:method", "used for", "integrating automatic Q/A applications into real-world environments:task"]], "353": [["annotation scheme:method", "used for", "scientific articles:material"]], "356": [["Coedition:task", "used for", "text revision:other scientific term"], ["natural language text:material", "used for", "Coedition:task"]], "357": [["methods:generic", "used for", "preparing a segmented corpus:task"]], "360": [["OA:method", "used for", "auditory processing:task"], ["onset neurons -LRB- ONs -RRB-:other scientific term", "used for", "OA:method"]], "362": [["Fujisaki model:method", "used for", "statistical model:method"], ["statistical model:method", "used for", "speech F0 contours:other scientific term"]], "363": [["divide-and-conquer procedure:method", "used for", "method:generic"], ["method:generic", "used for", "evaluation of object detection cascades:task"]], "365": [["Japanese:material", "used for", "morphological analysis problem:task"], ["Multi-lingual Evaluation Task -LRB- MET -RRB-:task", "used for", "Japanese text:material"], ["approach:generic", "used for", "Multi-lingual Evaluation Task -LRB- MET -RRB-:task"], ["morphological analysis problem:task", "used for", "task:generic"]], "366": [["detectors:generic", "used for", "blur:other scientific term"], ["detectors:generic", "used for", "distinctive textured patterns:other scientific term"], ["detectors:generic", "used for", "illumination variation:other scientific term"], ["detectors:generic", "used for", "large-scale structures:other scientific term"], ["detectors:generic", "used for", "rotation:other scientific term"]], "370": [["WSD datasets:material", "used for", "second-order vector cooccurrence algorithm:method"]], "371": [["Joint matrix triangularization:task", "used for", "joint eigenstructure:other scientific term"], ["joint eigenstructure:other scientific term", "used for", "machine learning:task"], ["joint eigenstructure:other scientific term", "used for", "signal processing:task"]], "372": [["active sensing devices:other scientific term", "used for", "task:generic"], ["manual interaction:other scientific term", "used for", "task:generic"], ["synthetic scenes:other scientific term", "used for", "task:generic"]], "374": [["joint classification and regression optimization objective:other scientific term", "used for", "network:generic"]], "377": [["Plume's approach:method", "used for", "parsing:task"], ["semantic caseframe instantiation:other scientific term", "used for", "Plume's approach:method"]], "379": [["image:material", "used for", "classification:task"], ["image:material", "used for", "detection:task"], ["position:other scientific term", "used for", "classification:task"], ["position:other scientific term", "used for", "detection:task"], ["viewpoint:other scientific term", "used for", "classification:task"], ["viewpoint:other scientific term", "used for", "detection:task"]], "380": [["IEMOCAP database:material", "used for", "discrete -LRB- categorical -RRB- and continuous -LRB- attribute -RRB- emotional assessments:task"]], "382": [["it:generic", "used for", "active reconstruction systems:task"], ["method:generic", "used for", "scene geometry:other scientific term"]], "383": [["evaluation techniques:generic", "used for", "human language learning process:task"], ["evaluation techniques:generic", "used for", "machine translation systems:task"], ["evaluation techniques:generic", "used for", "translation process:task"]], "384": [["trajectory basis:other scientific term", "used for", "smooth motion:other scientific term"]], "385": [["numerical optimization problem:task", "used for", "visual object tracking:task"]], "387": [["Convolutional Neural Networks -LRB- CNN -RRB- architectures:method", "used for", "object recognition:task"], ["Convolutional Neural Networks -LRB- CNN -RRB- architectures:method", "used for", "pose estimation:task"]], "389": [["PC-KIMMO environment:method", "used for", "description:generic"], ["root word lexicon:material", "used for", "description:generic"]], "390": [["statistical learning:method", "used for", "Fujisaki-model parameters:other scientific term"], ["text input:material", "used for", "Fujisaki-model parameters:other scientific term"]], "391": [["Bayesian inference:method", "used for", "rules:other scientific term"], ["complex tree structures:other scientific term", "used for", "discriminative model's posterior:other scientific term"], ["them:generic", "used for", "complex tree structures:other scientific term"], ["unlabeled corpus:material", "used for", "discriminative model's posterior:other scientific term"]], "392": [["formalism:generic", "used for", "grammar formalisms:method"]], "393": [["first-order autoregressive model:method", "used for", "signals:generic"]], "395": [["framework:generic", "used for", "machine transliteration/backtransliteration:task"]], "396": [["framework:generic", "used for", "joint source-channel transliteration model:method"], ["n-gram transliteration model -LRB- n-gram TM -RRB-:method", "used for", "transliteration process:method"]], "398": [["Wizard of Oz technique:method", "used for", "NL requirements:other scientific term"], ["Wizard of Oz technique:method", "used for", "task:generic"]], "402": [["Topic signatures:other scientific term", "used for", "Natural Language Processing -LRB- NLP -RRB- applications:task"], ["Topic signatures:other scientific term", "used for", "Text Summarisation:task"], ["Topic signatures:other scientific term", "used for", "Word Sense Disambiguation -LRB- WSD -RRB-:task"]], "403": [["view points:other scientific term", "used for", "approach:generic"]], "404": [["method:method", "used for", "shape constrained image segmentation:task"], ["mixtures of feature distributions:other scientific term", "used for", "color:other scientific term"], ["mixtures of feature distributions:other scientific term", "used for", "method:method"], ["mixtures of feature distributions:other scientific term", "used for", "probabilistic shape knowledge:other scientific term"], ["mixtures of feature distributions:other scientific term", "used for", "texture:other scientific term"]], "405": [["LR-parser:method", "used for", "CF grammars:method"], ["LR-parser:method", "used for", "Extended CF grammars:method"]], "406": [["Kernel space embedding:other scientific term", "used for", "inarbitrary distance measures:method"]], "408": [["moderate positive sample mining method:method", "used for", "robust CNN:method"]], "409": [["partial scene segmentation:task", "used for", "unsupervised seg-mentation of whole objects:task"], ["soft, binary mattes:other scientific term", "used for", "partial scene segmentation:task"]], "412": [["random-projection based methods:method", "used for", "NN search:task"]], "413": [["dictionary lookup stage:method", "used for", "rules:other scientific term"], ["rules:other scientific term", "used for", "NE items:other scientific term"]], "414": [["model:generic", "used for", "interpretation of compounds:task"]], "416": [["linguistic parser/generator:method", "used for", "LFG:method"], ["maximum-entropy model:method", "used for", "stochastic output selection:task"], ["packed parse forests:other scientific term", "used for", "parse reduction:task"], ["transfer component:method", "used for", "parse reduction:task"]], "417": [["features of entities:other scientific term", "used for", "recovery:task"], ["prior structure:other scientific term", "used for", "recovery:task"], ["side information:other scientific term", "used for", "robust PCA:method"]], "419": [["decision-tree classifier:method", "used for", "grammatical relations -LRB- grs -RRB-:other scientific term"]], "420": [["tool:generic", "used for", "linguistic annotation of scfs:task"]], "421": [["visual pathway:method", "used for", "images:material"]], "424": [["Online action detection:task", "used for", "action positions:other scientific term"], ["Online action detection:task", "used for", "action type:other scientific term"], ["untrimmed stream:material", "used for", "Online action detection:task"]], "425": [["MT evaluation methods:metric", "used for", "classifiers:method"], ["classifiers:method", "used for", "entailment:task"], ["classifiers:method", "used for", "semantic equivalence:task"]], "426": [["PER:metric", "used for", "classification method:method"], ["PER:metric", "used for", "part of speech information:other scientific term"], ["part of speech information:other scientific term", "used for", "word matches and non-matches:task"]], "428": [["multinomial distributions:method", "used for", "nucleotides in a DNA sequence:material"], ["multinomial distributions:method", "used for", "text documents:material"]], "429": [["random sampling:method", "used for", "MINPRAN:method"]], "431": [["Plume:method", "used for", "declarative and imperative utterances:material"], ["it:generic", "used for", "interrogatives:other scientific term"], ["it:generic", "used for", "passives:other scientific term"], ["it:generic", "used for", "relative clauses:other scientific term"]], "432": [["smoothing:method", "used for", "unlexicalized parser:method"]], "433": [["convex problem:task", "used for", "side information:other scientific term"], ["method:generic", "used for", "low rank matrix:other scientific term"]], "437": [["algorithm:generic", "used for", "LR -LRB- 0 -RRB- grammars:method"]], "438": [["Criteria:generic", "used for", "anaphora resolution within sentence boundaries:task"], ["GB's binding theory:method", "used for", "Criteria:generic"], ["those:generic", "used for", "text-level anaphora:other scientific term"]], "442": [["acoustic measures:metric", "used for", "two:generic"], ["confidence tests:method", "used for", "UV procedure:method"], ["confidence tests:method", "used for", "hierarchical structure:other scientific term"], ["linguistic information:other scientific term", "used for", "one:generic"]], "443": [["It:generic", "used for", "submanifold:other scientific term"], ["cluster number estimation:task", "used for", "It:generic"], ["eigenvectors:other scientific term", "used for", "It:generic"], ["high dimensionality space:other scientific term", "used for", "submanifold:other scientific term"]], "444": [["algorithm:generic", "used for", "detection task:task"], ["algorithm:generic", "used for", "viewpoint classification task:task"]], "445": [["method:generic", "used for", "low rank matrices:other scientific term"]], "447": [["convolution tree kernel:method", "used for", "features:generic"]], "448": [["hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers:method", "used for", "detecting sentence boundaries:task"], ["textual and prosodic knowledge sources:material", "used for", "hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers:method"]], "450": [["generative model:method", "used for", "field structured text:material"], ["hidden Markov models -LRB- HMMs -RRB-:method", "used for", "generative model:method"]], "451": [["non-parallel corpus:material", "used for", "MT system:method"], ["parallel corpus:material", "used for", "MT system:method"]], "452": [["memo-functions:method", "used for", "parser:method"], ["parser:method", "used for", "non-LR grammars:method"]], "454": [["algorithm:generic", "used for", "Fujisaki-model parameters:other scientific term"], ["raw F0 contours:other scientific term", "used for", "Fujisaki-model parameters:other scientific term"], ["statistical methods:method", "used for", "algorithm:generic"]], "455": [["exhaustive procedure:method", "used for", "cascade evaluation:task"], ["method:generic", "used for", "search:task"]], "456": [["side information:other scientific term", "used for", "method:generic"]], "457": [["bio-inspired model:method", "used for", "analog programmable array processor -LRB- APAP -RRB-:task"], ["vertebrate retina:other scientific term", "used for", "bio-inspired model:method"]], "458": [["logical formalism:method", "used for", "determiners:task"]], "459": [["common ground:task", "used for", "human-computer interaction:task"], ["design:generic", "used for", "embodied conversational agents:method"], ["verbal and nonverbal means:method", "used for", "grounding:task"]], "460": [["meaning-entailing substitutability:metric", "used for", "semantic-oriented NLP applications:task"]], "461": [["distributional word feature vectors:other scientific term", "used for", "word similarity:task"]], "465": [["convolutional neural networks -LRB- CNN -RRB-:method", "used for", "feature extraction:other scientific term"], ["highly-curved manifolds:method", "used for", "pedestrian data:material"]], "468": [["histogram-based interest point detectors:method", "used for", "matching textured scenes:task"]], "469": [["method:generic", "used for", "fully automatic recognition system:method"]], "472": [["maximization of translation accuracy:metric", "used for", "training method:method"], ["statistical translation model:method", "used for", "phrases:generic"]], "473": [["Euclidean distance:other scientific term", "used for", "manifold learning methods:method"], ["graphical relationship:other scientific term", "used for", "geodesic distance:other scientific term"]], "474": [["deep model:method", "used for", "person re-identification:task"], ["robust deep metrics:other scientific term", "used for", "person re-identification:task"], ["state-of-the-art methods:generic", "used for", "person re-identification:task"]], "475": [["morphological analyzer:method", "used for", "recognition and classification of proper names, numerical and temporal expressions:task"]], "477": [["projective unifocal, bifo-cal, and trifocal tensors:method", "used for", "affine case:other scientific term"]], "478": [["geometric, appearance, or correlation-based information:other scientific term", "used for", "approaches:generic"]], "479": [["MAP estimation framework:method", "used for", "Multiple Instance Learning -LRB- MIL -RRB- formulation:method"], ["logistic softmax function of covariance-based region features:other scientific term", "used for", "Multiple Instance Learning -LRB- MIL -RRB- formulation:method"]], "481": [["expert games:material", "used for", "system:generic"]], "482": [["method:generic", "used for", "raw corpus:material"], ["segmented corpus:material", "used for", "model:generic"], ["word list:other scientific term", "used for", "method:generic"]], "483": [["model:generic", "used for", "on-line handwriting:task"]], "485": [["smoothing:method", "used for", "unlexicalized parser:method"], ["suffix analysis:method", "used for", "unlexicalized parser:method"], ["unlexicalized parser:method", "used for", "German:material"]], "487": [["prior knowledge:other scientific term", "used for", "field structured extraction tasks:task"]], "488": [["technique:generic", "used for", "search algorithm:method"]], "492": [["image information:other scientific term", "used for", "3--D shape:other scientific term"]], "494": [["Noun Classifier Associations -LRB- NCA -RRB-:method", "used for", "classifier assignment:task"], ["Noun Classifier Associations -LRB- NCA -RRB-:method", "used for", "semantic construction of noun phrase:task"], ["corpus-based method:method", "used for", "Noun Classifier Associations -LRB- NCA -RRB-:method"], ["corpus-based method:method", "used for", "classifier assignment:task"], ["corpus-based method:method", "used for", "semantic construction of noun phrase:task"]], "495": [["linguistic information:other scientific term", "used for", "loss functions:other scientific term"], ["syntactic structure:other scientific term", "used for", "loss functions:other scientific term"], ["word-to-word alignments:other scientific term", "used for", "loss functions:other scientific term"]], "496": [["automated evaluation techniques:method", "used for", "evaluation of human language learners:task"]], "499": [["regularizer:method", "used for", "low-rank matrix optimization:task"], ["regularizer:method", "used for", "or-thonormality:other scientific term"]], "501": [["robust principal component analysis -LRB- robust PCA -RRB- problem:method", "used for", "machine learning applications:task"]], "504": [["local optimization:method", "used for", "local mode of the similarity measure:other scientific term"], ["parameter space of translation, rotation and scale:other scientific term", "used for", "local mode of the similarity measure:other scientific term"]], "505": [["Techniques:generic", "used for", "automatically training modules:method"]], "506": [["Confidence tests:method", "used for", "decoded string hypotheses:other scientific term"]], "507": [["contemporary methods:generic", "used for", "unsupervised object discovery:task"]], "509": [["action model formalism:method", "used for", "methods:metric"], ["action model formalism:method", "used for", "re-active agent:method"], ["noise-handling mechanisms:method", "used for", "methods:metric"]], "511": [["TAGs:method", "used for", "automatic translation of natural language:task"], ["TAGs:method", "used for", "semantic interpretation:task"]], "512": [["automatic candidate generation:method", "used for", "sentential paraphrases:material"], ["class-oriented framework:method", "used for", "compositional classes of paraphrases:task"], ["manual judgement:method", "used for", "sentential paraphrases:material"]], "514": [["algorithm:generic", "used for", "eye contact:other scientific term"], ["cameras:other scientific term", "used for", "video streams:material"], ["virtual camera:other scientific term", "used for", "images:material"]], "515": [["layers of distributed representations:method", "used for", "object pose information:other scientific term"]], "517": [["approach:generic", "used for", "FERRET:method"], ["approach:generic", "used for", "Q/A:method"]], "520": [["method:generic", "used for", "branch-and-bound object detection:task"], ["method:generic", "used for", "cascade evaluation:task"], ["nonlinear quality functions:other scientific term", "used for", "branch-and-bound object detection:task"]], "523": [["labeled data:material", "used for", "semi-supervised methods:method"], ["labeled examples:material", "used for", "supervised methods:method"], ["unlabeled examples:material", "used for", "unsupervised methods:method"]], "524": [["deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork:method", "used for", "model:generic"]], "525": [["resources:generic", "used for", "liaisons:other scientific term"]], "526": [["components:generic", "used for", "intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-:task"], ["disambiguated morphological analysis:method", "used for", "aligned bilingual corpus:material"], ["lemmatized indexing:method", "used for", "aligned bilingual corpus:material"]], "527": [["unified framework:method", "used for", "reasoning:task"]], "530": [["compact geometric derivation:other scientific term", "used for", "novel-view synthesis:task"], ["dense-stereo dynamic-programming:method", "used for", "occlusion labeling:task"], ["direct projection of the minimum-cost surface:method", "used for", "compact geometric derivation:other scientific term"]], "531": [["Adaptive Simulated Annealing -LRB- ASA -RRB-:method", "used for", "it:generic"], ["global optimization problem:task", "used for", "object detection:task"]], "532": [["algorithm:generic", "used for", "rendering of occlusions:task"], ["algorithm:generic", "used for", "temporal artefacts -LRB- flicker -RRB-:other scientific term"], ["algorithm:generic", "used for", "temporal maintenance of a background model:task"], ["cost aggregation algorithm:method", "used for", "three-dimensional matching cost space:other scientific term"]], "533": [["representation:generic", "used for", "latter:generic"], ["representation:generic", "used for", "pose information:other scientific term"], ["view-invariant representation:method", "used for", "former:generic"]], "534": [["information:generic", "used for", "robust PCA:method"], ["low rank plus sparse structure:other scientific term", "used for", "approaches:generic"]], "536": [["classifiers:method", "used for", "three-way voting:method"]], "538": [["dictionary:material", "used for", "lattice:other scientific term"]], "540": [["approach:generic", "used for", "learned confidence measures:method"], ["automatically generated training data:material", "used for", "them:generic"]], "541": [["Bayesian inference techniques:method", "used for", "Gaussian models:method"], ["P\u00f3lya-gamma augmentation:task", "used for", "multinomial distribution:method"], ["logistic stick-breaking representation:method", "used for", "multinomial distribution:method"]], "542": [["Multi-view constraints:other scientific term", "used for", "matching:task"], ["Multi-view constraints:other scientific term", "used for", "reconstruction:task"], ["images:material", "used for", "acquisition of true three-dimensional affine and Euclidean models:task"], ["normalized representation:method", "used for", "matching:task"], ["normalized representation:method", "used for", "reconstruction:task"]], "543": [["TAGs:method", "used for", "syntax proper:other scientific term"], ["logical form language:other scientific term", "used for", "semantics:other scientific term"]], "544": [["automatic speech recognition -LRB- ASR -RRB-:method", "used for", "offset adaptation -LRB- OA -RRB- model:method"], ["pool models:method", "used for", "inner hair cell synapse:other scientific term"], ["visual inspection:method", "used for", "offset adaptation -LRB- OA -RRB- model:method"]], "547": [["sentence extraction:method", "used for", "summarization:task"]], "549": [["dependency network representation:method", "used for", "tag contexts:other scientific term"], ["fine-grained modeling of unknown word features:method", "used for", "part-of-speech tagger:method"], ["lexical features:other scientific term", "used for", "part-of-speech tagger:method"], ["priors in conditional loglinear models:other scientific term", "used for", "part-of-speech tagger:method"], ["tag contexts:other scientific term", "used for", "part-of-speech tagger:method"]], "550": [["photometric model:method", "used for", "image formation:task"], ["statistical model:method", "used for", "extreme illumination changes:other scientific term"], ["statistical model:method", "used for", "generic face appearance variation:task"]]}, "false_cases": {"3": [["Language resource quality:metric", "used for", "NLP:other scientific term"]], "8": [["It:generic", "used for", "empirical MT research:other scientific term"]], "15": [["beam-search decoder:method", "used for", "Translations:material"]], "17": [["self-assessments:generic", "used for", "intended emotions:other scientific term"]], "18": [["approaches:generic", "used for", "independent and relevant event-based extractive mutli-document summarization:task"]], "20": [["new view:other scientific term", "used for", "extensional reference:other scientific term"]], "21": [["combination methods:method", "used for", "system performance:metric"]], "22": [["approach:method", "used for", "VIVID benchmark datasets:material"]], "26": [["deep learning methods:method", "used for", "task:generic"]], "27": [["Background modeling:method", "used for", "vision systems:other scientific term"]], "29": [["novel approach:method", "used for", "automatically acquiring English topic signatures:task"]], "32": [["Prolog form:method", "used for", "the answer:generic"]], "36": [["validation:task", "used for", "these:generic"]], "37": [["different-quality references:other scientific term", "used for", "evaluation:task"]], "38": [["proposed approach:method", "used for", "experiments:task"], ["proposed approach:method", "used for", "performance:metric"]], "39": [["histogram information:other scientific term", "used for", "interest points:other scientific term"], ["method:generic", "used for", "interest points:other scientific term"]], "41": [["independent approach:method", "used for", "important contents:other scientific term"]], "42": [["Minimum Bayes-Risk -LRB- MBR -RRB-:method", "used for", "statistical machine translation:task"]], "47": [["synthesis of cyclopean views:method", "used for", "extended conversational sequences:other scientific term"]], "49": [["MINPRAN:method", "used for", "complex range and intensity data:material"], ["complex range and intensity data:material", "used for", "MINPRAN:method"]], "51": [["method:generic", "used for", "phrases:other scientific term"]], "54": [["sparse selectional preferences:other scientific term", "used for", "posterior:other scientific term"]], "55": [["application:task", "used for", "LCS-Marine:method"], ["application:task", "used for", "this approach:generic"]], "56": [["our algorithm:method", "used for", "simulations:task"], ["simulations:task", "used for", "our algorithm:method"]], "57": [["Machine transliteration/back-transliteration:method", "used for", "multilingual speech and language applications:task"]], "58": [["experimental results:other scientific term", "used for", "this paper:generic"]], "66": [["method:generic", "used for", "incremental probabilistic parser:method"]], "68": [["algorithm:method", "used for", "novel view generation:task"]], "69": [["UNL graphs:other scientific term", "used for", "this context:generic"]], "70": [["word spotting:task", "used for", "matching of cursive scripts:task"]], "71": [["hand-crafted rules:method", "used for", "basic syntactic knowledge:other scientific term"]], "72": [["Listen-Communicate-Show -LRB- LCS -RRB-:method", "used for", "human interaction:task"]], "73": [["algorithm:method", "used for", "noun:other scientific term"], ["classifier word:other scientific term", "used for", "noun:other scientific term"]], "77": [["information about meeting context:other scientific term", "used for", "classifiers' performances:metric"]], "81": [["integrated learning system:method", "used for", "simulated construction:task"]], "84": [["scheme:method", "used for", "output:generic"]], "85": [["method:generic", "used for", "non-parallel corpora:material"], ["method:generic", "used for", "parallel sentences:other scientific term"]], "86": [["processing of utterances:task", "used for", "discourse:other scientific term"], ["theory:other scientific term", "used for", "discourse:other scientific term"]], "89": [["scalable stochastic gradient descent algorithm:method", "used for", "resulting learning problem:task"]], "91": [["model-based approach:method", "used for", "on-line cursive handwriting analysis:task"], ["model-based approach:method", "used for", "recognition:task"], ["on-line cursive handwriting analysis:task", "used for", "recognition:task"]], "92": [["these approaches:generic", "used for", "object pose estimation:task"]], "93": [["Light fields:other scientific term", "used for", "scene description:other scientific term"]], "94": [["learning to read:task", "used for", "GLOSSER:method"], ["reading:task", "used for", "GLOSSER:method"]], "96": [["Japanese character strings:material", "used for", "segment:task"], ["Japanese character strings:material", "used for", "tag:task"], ["segment:task", "used for", "Japanese character strings:material"], ["tag:task", "used for", "Japanese character strings:material"]], "97": [["automated interpretation:task", "used for", "nominal compounds:other scientific term"], ["nominal compounds:other scientific term", "used for", "automated interpretation:task"]], "99": [["model:method", "used for", "blind separation of natural speech signals:task"]], "100": [["transliteration/backtransliteration experiments:task", "used for", "English/Chinese:material"], ["transliteration/backtransliteration experiments:task", "used for", "English/Japanese:material"], ["transliteration/backtransliteration experiments:task", "used for", "proposed methods:method"]], "102": [["specialized regression problem:task", "used for", "sampling probabilities:metric"]], "104": [["Branch and bound strategies:method", "used for", "global optimality:other scientific term"]], "108": [["learned confidence measures:other scientific term", "used for", "quality improvement:task"], ["learned confidence measures:other scientific term", "used for", "stereo vision:other scientific term"]], "110": [["large streaming video dataset:material", "used for", "model:method"]], "111": [["German:material", "used for", "translation direction:other scientific term"], ["search restriction:method", "used for", "translation direction:other scientific term"]], "114": [["complete cursive handwriting recognition:task", "used for", "experiments:generic"], ["dynamic representation:method", "used for", "complete cursive handwriting recognition:task"]], "115": [["high-capacity models:method", "used for", "computer vision:other scientific term"]], "118": [["intelligent agent:method", "used for", "request:generic"]], "119": [["method:generic", "used for", "space-time interest point detection:method"], ["space-time interest point detection:method", "used for", "method:generic"]], "120": [["polarization:other scientific term", "used for", "saturation:other scientific term"]], "122": [["approach:generic", "used for", "3D object categorization:task"], ["generative probabilistic framework:method", "used for", "3D object categorization:task"]], "124": [["gray-level band-pass white noise patterns:material", "used for", "indirect lighting:other scientific term"], ["gray-level band-pass white noise patterns:material", "used for", "scene discontinuities:other scientific term"]], "126": [["model:other scientific term", "used for", "modeling the knowledge sources:task"]], "128": [["training data:material", "used for", "fully automated manner:other scientific term"]], "129": [["enrichment:task", "used for", "human-machine interactions:other scientific term"]], "130": [["Chat-80:method", "used for", "variety of applications:task"]], "131": [["efficient novel-view generation:task", "used for", "technique:method"], ["technique:method", "used for", "efficient novel-view generation:task"]], "132": [["automatic scheme:method", "used for", "cooccurrence patterns:other scientific term"], ["automatic scheme:method", "used for", "large corpus:material"], ["automatic scheme:method", "used for", "statistics:metric"]], "133": [["Memo-functions:method", "used for", "compact representation:other scientific term"]], "135": [["Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-:method", "used for", "metric learning formulation:method"]], "136": [["synchronous TAGs:method", "used for", "correspondences between languages:other scientific term"], ["variant of TAGs:method", "used for", "correspondences between languages:other scientific term"]], "138": [["deep architectures:other scientific term", "used for", "object category recognition:task"]], "139": [["MSG -LRB- Modulation-filtered Spec-troGram -RRB- auditory features:other scientific term", "used for", "results:generic"]], "142": [["proposed approach:method", "used for", "cluttered scenes:other scientific term"]], "143": [["new research direction:task", "used for", "lack of structures:other scientific term"]], "144": [["Experiment results:material", "used for", "spectral clustering based approach:method"]], "145": [["perception of transparent objects:task", "used for", "vision:other scientific term"]], "149": [["this paper:generic", "used for", "object detection:task"]], "152": [["direction-giving task:task", "used for", "attentional focus:other scientific term"], ["direction-giving task:task", "used for", "eye gaze:other scientific term"], ["direction-giving task:task", "used for", "head nods:other scientific term"]], "154": [["Bayesian Network:method", "used for", "addressee identification:task"], ["Naive Bayes classifiers:method", "used for", "addressee identification:task"], ["four-participants face-to-face meetings:material", "used for", "addressee identification:task"]], "155": [["applications:task", "used for", "computer Go:task"]], "157": [["Chat-80:material", "used for", "prototype natural language question answering system:method"], ["This paper:generic", "used for", "prototype natural language question answering system:method"]], "158": [["Human action recognition:task", "used for", "well-segmented 3D skeleton data:material"]], "162": [["GLOSSER:method", "used for", "four language pairs:generic"]], "163": [["program:generic", "used for", "UNIX:material"], ["program:generic", "used for", "Windows '95:material"]], "164": [["training:task", "used for", "Euclidean distance:other scientific term"], ["training:task", "used for", "deep embedding methods:method"]], "166": [["high-quality data:material", "used for", "automatic evaluations:task"]], "169": [["Fast algorithms:method", "used for", "nearest neighbor -LRB- NN -RRB-:other scientific term"]], "172": [["LCS-Marine:method", "used for", "tactical personnel:generic"]], "173": [["Pustejovsky's principles:other scientific term", "used for", "predicative information:other scientific term"]], "177": [["PageRank algorithm:method", "used for", "important contents:other scientific term"], ["PageRank algorithm:method", "used for", "relevant approach:generic"]], "178": [["statistical approach:method", "used for", "expected loss of translation errors:metric"]], "179": [["MBR decoding:method", "used for", "specific loss functions:other scientific term"], ["MBR decoding:method", "used for", "statistical MT performance:metric"]], "180": [["classifiers:method", "used for", "conversational context:other scientific term"], ["classifiers:method", "used for", "speaker's gaze information:other scientific term"], ["classifiers:method", "used for", "utterance features:other scientific term"]], "181": [["first experiment:task", "used for", "intelligibility:other scientific term"]], "183": [["probability distribution:other scientific term", "used for", "legal moves:other scientific term"], ["probability distribution:other scientific term", "used for", "professional play:task"]], "185": [["subtask of regression optimization:task", "used for", "forecast the action:task"]], "186": [["our scheme:method", "used for", "promising performance:metric"]], "187": [["cluster analysis:method", "used for", "object:other scientific term"]], "189": [["unified account:method", "used for", "sentence-level and text-level anaphora:other scientific term"]], "190": [["word list:material", "used for", "language model adaptation methods:method"]], "192": [["estimation:task", "used for", "cycloidal motion parameters:other scientific term"], ["general procedure:method", "used for", "arbitrary handwriting:other scientific term"], ["general procedure:method", "used for", "cycloidal motion parameters:other scientific term"], ["quantization:task", "used for", "cycloidal motion parameters:other scientific term"]], "195": [["parameter training algorithm:method", "used for", "present model:other scientific term"]], "198": [["model-based approach:method", "used for", "known motion:other scientific term"], ["model-based approach:method", "used for", "poses:other scientific term"], ["model-based approach:method", "used for", "shapes:other scientific term"]], "199": [["convolution kernel:method", "used for", "syntactic structure information:other scientific term"], ["relation extraction:task", "used for", "syntactic structure information:other scientific term"]], "200": [["mi-cro phase shifting:method", "used for", "results:generic"], ["modulated phase shifting:method", "used for", "results:generic"], ["state of the art methods:method", "used for", "results:generic"]], "201": [["powerful pattern-matching language:method", "used for", "frames:other scientific term"]], "202": [["it:generic", "used for", "this problem:task"]], "203": [["this technique:method", "used for", "task dialogues:material"]], "204": [["non-native language essays:material", "used for", "language learning experiment:task"]], "205": [["experiment:task", "used for", "similar criteria:other scientific term"]], "206": [["automated technique:method", "used for", "reflections:other scientific term"], ["motion trajectories:other scientific term", "used for", "reflections:other scientific term"]], "207": [["Monte Carlo approach:method", "used for", "parameter space:other scientific term"]], "209": [["phrase-based statistical machine translation method:method", "used for", "non-contiguous phrases:other scientific term"], ["phrase-based statistical machine translation method:method", "used for", "phrases with gaps:other scientific term"]], "210": [["proposed method:method", "used for", "experimental results:material"]], "211": [["data-dependent bandwidth:method", "used for", "density estimation:method"]], "212": [["approach:generic", "used for", "distillation:task"], ["approach:generic", "used for", "document retrieval:task"], ["document retrieval:task", "used for", "distillation:task"], ["information extraction annotations:material", "used for", "document retrieval:task"]], "213": [["novel representation:method", "used for", "three-dimensional objects:other scientific term"]], "214": [["It:generic", "used for", "Japanese information extraction -LRB- -LSB- 3 -RSB- -RRB-:method"]], "215": [["approach:generic", "used for", "iterative deformation:method"], ["iterative deformation:method", "used for", "approach:generic"]], "216": [["English and Czech newspaper texts:material", "used for", "model:method"]], "217": [["binary-binary partial matrix-vector multiplication:task", "used for", "low-power analog array:method"], ["low-power analog array:method", "used for", "binary-binary partial matrix-vector multiplication:task"]], "219": [["distribution of natural images:other scientific term", "used for", "support vector machines:method"]], "220": [["ECA:method", "used for", "dialogue state:other scientific term"]], "223": [["topical blog post retrieval:task", "used for", "given topic:generic"]], "224": [["retrieval approach:method", "used for", "indicators:other scientific term"]], "226": [["combined approach:method", "used for", "image understanding:task"]], "228": [["ensembles:method", "used for", "significantly better results:metric"]], "229": [["multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method", "used for", "temporal localization information:other scientific term"]], "231": [["paraphrase classification:task", "used for", "technique:method"], ["technique:method", "used for", "accuracy:metric"], ["technique:method", "used for", "experiments:generic"]], "232": [["trainable sentence planner:method", "used for", "subjective human judgments:metric"]], "233": [["method:generic", "used for", "language pairs:other scientific term"], ["method:generic", "used for", "scarce resources:material"]], "234": [["multilingual corpus:material", "used for", "experiments:task"]], "238": [["Noise Spotting:task", "used for", "ASR system:method"], ["Word Spotting:task", "used for", "ASR system:method"]], "239": [["human effort:other scientific term", "used for", "pixel-level labels:other scientific term"]], "243": [["weakly supervised dependency parser:method", "used for", "speech syntax:other scientific term"]], "245": [["it:generic", "used for", "transparent objects:material"]], "246": [["probabilistic framework:method", "used for", "visual models of 3D object categories:method"]], "247": [["sentence condensation systems:task", "used for", "summarization quality:metric"], ["standard parser evaluation methods:method", "used for", "sentence condensation systems:task"]], "248": [["method:generic", "used for", "natural speech signals:material"]], "251": [["system:generic", "used for", "experiments:task"]], "254": [["learning to predict moves:task", "used for", "board game of Go:material"], ["learning to predict moves:task", "used for", "game records of expert players:material"]], "255": [["better training resources:material", "used for", "robust automatic abstracting systems:task"]], "257": [["numerical hybrid local and global mode-seeking tracker:method", "used for", "heavy occlusion:other scientific term"], ["numerical hybrid local and global mode-seeking tracker:method", "used for", "large camera motions:other scientific term"]], "258": [["new algorithm:method", "used for", "long stereo video streams:material"]], "259": [["statistics:other scientific term", "used for", "anaphora references:other scientific term"], ["statistics:other scientific term", "used for", "syntactic ambiguities:other scientific term"]], "260": [["new theory of discourse structure:other scientific term", "used for", "discourse:other scientific term"]], "263": [["central goal:generic", "used for", "research:generic"], ["merge approaches:task", "used for", "pivot MT:method"]], "264": [["person re-identification:task", "used for", "study:generic"]], "265": [["critical step:generic", "used for", "neuronal processing:task"], ["encoding sound:task", "used for", "discrete nerve-action potentials:other scientific term"], ["neuronal processing:task", "used for", "discrete nerve-action potentials:other scientific term"]], "270": [["generative framework:method", "used for", "model:method"], ["generative framework:method", "used for", "relative position of parts:other scientific term"]], "272": [["novel system:method", "used for", "adjectival subcategorization frames -LRB- scfs -RRB-:other scientific term"]], "273": [["proposed method:method", "used for", "system development effort:task"], ["proposed method:method", "used for", "transliteration accuracy:metric"]], "275": [["small set of records:material", "used for", "evaluating aggregate queries:task"]], "276": [["closed-form -LRB- analytical -RRB- solution:method", "used for", "cross-entropy:other scientific term"]], "277": [["feature weighting and selection function:method", "used for", "superior feature vectors:metric"], ["feature weighting and selection function:method", "used for", "word similarity performance:metric"]], "278": [["Chat-80:method", "used for", "extraposition grammars:method"]], "280": [["entailment:task", "used for", "MT evaluation techniques:method"], ["paraphrase classification:task", "used for", "MT evaluation techniques:method"], ["paraphrase classification:task", "used for", "useful features:other scientific term"]], "281": [["experiment:task", "used for", "pronoun:other scientific term"]], "282": [["extracted data:material", "used for", "state-of-the-art statistical machine translation system:method"]], "283": [["paper:generic", "used for", "example discourses:material"]], "284": [["method:generic", "used for", "application:task"], ["method:generic", "used for", "specific words:material"]], "286": [["general pen trajectory:other scientific term", "used for", "efficiently encoded:generic"], ["phase lags:other scientific term", "used for", "general pen trajectory:other scientific term"]], "289": [["light field triangulation:task", "used for", "geometric structures of 3D lines:other scientific term"]], "290": [["triangulation problem:task", "used for", "continuous and non-overlapping simplices:other scientific term"]], "292": [["approach:generic", "used for", "pixel-accurate semantic label maps:method"], ["images:material", "used for", "pixel-accurate semantic label maps:method"]], "293": [["modeling of the dynamic characteristics:task", "used for", "optical flow:other scientific term"]], "294": [["applications:task", "used for", "new domains:other scientific term"], ["applications:task", "used for", "technology:other scientific term"]], "295": [["Lexical-Functional Grammars -LRB- LFG -RRB-:other scientific term", "used for", "sentence condensation:task"], ["ambiguity packing:method", "used for", "sentence condensation:task"]], "299": [["problem:task", "used for", "reconstructing the motion of a 3D articulated tree:task"]], "301": [["domain-specific models of actions:method", "used for", "planning systems:method"]], "302": [["training instances:material", "used for", "action models:method"], ["variant of GOLEM:method", "used for", "action models:method"]], "303": [["automated segmentation:task", "used for", "images:material"], ["automated segmentation:task", "used for", "semantically meaningful parts:other scientific term"]], "304": [["search procedure:method", "used for", "statistical machine translation -LRB- MT -RRB-:other scientific term"]], "305": [["experimental tests:task", "used for", "limited-domain spoken-language task:task"]], "306": [["explanations:generic", "used for", "behaviour:generic"]], "308": [["sentence-by-sentence error correction method:method", "used for", "decrease of productivity:metric"]], "309": [["MINPRAN:method", "used for", "robust operator:other scientific term"]], "311": [["learned metric:other scientific term", "used for", "better generalization ability:other scientific term"], ["learning:task", "used for", "better generalization ability:other scientific term"], ["metric weight constraint:method", "used for", "better generalization ability:other scientific term"]], "312": [["full scale two-level morphological description:method", "used for", "Turkish word structures:other scientific term"]], "313": [["our method:method", "used for", "PASCAL VOC 2006 dataset:material"], ["our method:method", "used for", "acceleration:metric"]], "314": [["1 distance:other scientific term", "used for", "approach:generic"]], "315": [["it:generic", "used for", "experimentation:task"], ["methodology:method", "used for", "experimentation:task"]], "316": [["anisotropic meshing:method", "used for", "satisfactory reconstruction results:metric"], ["anisotropic meshing:method", "used for", "triangulations:other scientific term"], ["non-quadratic approach to regularization:method", "used for", "satisfactory reconstruction results:metric"]], "318": [["high-resolution parallel inner-product computation:task", "used for", "image processing:task"], ["mixed-signal paradigm:method", "used for", "kernels:other scientific term"]], "319": [["approach:generic", "used for", "real image data:material"]], "321": [["email conversation:material", "used for", "email summarization:task"], ["our work:generic", "used for", "email summarization:task"]], "322": [["camera handoff:task", "used for", "wide-area surveillance scenarios:task"]], "323": [["systems:generic", "used for", "data retrieval:task"]], "326": [["game tree search:task", "used for", "move selector:method"], ["game tree search:task", "used for", "move sorter:method"], ["move selector:method", "used for", "Go players:generic"], ["move selector:method", "used for", "game tree search:task"], ["move sorter:method", "used for", "game tree search:task"], ["training tool:method", "used for", "Go players:generic"]], "330": [["processing description:other scientific term", "used for", "recognition tasks:task"], ["recognition tasks:task", "used for", "processing description:other scientific term"]], "332": [["problems in computer vision:task", "used for", "person re-identification:task"]], "333": [["auditory nerve -LRB- AN -RRB-:other scientific term", "used for", "phase locking:other scientific term"]], "334": [["Multi-layer perceptrons -LRB- MLPs -RRB-:method", "used for", "ANF-based auditory features:other scientific term"], ["Multi-layer perceptrons -LRB- MLPs -RRB-:method", "used for", "ON-based auditory features:other scientific term"]], "335": [["It:generic", "used for", "current work in unsupervised object discovery:task"], ["dataset of scenes:material", "used for", "current work in unsupervised object discovery:task"]], "336": [["problem:task", "used for", "text-to-speech synthesis:method"], ["speech:material", "used for", "text-to-speech synthesis:method"], ["text input:material", "used for", "text-to-speech synthesis:method"]], "337": [["differential features:other scientific term", "used for", "3--D reconstruction:task"], ["differential features:other scientific term", "used for", "constraints:other scientific term"], ["differential features:other scientific term", "used for", "tools:generic"]], "338": [["unsupervised learning approach:method", "used for", "named entities:other scientific term"]], "339": [["estimation of the tensors:task", "used for", "factorization:method"]], "340": [["classifier:other scientific term", "used for", "noun:other scientific term"]], "346": [["features:other scientific term", "used for", "structure of email-threads:other scientific term"], ["question-answer pairing:task", "used for", "features:other scientific term"]], "348": [["sentence boundary detection:task", "used for", "speech recognition output:other scientific term"]], "352": [["FERRET:method", "used for", "interactive question-answering -LRB- Q/A -RRB-:method"]], "354": [["failure to understand the speaker's intention:task", "used for", "misunderstandings:other scientific term"], ["mistakes:other scientific term", "used for", "misunderstandings:other scientific term"]], "355": [["discourse phenomena:other scientific term", "used for", "adequate explanation:generic"], ["distinction:other scientific term", "used for", "adequate explanation:generic"], ["distinction:other scientific term", "used for", "discourse phenomena:other scientific term"]], "357": [["variety of methods:method", "used for", "experiments:generic"], ["variety of methods:method", "used for", "speech recognition accuracies:metric"]], "358": [["Metagrammatical formalisms:method", "used for", "generalizations about the syntax of natural languages:task"]], "359": [["Constrained Delaunay Triangulation -LRB- CDT -RRB-:method", "used for", "line constraints:other scientific term"], ["algorithm:method", "used for", "Constrained Delaunay Triangulation -LRB- CDT -RRB-:method"], ["algorithm:method", "used for", "line constraints:other scientific term"]], "360": [["auditory processing:task", "used for", "OA:other scientific term"], ["auditory processing:task", "used for", "auditory brainstem:other scientific term"], ["auditory processing:task", "used for", "onset neurons -LRB- ONs -RRB-:other scientific term"]], "362": [["statistical model:method", "used for", "generating process of speech F0 contours:task"]], "363": [["method:generic", "used for", "object detection cascades:method"]], "364": [["information distillation:task", "used for", "relevant pieces of information:other scientific term"]], "365": [["morphological analysis problem:task", "used for", "Japanese text:material"]], "367": [["generic mathematical formalism:method", "used for", "products of them:other scientific term"], ["generic mathematical formalism:method", "used for", "various structures:other scientific term"]], "368": [["computing:task", "used for", "Kullback-Leibler distance:other scientific term"], ["computing:task", "used for", "relative entropy:other scientific term"]], "370": [["second-order vector cooccurrence algorithm:method", "used for", "topic signatures:other scientific term"]], "371": [["joint matrix triangularization:method", "used for", "joint eigenstructure:other scientific term"], ["machine learning:task", "used for", "joint matrix triangularization:method"], ["signal processing:task", "used for", "joint matrix triangularization:method"]], "372": [["training data:material", "used for", "tedious and time consuming task:task"]], "374": [["joint classification and regression optimization objective:method", "used for", "start and end points of actions:task"], ["start and end points of actions:task", "used for", "network:method"]], "375": [["maximum entropy classifier:method", "used for", "pair of sentences:material"], ["pair of sentences:material", "used for", "translations:task"]], "376": [["NE item:other scientific term", "used for", "final output:other scientific term"], ["segment:other scientific term", "used for", "final output:other scientific term"]], "377": [["Plume's approach to parsing:method", "used for", "semantic caseframe instantiation:method"]], "380": [["IEMOCAP database:material", "used for", "continuous -LRB- attribute -RRB- emotional assessments:other scientific term"], ["IEMOCAP database:material", "used for", "discrete -LRB- categorical -RRB- emotional assessments:other scientific term"]], "381": [["separation method:method", "used for", "separated signals:other scientific term"]], "382": [["our method:method", "used for", "scene geometry:other scientific term"]], "383": [["development of machine translation systems:task", "used for", "evaluation techniques:method"], ["evaluation techniques:method", "used for", "information:generic"], ["translation process:task", "used for", "evaluation techniques:method"]], "384": [["trajectory basis:method", "used for", "smooth motion:other scientific term"]], "386": [["exhaustive comparison:task", "used for", "baseline sentence planners:method"], ["exhaustive comparison:task", "used for", "hand-crafted template-based generation component:method"], ["exhaustive comparison:task", "used for", "rule-based sentence planners:method"]], "387": [["Convolutional Neural Networks -LRB- CNN -RRB-:method", "used for", "task of simultaneous object recognition and pose estimation:task"]], "388": [["line-assisted graph-cut -LRB- LAGC -RRB-:method", "used for", "light field stereo matching:task"]], "392": [["formalism:other scientific term", "used for", "HPSG:other scientific term"], ["formalism:other scientific term", "used for", "LFG:other scientific term"], ["formalism:other scientific term", "used for", "TAG:other scientific term"], ["formalism:other scientific term", "used for", "dependency grammars:other scientific term"], ["formalism:other scientific term", "used for", "grammar formalisms:other scientific term"], ["formalism:other scientific term", "used for", "rewriting systems:other scientific term"]], "394": [["treebank:material", "used for", "compact lexicon:method"]], "395": [["novel framework:method", "used for", "direct orthographical mapping -LRB- DOM -RRB-:method"], ["novel framework:method", "used for", "machine transliteration/backtransliteration:task"]], "396": [["joint source-channel transliteration model:method", "used for", "transliteration process:task"], ["transliteration process:task", "used for", "joint source-channel transliteration model:method"]], "398": [["carrying out this task:task", "used for", "laboratory study:method"]], "401": [["credibility indicators:other scientific term", "used for", "retrieval effectiveness:metric"]], "402": [["Natural Language Processing -LRB- NLP -RRB-:other scientific term", "used for", "applications:generic"], ["topic signatures:other scientific term", "used for", "Natural Language Processing -LRB- NLP -RRB-:other scientific term"], ["topic signatures:other scientific term", "used for", "Text Summarisation:task"], ["topic signatures:other scientific term", "used for", "Word Sense Disambiguation -LRB- WSD -RRB-:task"], ["topic signatures:other scientific term", "used for", "applications:generic"]], "404": [["mixtures of feature distributions:method", "used for", "color:other scientific term"], ["mixtures of feature distributions:method", "used for", "texture:other scientific term"], ["shape constrained image segmentation:task", "used for", "color:other scientific term"], ["shape constrained image segmentation:task", "used for", "probabilistic shape knowledge:other scientific term"], ["shape constrained image segmentation:task", "used for", "texture:other scientific term"]], "405": [["LR-parser:method", "used for", "grammars with regular expressions:other scientific term"]], "407": [["correcting the positions:task", "used for", "words in the list:material"], ["this paper:generic", "used for", "correcting the positions:task"], ["words in the list:material", "used for", "correcting the positions:task"]], "408": [["novel moderate positive sample mining method:method", "used for", "person re-identification:task"], ["person re-identification:task", "used for", "novel moderate positive sample mining method:method"], ["person re-identification:task", "used for", "robust CNN:method"]], "412": [["2 NN search:task", "used for", "random-projection based methods:method"], ["locality-sensitive hashing -LRB- LSH -RRB-:method", "used for", "2 NN search:task"], ["random projection trees:method", "used for", "2 NN search:task"], ["random-projection based methods:method", "used for", "2 NN search:task"]], "413": [["dictionary lookup stage:method", "used for", "information:generic"], ["set of rules:method", "used for", "NE items:other scientific term"]], "415": [["this paper:generic", "used for", "detailed design:generic"]], "416": [["linguistic parser/generator for LFG:method", "used for", "system:generic"], ["maximum-entropy model:method", "used for", "system:generic"], ["transfer component for parse reduction:method", "used for", "system:generic"]], "417": [["features of entities:other scientific term", "used for", "robust PCA:task"], ["prior structure:other scientific term", "used for", "robust PCA:task"], ["side information:other scientific term", "used for", "robust PCA:task"]], "419": [["decision-tree classifier:method", "used for", "output of a robust statistical parser:other scientific term"]], "420": [["subcategorization acquisition:task", "used for", "linguistic annotation:method"], ["tool:method", "used for", "linguistic annotation:method"], ["tool:method", "used for", "subcategorization acquisition:task"]], "421": [["early vision applications:task", "used for", "visual pathway:other scientific term"]], "422": [["this model:generic", "used for", "task:generic"]], "424": [["online action detection:task", "used for", "action positions:other scientific term"]], "426": [["classification method:method", "used for", "PER:other scientific term"]], "428": [["children's names in a given state and year:material", "used for", "multinomial distributions:other scientific term"], ["nucleotides in a DNA sequence:material", "used for", "multinomial distributions:other scientific term"], ["text documents:material", "used for", "multinomial distributions:other scientific term"]], "430": [["NIST Automatic Content Extraction -LRB- ACE -RRB-:task", "used for", "task:generic"]], "431": [["Plume:method", "used for", "simple declarative and imperative utterances:other scientific term"]], "433": [["proposed method:method", "used for", "robust PCA:method"]], "434": [["convolution kernel over parse trees:method", "used for", "24 ACE relation subtypes:other scientific term"]], "442": [["UV procedure:method", "used for", "three different confidence tests:other scientific term"]], "443": [["It:generic", "used for", "cluster number estimation:task"]], "444": [["detection task:task", "used for", "algorithm:method"], ["viewpoint classification task:task", "used for", "algorithm:method"]], "445": [["our proposed method:method", "used for", "low rank matrices:other scientific term"]], "447": [["relation extraction:task", "used for", "syntactic structure features:other scientific term"]], "448": [["detecting sentence boundaries:task", "used for", "hidden Markov model -LRB- HMM -RRB-:method"], ["detecting sentence boundaries:task", "used for", "maximum entropy -LRB- Maxent -RRB- classifiers:method"], ["textual and prosodic knowledge sources:other scientific term", "used for", "detecting sentence boundaries:task"]], "450": [["generative model:other scientific term", "used for", "field structured text:other scientific term"]], "451": [["good-quality MT system:method", "used for", "large non-parallel corpus:material"], ["large non-parallel corpus:material", "used for", "good-quality MT system:method"]], "453": [["bilingual corpus:material", "used for", "specific and special domain of HK laws:other scientific term"]], "454": [["efficient algorithm:method", "used for", "Fujisaki-model parameters:other scientific term"], ["model:method", "used for", "Fujisaki-model parameters:other scientific term"]], "455": [["search:task", "used for", "proposed method:method"]], "456": [["noisy image classification:task", "used for", "our method:method"], ["our method:method", "used for", "performance:metric"], ["real application:task", "used for", "our method:method"], ["synthetic experiments:task", "used for", "our method:method"]], "458": [["logical formalism:method", "used for", "determiners:other scientific term"], ["logical formalism:method", "used for", "interpretation:other scientific term"], ["logical formalism:method", "used for", "meaning:other scientific term"]], "459": [["design for embodied conversational agents:method", "used for", "common ground:other scientific term"], ["design for embodied conversational agents:method", "used for", "grounding:other scientific term"], ["human-computer interaction:task", "used for", "design for embodied conversational agents:method"], ["verbal and nonverbal means:other scientific term", "used for", "grounding:other scientific term"]], "460": [["criterion:other scientific term", "used for", "meaning-entailing substitutability:other scientific term"]], "461": [["distributional word feature vectors:material", "used for", "evaluating feature vector quality:task"]], "465": [["convolutional neural networks -LRB- CNN -RRB-:method", "used for", "capability of feature extraction:other scientific term"]], "466": [["ACE events:material", "used for", "information retrieval engine:method"]], "467": [["Japanese text:material", "used for", "morphological analysis:task"], ["morphological analysis:task", "used for", "Japanese text:material"]], "468": [["matching textured scenes:task", "used for", "histogram-based interest point detectors:method"]], "469": [["evaluation:task", "used for", "fully automatic recognition system:method"], ["fully automatic recognition system:method", "used for", "evaluation:task"], ["fully automatic recognition system:method", "used for", "proposed method:method"], ["proposed method:method", "used for", "fully automatic recognition system:method"]], "471": [["nine standard person re-identification datasets:material", "used for", "new method:method"]], "472": [["maximization of translation accuracy:task", "used for", "statistical translation model:method"]], "474": [["deep model:method", "used for", "robust deep metrics:metric"], ["person re-identification:task", "used for", "deep model:method"]], "475": [["morphological analyzer:method", "used for", "Named Entity -LRB- NE -RRB-:other scientific term"], ["recognition and classification:task", "used for", "Named Entity -LRB- NE -RRB-:other scientific term"]], "479": [["Multiple Instance Learning -LRB- MIL -RRB-:method", "used for", "problem:generic"], ["logistic softmax function:other scientific term", "used for", "problem:generic"]], "480": [["system:generic", "used for", "challenging data set:material"]], "484": [["tagger:method", "used for", "97.24% accuracy:metric"], ["tagger:method", "used for", "Penn Treebank WSJ:material"], ["tagger:method", "used for", "best previous single automatically learned tagging result:other scientific term"], ["tagger:method", "used for", "error reduction of 4.4%:metric"]], "485": [["unlexicalized parser:method", "used for", "labelled bracket F-score:metric"]], "486": [["word senses:other scientific term", "used for", "method:generic"]], "487": [["field structured extraction tasks:task", "used for", "effective models:other scientific term"]], "488": [["novel technique:method", "used for", "efficient search algorithm:method"], ["traveling salesman problem:task", "used for", "DP-based solution:method"]], "491": [["local range:other scientific term", "used for", "training the CNN embedding:task"], ["training the CNN embedding:task", "used for", "local range:other scientific term"], ["training the CNN embedding:task", "used for", "suitable positive -LRB- i.e. intra-class -RRB- training samples:material"]], "492": [["3--D stereo reconstruction scheme:method", "used for", "3--D shape:other scientific term"], ["3--D stereo reconstruction scheme:method", "used for", "image information:other scientific term"], ["a priori geometric constraints:other scientific term", "used for", "3--D shape:other scientific term"]], "494": [["corpus-based method:method", "used for", "Noun Classifier Associations -LRB- NCA -RRB-:other scientific term"]], "495": [["hierarchy of loss functions:method", "used for", "linguistic information:other scientific term"]], "496": [["automated evaluation techniques:method", "used for", "efficacy:metric"], ["automated evaluation techniques:method", "used for", "human language learners:other scientific term"], ["automated evaluation techniques:method", "used for", "research:generic"]], "498": [["dynamic programming approach:method", "used for", "general trajectories:other scientific term"]], "499": [["new type of regularizer:method", "used for", "matrix rank degeneration:other scientific term"]], "500": [["Automatic Speech Recognition -LRB- ASR -RRB- System:method", "used for", "real applications:generic"], ["Utterance Verification -LRB- UV -RRB-:task", "used for", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"], ["Utterance Verification -LRB- UV -RRB-:task", "used for", "acoustic noises:other scientific term"], ["Utterance Verification -LRB- UV -RRB-:task", "used for", "out-of-vocabulary -LRB- OOV -RRB- words:other scientific term"], ["Utterance Verification -LRB- UV -RRB-:task", "used for", "spontaneous speech:other scientific term"]], "501": [["data matrix:material", "used for", "robust principal component analysis -LRB- robust PCA -RRB-:other scientific term"], ["machine learning applications:task", "used for", "robust principal component analysis -LRB- robust PCA -RRB-:other scientific term"]], "502": [["three important requirements:other scientific term", "used for", "task:generic"]], "505": [["techniques:method", "used for", "natural language generator:method"]], "506": [["UV procedure:method", "used for", "decoded string hypotheses:other scientific term"]], "508": [["experiments on real data sets:task", "used for", "detector:other scientific term"]], "510": [["English-Chinese bitexts:material", "used for", "laws of Hong Kong:material"]], "511": [["application of TAGs:task", "used for", "automatic translation of natural language:task"], ["application of TAGs:task", "used for", "semantic interpretation:task"]], "512": [["class-oriented framework:method", "used for", "automatic candidate generation:method"], ["class-oriented framework:method", "used for", "compositional classes of paraphrases:other scientific term"], ["class-oriented framework:method", "used for", "manual judgement:method"], ["paraphrase examples:material", "used for", "sentential paraphrases:material"]], "514": [["arbitrary position:other scientific term", "used for", "eye contact:task"], ["eye contact:task", "used for", "proposed algorithm:method"], ["proposed algorithm:method", "used for", "virtual camera:method"]], "515": [["layers:other scientific term", "used for", "object pose information:other scientific term"]], "516": [["real telephone application:material", "used for", "natural number recognition task:task"]], "517": [["FERRET:method", "used for", "Q/A:other scientific term"], ["Q/A:other scientific term", "used for", "answers:other scientific term"], ["Q/A:other scientific term", "used for", "questions:other scientific term"]], "518": [["discourse processing:task", "used for", "utterances:other scientific term"]], "520": [["efficient branch-and-bound object detection:task", "used for", "kernel-ized support vector machines:method"], ["method:generic", "used for", "efficient branch-and-bound object detection:task"]], "524": [["deep Long Short-Term Memory -LRB- LSTM -RRB-:method", "used for", "complex long-range temporal dynamics:other scientific term"], ["proposed model:method", "used for", "complex long-range temporal dynamics:other scientific term"], ["proposed model:method", "used for", "high computational efficiency:metric"]], "526": [["demonstration:method", "used for", "Applied Natural Language Processing:method"], ["demonstration:method", "used for", "intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-:method"]], "528": [["domain independent features:method", "used for", "machine learning algorithms:method"], ["input dataset:material", "used for", "domain independent features:method"]], "530": [["novel-view synthesis:task", "used for", "compact geometric derivation:method"]], "531": [["Adaptive Simulated Annealing -LRB- ASA -RRB-:method", "used for", "global optimization problem:task"], ["Adaptive Simulated Annealing -LRB- ASA -RRB-:method", "used for", "object detection:task"], ["object detection:task", "used for", "Adaptive Simulated Annealing -LRB- ASA -RRB-:method"]], "532": [["rendering of occlusions:task", "used for", "novel algorithm:method"], ["temporal maintenance:task", "used for", "rendering of occlusions:task"]], "533": [["Object Recognition task:task", "used for", "categorization of objects:task"], ["Object Recognition task:task", "used for", "estimating object pose:task"], ["Object Recognition task:task", "used for", "representation capable of capturing pose information:method"], ["Object Recognition task:task", "used for", "view-invariant representation:method"]], "535": [["methods:method", "used for", "global meaning:other scientific term"]], "536": [["CRF model:method", "used for", "NIST sentence boundary detection task:task"], ["CRF model:method", "used for", "speech:other scientific term"], ["HMM:method", "used for", "NIST sentence boundary detection task:task"], ["HMM:method", "used for", "speech:other scientific term"], ["Max-ent models:method", "used for", "NIST sentence boundary detection task:task"], ["Max-ent models:method", "used for", "speech:other scientific term"], ["NIST sentence boundary detection task:task", "used for", "HMM:method"], ["NIST sentence boundary detection task:task", "used for", "Max-ent models:method"]], "537": [["face images:material", "used for", "training:task"], ["recognition input:task", "used for", "video sequences:material"], ["training:task", "used for", "recognition input:task"], ["training:task", "used for", "video sequences:material"], ["video sequences:material", "used for", "training:task"]], "540": [["KITTI2012 dataset:material", "used for", "performance:metric"], ["automatically generated training data:material", "used for", "learned confidence measures:method"], ["learned confidence measures:method", "used for", "performance:metric"]], "542": [["matching:task", "used for", "multiple images:material"], ["reconstruction:task", "used for", "multiple images:material"]], "543": [["formalism:other scientific term", "used for", "natural languages:other scientific term"]], "547": [["sentence extraction:method", "used for", "summary:other scientific term"], ["summarization:task", "used for", "sentence extraction:method"]], "549": [["part-of-speech tagger:method", "used for", "lexical features:other scientific term"], ["part-of-speech tagger:method", "used for", "multiple consecutive words:other scientific term"], ["part-of-speech tagger:method", "used for", "priors in conditional loglinear models:other scientific term"], ["part-of-speech tagger:method", "used for", "unknown word features:other scientific term"]]}, "error_cases": {}}