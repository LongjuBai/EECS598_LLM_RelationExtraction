{"micro_pc": 0.10815669019685271, "macro_pc": 0.051248357424441525, "pc_list": {"used for": 0.0702247191011236, "feature of": 0.021052631578947368, "compare": 0.13793103448275862, "evaluated for": 0.0, "conjunction": 0.5, "hyponym of": 0.0, "part of": 0.027888446215139442}, "micro_rc": 0.043615281512629264, "macro_rc": 0.04004106776180698, "rc_list": {"used for": 0.04690431519699812, "feature of": 0.03389830508474576, "compare": 0.10526315789473684, "evaluated for": 0.0, "conjunction": 0.008130081300813009, "hyponym of": 0.0, "part of": 0.1111111111111111}, "micro_f1": 0.03745799541979939, "macro_f1": 0.044956772334293946, "f1_list": {"used for": 0.056242969628796394, "feature of": 0.025974025974025976, "compare": 0.11940298507462686, "evaluated for": 0, "conjunction": 0.016, "hyponym of": 0, "part of": 0.044585987261146494}, "num_cases": 551, "accuracy": 0.15789473684210525, "correct_cases": {"0": {"text": "Experimental results are encouraging.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "2": {"text": "The analyzer is called \"Amorph\".", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "4": {"text": "Preliminary modeling and recognition results are presented.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "6": {"text": "A unique form of reg-ularization is also needed.", "true": [], "pred": [], "response": "\n"}, "9": {"text": "Turkish has finite-state but nevertheless rather complex morphotactics.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "12": {"text": "This raises questions about the validity of such approaches.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "14": {"text": "Basic methodology and practical techniques are reported in detail.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "16": {"text": "Basically, there is no exact rule for classifier selection.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "17": {"text": "Therefore, self-assessments will be closer to the intended emotions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "18": {"text": "We investigate independent and relevant event-based extractive mutli-document summarization approaches.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "19": {"text": "The classifiers show little gain from information about meeting context.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "25": {"text": "Unconstrained MPS grammars, unfortunately, are not computationally safe.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "28": {"text": "The result theoretically justifies the effectiveness of features in robust PCA.", "true": [["features:other scientific term", "feature of", "robust PCA:method"]], "pred": [["features:other scientific term", "feature of", "robust PCA:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "30": {"text": "Such mistakes can slow, and possibly break down, communication.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "32": {"text": "Finally, the Prolog form is executed to yield the answer.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "41": {"text": "With independent approach, we identify important contents by frequency of events.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "43": {"text": "We discuss how these might be satisfied by future Natural Language systems.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "45": {"text": "Reflections in image sequences consist of several layers superimposed over each other.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "46": {"text": "Our goal is to recognize and isolate such miscommunications and circumvent them.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "60": {"text": "Even more illuminating was the factors on which the assessors made their decisions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "62": {"text": "Both learners perform well, yielding similar success rates of approx 90%.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "69": {"text": "For various reasons, UNL graphs are the best candidates in this context.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "76": {"text": "Unlike standard regression problems, the loss is inversely proportional to the regressed-to values.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "77": {"text": "Then, we explore whether information about meeting context can aid classifiers' performances.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "78": {"text": "Subjects were given a set of up to six extracts of translated newswire text.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "80": {"text": "We demonstrate the bound on synthetic data for which the ground truth is known.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "95": {"text": "Surprisingly enough, similar scores are obtained in many cases regardless of the quality.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "98": {"text": "The results indicate that there is a mismatch between the expression and perception of emotion.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "101": {"text": "A prototype chip has been designed and fabricated in a 0.5 \u00b5m standard CMOS process.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "103": {"text": "Additionally, they were asked to mark the word at which they made this decision.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "106": {"text": "The bound depends only on the observable matrices in M' and the noise level.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "109": {"text": "Our experimental results show that the scheme is stable, reproducible and intuitive to use.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "120": {"text": "The polarization of the objects of the elementary structures controls the saturation of the final structure.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "128": {"text": "This enables us to generate a huge amount of training data in a fully automated manner.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "137": {"text": "These parameters are then quantized into a small number of values without altering the writing intelligibility.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "139": {"text": "Similar results were previously obtained with MSG -LRB- Modulation-filtered Spec-troGram -RRB- auditory features -LSB- 2 -RSB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "141": {"text": "Existing work in the area has mostly addressed scenes that consist of static or quasi-static structures.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "143": {"text": "This work proposes a new research direction to address the lack of structures in traditional n-gram models.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "150": {"text": "Thus the resulting detectors are not robust and highly depend on the choice of the training examples.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "159": {"text": "In this paper, we study the problem of online action detection from the streaming skeleton data.", "true": [["streaming skeleton data:material", "used for", "online action detection:task"]], "pred": [["streaming skeleton data:material", "used for", "online action detection:task"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "172": {"text": "Using LCS-Marine, tactical personnel can converse with their logistics system to place a supply or information request.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "185": {"text": "Furthermore, the subtask of regression optimization provides the ability to forecast the action prior to its occurrence.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "188": {"text": "The attentional state is an abstraction of the focus of attention of the participants as the discourse unfolds.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "193": {"text": "We extensively experiment on two recent large and challenging multi-view datasets and we achieve better than the state-of-the-art.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "210": {"text": "Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "218": {"text": "We examine a broad range of texts to show how the distribution of demonstrative forms and functions is genre dependent.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "221": {"text": "We provide an efficient and simple regularized Empirical Risk Minimization -LRB- ERM -RRB- algorithm along with a theoretical generalization result.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "227": {"text": "Experimental evidence shows that semantically meaningful segments are inferred, even when image data alone gives rise to ambiguous segmentations.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "235": {"text": "Instead it assumes that the bad data are randomly -LRB- uniformly -RRB- distributed within the dynamic range of the sensor.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "236": {"text": "We show that none of them satisfies both criteria, and suggest new directions for research on alternative metagrammatical formalisms.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "244": {"text": "This enables us to obtain an affine specialization of known projective relations connecting points and lines across two or three views.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "256": {"text": "However, one can dramatically improve the quality of the learned structure by exploiting simple prior knowledge of the desired solutions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "262": {"text": "Versions in some other languages known by the user may be displayed, so that improvement sharing is visible and encouraging.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "267": {"text": "Requestors can also instruct the system to notify them when the status of a request changes or when a request is complete.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "286": {"text": "By slow modulations of the amplitudes and phase lags of the two oscillators, a general pen trajectory can be efficiently encoded.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "308": {"text": "In this sentence-by-sentence error correction method, however, the annotator encounters grammatically complicated positions and this results in a decrease of productivity.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "310": {"text": "We discuss the application of synchronous TAGs to concrete examples, mentioning primarily in passing some computational issues that arise in its interpretation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "329": {"text": "The attentional state, being dynamic, records the objects, properties, and relations that are salient at each point of the discourse.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "331": {"text": "But computational linguists seem to be quite dubious about analogies between sentences: they would not be enough numerous to be of any use.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "341": {"text": "Registration of classifier for each noun is limited to the type of unit classifier because other types are open due to the meaning of representation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "345": {"text": "The speakers in the database assigned their own emotions to more specific emotional categories, which led to more extreme values in the activation-valence space.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "359": {"text": "We instead present a simple but effective algorithm to first map bilinear subspaces to line constraints and then apply Constrained Delaunay Triangulation -LRB- CDT -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "373": {"text": "In this paper, we present methods by which an agent learns action models from its own experience and from its observation of a domain expert.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "375": {"text": "We train a maximum entropy classifier that, given a pair of sentences, can reliably determine whether or not they are translations of each other.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "397": {"text": "The distribution of nonverbal behaviors differed depending on the type of dialogue move being grounded, and the overall pattern reflected a monitoring of lack of negative feedback.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "399": {"text": "Our preliminary experiments on building a paraphrase corpus have so far been producing promising results, which we have evaluated according to cost-efficiency, exhaustiveness, and reliability.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "410": {"text": "Morphemes added to a root word or a stem can convert the word from a nominal to a verbal structure or vice-versa, or can create adverbial constructs.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "418": {"text": "This paper analyzes the validity of this assumption by comparing the mismatches between the assessments made by na \u00a8 \u0131ve listeners and by the speakers that generated the data.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "427": {"text": "If is is satisfactory, the errors were probably due to the graph, not to the deconverter, and the graph is sent to deconverters in other languages.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "439": {"text": "As new versions are added with appropriate tags and attributes in the original multilingual document, nothing is ever lost, and cooperative working on a document is rendered feasible.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "440": {"text": "It runs in time O -LRB- N 2 + SN log N -RRB-, where S is the number of random samples and N is the number of data points.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "441": {"text": "We show that the light field space is largely bi-linear due to 3D line segments in the scene, and direct tri-angulation of these bilinear subspaces leads to large errors.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "449": {"text": "We consider two groups of indicators: post level -LRB- determined using information about individual blog posts only -RRB- and blog level -LRB- determined using information from the underlying blogs -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "463": {"text": "In particular, it does not depend on optimization specific properties of the triangularizer, such as its proximity to critical points, that are typical of existing bounds in the literature.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "464": {"text": "We want to illustrate a framework less restrictive than earlier ones by allowing a speaker leeway in forming an utterance about a task and in determining the conversational vehicle to deliver it.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "466": {"text": "We experimentally show that using the ACE events to constrain the document set returned by an information retrieval engine significantly improves the precision at various recall rates for two different query templates.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "470": {"text": "We are developing a prototype where, in the simplest sharing scenario, naive users interact directly with the text in their language -LRB- L0 -RRB-, and indirectly with the associated graph.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "489": {"text": "As an analogy must be valid on the level of form as well as on the level of meaning, we relied on the idea that translation should preserve meaning to test for similar meanings.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "490": {"text": "We demonstrate analytically that MINPRAN distinguishes good ts from ts to random data, and that MINPRAN nds accurate ts and nearly the correct number of inliers, regardless of the percentage of true inliers.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "493": {"text": "In Thai language, it frequently happens that there is fluctuation in the choice of classifier for a given concrete noun, both from the point of view of the whole speech community and individual speakers.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "519": {"text": "The reality of analogies between words is refuted by noone -LRB- e.g., I walked is to to walk as I laughed is to to laugh, noted I walked: to walk:: I laughed: to laugh -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "521": {"text": "We incorporate the prior on natural images by requiring that the separating hyperplane will not only yield a wide margin, but also that the corresponding positive half space will have a low probability to contain natural images -LRB- the background -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "522": {"text": "Here we suggest a formal perspective on the difficulty in finding such a unification, in the form of an impossibility theorem: for a set of three simple properties, we show that there is no clustering function satisfying all three.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "529": {"text": "Because a speaker and listener cannot be assured to have the same beliefs, contexts, perceptions, backgrounds, or goals, at each point in a conversation, difficulties and mistakes arise when a listener interprets a speaker's utterance.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n(91) \"none\"  \n(92) \"none\"  \n(93) \"none\"  \n(94) \"none\"  \n(95) \"none\"  \n(96) \"none\"  \n(97) \"none\"  \n(98) \"none\"  \n(99) \"none\"  \n(100) \"none\"  \n(101) \"none\"  \n(102) \"none\"  \n(103) \"none\"  \n(104) \"none\"  \n(105) \"none\"  \n(106) \"none\"  \n(107) \"none\"  \n(108) \"none\"  \n(109) \"none\"  \n(110) \"none\"  \n"}, "535": {"text": "Determiners play an important role in conveying the meaning of an utterance, but they have often been disregarded, perhaps because it seemed more important to devise methods to grasp the global meaning of a sentence, even if not in a precise way.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "539": {"text": "In our approach, the slave camera only passively follows the target -LRB- by loose registration with the master -RRB- and bootstraps itself from its own incoming imagery, thus effectively circumventing the problems faced by previous approaches and avoiding the need to perform any model transfer.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}, "545": {"text": "In all of these cases, we expect some form of dependency between the draws: the nucleotide at one position in the DNA strand may depend on the preceding nucleotides, children's names are highly correlated from year to year, and topics in text may be correlated and dynamic.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n"}}, "fail_cases": {"1": {"text": "We call these misunderstandings miscommunication.", "true": [], "pred": [["misunderstandings:other scientific term", "hyponym of", "miscommunication:other scientific term"]], "response": "(1) \"hyponym of\"  \n(2) \"none\"\n"}, "3": {"text": "Language resource quality is crucial in NLP.", "true": [["Language resource quality:metric", "feature of", "NLP:task"]], "pred": [["Language resource quality:other scientific term", "feature of", "NLP:other scientific term"]], "response": "(1) \"feature of\"  \n(2) \"none\"\n"}, "5": {"text": "Another problem with determiners is their inherent ambiguity.", "true": [["ambiguity:other scientific term", "feature of", "determiners:method"]], "pred": [["determiners:other scientific term", "part of", "problem:task"], ["ambiguity:other scientific term", "part of", "problem:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "7": {"text": "The results showed the advantages of our method.", "true": [], "pred": [["advantages:other scientific term", "feature of", "our method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "8": {"text": "It is particularly valuable to empirical MT research.", "true": [["It:generic", "used for", "empirical MT research:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "10": {"text": "We have implemented a restricted domain parser called Plume.", "true": [["Plume:method", "hyponym of", "restricted domain parser:method"]], "pred": [["Plume:material", "hyponym of", "restricted domain parser:method"]], "response": "(1) \"hyponym of\"  \n(2) \"none\"\n"}, "11": {"text": "Each part is a collection of salient image features.", "true": [], "pred": [["part:generic", "hyponym of", "collection of salient image features:other scientific term"]], "response": "(1) \"none\"  \n(2) \"hyponym of\"\n"}, "13": {"text": "Extension to affine projection enables reconstruction without estimating cameras.", "true": [["affine projection:method", "used for", "reconstruction:task"]], "pred": [["cameras:other scientific term", "part of", "affine projection:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "15": {"text": "Translations are produced by means of a beam-search decoder.", "true": [["beam-search decoder:method", "used for", "Translations:other scientific term"]], "pred": [["Translations:material", "used for", "beam-search decoder:method"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "20": {"text": "The paper also promotes a new view for extensional reference.", "true": [], "pred": [["new view:other scientific term", "used for", "extensional reference:other scientific term"], ["new view:other scientific term", "part of", "paper:generic"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "21": {"text": "Combination methods are an effective way of improving system performance.", "true": [], "pred": [["Combination methods:method", "used for", "system performance:metric"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "22": {"text": "Our approach outperforms state-of-the-art trackers on the VIVID benchmark datasets.", "true": [["state-of-the-art trackers:generic", "compare", "approach:generic"], ["approach:generic", "evaluated for", "VIVID benchmark datasets:material"], ["state-of-the-art trackers:generic", "evaluated for", "VIVID benchmark datasets:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "23": {"text": "We further demonstrate synthesis from a freely translating virtual camera.", "true": [["translating virtual camera:other scientific term", "used for", "synthesis:task"]], "pred": [["freely translating virtual camera:other scientific term", "used for", "synthesis:task"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "24": {"text": "We briefly investigate the weak equivalence of the two formalisms.", "true": [], "pred": [["weak equivalence:other scientific term", "compare", "two formalisms:other scientific term"]], "response": "(1) \"compare\"  \n(2) \"none\"\n"}, "26": {"text": "Deep learning methods have achieved wide success in this task.", "true": [], "pred": [["deep learning methods:method", "used for", "task:generic"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "27": {"text": "Background modeling is an important component of many vision systems.", "true": [["Background modeling:task", "part of", "vision systems:task"]], "pred": [["component:generic", "feature of", "background modeling:method"], ["background modeling:method", "part of", "vision systems:other scientific term"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"part of\"  \n"}, "29": {"text": "We present a novel approach for automatically acquiring English topic signatures.", "true": [["approach:generic", "used for", "automatically acquiring English topic signatures:task"]], "pred": [["automatically acquiring English topic signatures:task", "used for", "novel approach:method"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "31": {"text": "This paper examines the benefits of system combination for unsupervised WSD.", "true": [["system combination:method", "used for", "unsupervised WSD:task"]], "pred": [["unsupervised WSD:task", "used for", "system combination:method"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "33": {"text": "Manual acquisition of semantic constraints in broad domains is very expensive.", "true": [], "pred": [["Manual acquisition:task", "used for", "semantic constraints:other scientific term"], ["Manual acquisition:task", "used for", "broad domains:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "34": {"text": "It is presented as a generalization of the recursive descent parser.", "true": [["recursive descent parser:method", "used for", "It:generic"]], "pred": [["It:generic", "feature of", "recursive descent parser:method"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "35": {"text": "These dependencies are not naturally captured by the typical Dirichlet-multinomial formulation.", "true": [], "pred": [["dependencies:other scientific term", "feature of", "Dirichlet-multinomial formulation:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "36": {"text": "The validation of these resources is widely recommended before being used.", "true": [], "pred": [["resources:material", "used for", "validation:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "37": {"text": "This paper describes the impact of using different-quality references on evaluation.", "true": [["different-quality references:other scientific term", "used for", "evaluation:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "38": {"text": "Extensive experiments demonstrate the utility and performance of the proposed approach.", "true": [], "pred": [["utility:metric", "feature of", "proposed approach:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "39": {"text": "We present a new method for detecting interest points using histogram information.", "true": [["method:generic", "used for", "detecting interest points:task"], ["histogram information:other scientific term", "used for", "detecting interest points:task"]], "pred": [["method:generic", "used for", "interest points:other scientific term"], ["method:generic", "used for", "histogram information:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"used for\"  \n"}, "40": {"text": "A random modulation scheme produces near-Bernoulli statistics even for highly correlated inputs.", "true": [["random modulation scheme:method", "used for", "near-Bernoulli statistics:other scientific term"], ["highly correlated inputs:material", "used for", "random modulation scheme:method"]], "pred": [["near-Bernoulli statistics:other scientific term", "feature of", "random modulation scheme:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "42": {"text": "We present Minimum Bayes-Risk -LRB- MBR -RRB- decoding for statistical machine translation.", "true": [["Minimum Bayes-Risk -LRB- MBR -RRB- decoding:method", "used for", "statistical machine translation:task"]], "pred": [["statistical machine translation:task", "used for", "Minimum Bayes-Risk -LRB- MBR -RRB-:method"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "44": {"text": "We suggest a new goal and evaluation criterion for word similarity measures.", "true": [["evaluation criterion:metric", "used for", "word similarity measures:metric"]], "pred": [["evaluation criterion:metric", "used for", "word similarity measures:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "47": {"text": "These include demonstrations of synthesis of cyclopean views of extended conversational sequences.", "true": [], "pred": [["demonstrations:generic", "used for", "synthesis of cyclopean views:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "48": {"text": "We give two estimates, a lower one and a higher one.", "true": [], "pred": [["lower one:generic", "compare", "higher one:generic"], ["higher one:generic", "compare", "lower one:generic"], ["estimates:metric", "part of", "lower one:generic"], ["estimates:metric", "part of", "higher one:generic"]], "response": "(1) \"compare\"  \n(2) \"compare\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "49": {"text": "Related work applies MINPRAN to complex range and intensity data 23 -RSB-.", "true": [["MINPRAN:method", "used for", "complex range:other scientific term"], ["MINPRAN:method", "used for", "intensity data:material"]], "pred": [["complex range and intensity data:material", "used for", "MINPRAN:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "50": {"text": "Such a triangulation provides a piecewise-linear interpolant useful for light field super-resolution.", "true": [["triangulation:other scientific term", "used for", "piecewise-linear interpolant:other scientific term"], ["piecewise-linear interpolant:other scientific term", "used for", "light field super-resolution:task"]], "pred": [["piecewise-linear interpolant:other scientific term", "used for", "light field super-resolution:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "51": {"text": "A method for producing such phrases from a word-aligned corpora is proposed.", "true": [["method:generic", "used for", "phrases:generic"], ["method:generic", "evaluated for", "word-aligned corpora:material"]], "pred": [["phrases:other scientific term", "used for", "method:generic"], ["word-aligned corpora:material", "part of", "method:generic"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "52": {"text": "Thus we believe researchers working with novel features should consider trying MLPs.", "true": [], "pred": [["novel features:other scientific term", "feature of", "MLPs:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "53": {"text": "Amorph recognizes NE items in two stages: dictionary lookup and rule application.", "true": [["Amorph:method", "used for", "NE items:other scientific term"], ["dictionary lookup:method", "part of", "Amorph:method"], ["dictionary lookup:method", "conjunction", "rule application:method"], ["rule application:method", "part of", "Amorph:method"]], "pred": [["NE items:other scientific term", "used for", "dictionary lookup:method"], ["NE items:other scientific term", "used for", "rule application:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "54": {"text": "This posterior encodes sparse se-lectional preferences between a head word and its dependents.", "true": [["posterior:generic", "used for", "sparse se-lectional preferences:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "55": {"text": "We have built and will demonstrate an application of this approach called LCS-Marine.", "true": [["approach:generic", "used for", "LCS-Marine:task"]], "pred": [["this approach:method", "used for", "LCS-Marine:method"], ["application:task", "part of", "this approach:method"], ["application:task", "part of", "LCS-Marine:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "56": {"text": "We have conducted numerous simulations to verify the practical feasibility of our algorithm.", "true": [], "pred": [["practical feasibility:other scientific term", "feature of", "our algorithm:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "57": {"text": "Machine transliteration/back-transliteration plays an important role in many multilingual speech and language applications.", "true": [["Machine transliteration/back-transliteration:task", "used for", "multilingual speech and language applications:task"]], "pred": [["Machine transliteration/back-transliteration:method", "used for", "multilingual speech and language applications:task"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "58": {"text": "Design challenges, trade-offs and some experimental results are presented in this paper.", "true": [], "pred": [["Design challenges:other scientific term", "part of", "this paper:generic"], ["trade-offs:other scientific term", "part of", "this paper:generic"], ["experimental results:other scientific term", "part of", "this paper:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"part of\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "59": {"text": "We report the performance of the MBR decoders on a Chinese-to-English translation task.", "true": [["MBR decoders:method", "used for", "Chinese-to-English translation task:task"]], "pred": [["performance:metric", "feature of", "Chinese-to-English translation task:task"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "61": {"text": "This paper presents a machine learning approach to bare slice disambiguation in dialogue.", "true": [["machine learning approach:method", "used for", "bare slice disambiguation:task"], ["dialogue:material", "used for", "bare slice disambiguation:task"]], "pred": [["bare slice disambiguation:task", "used for", "dialogue:other scientific term"], ["machine learning approach:method", "used for", "bare slice disambiguation:task"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n"}, "63": {"text": "It models reflection as regions containing two different layers moving over each other.", "true": [["It:generic", "used for", "reflection:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "64": {"text": "We present a strong detector based on combining a set of weak detectors.", "true": [["detectors:generic", "used for", "detector:generic"]], "pred": [["strong detector:method", "used for", "weak detectors:method"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "65": {"text": "However, they provide no guarantee of being more efficient than exhaustive search.", "true": [["they:generic", "compare", "exhaustive search:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "66": {"text": "This paper describes a method for incorporating priming into an incremental probabilistic parser.", "true": [["method:generic", "used for", "priming:other scientific term"], ["priming:other scientific term", "used for", "incremental probabilistic parser:method"]], "pred": [["method:generic", "used for", "incremental probabilistic parser:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "67": {"text": "The seven categories of the scheme are based on rhetorical moves of argumentation.", "true": [["rhetorical moves of argumentation:method", "used for", "scheme:generic"]], "pred": [["seven categories:other scientific term", "part of", "scheme:generic"], ["rhetorical moves of argumentation:other scientific term", "part of", "scheme:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "68": {"text": "A new algorithm is proposed for novel view generation in one-to-one teleconferencing applications.", "true": [["algorithm:generic", "used for", "novel view generation:task"], ["novel view generation:task", "used for", "one-to-one teleconferencing applications:task"]], "pred": [["novel view generation:task", "used for", "one-to-one teleconferencing applications:task"], ["novel view generation:task", "part of", "algorithm:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "70": {"text": "This motor control representation enables successful word spotting and matching of cursive scripts.", "true": [["motor control representation:method", "used for", "word spotting:task"], ["motor control representation:method", "used for", "matching of cursive scripts:task"], ["word spotting:task", "conjunction", "matching of cursive scripts:task"]], "pred": [["word spotting:task", "used for", "matching of cursive scripts:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "71": {"text": "Labeled data is replaced by a few hand-crafted rules that encode basic syntactic knowledge.", "true": [["hand-crafted rules:other scientific term", "used for", "syntactic knowledge:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "72": {"text": "Listen-Communicate-Show -LRB- LCS -RRB- is a new paradigm for human interaction with data sources.", "true": [["Listen-Communicate-Show -LRB- LCS -RRB-:task", "used for", "human interaction with data sources:task"]], "pred": [["new paradigm:other scientific term", "part of", "Listen-Communicate-Show -LRB- LCS -RRB-:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "73": {"text": "This paper presents an algorithm for selecting an appropriate classifier word for a noun.", "true": [], "pred": [["classifier word:other scientific term", "used for", "noun:other scientific term"], ["classifier word:other scientific term", "used for", "algorithm:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "74": {"text": "The signals are assumed to be piecewise stationary with varying variances in different epochs.", "true": [], "pred": [["piecewise stationary:other scientific term", "hyponym of", "signals:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"hyponym of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "75": {"text": "In this paper, events are defined as event terms and associated event elements.", "true": [], "pred": [["events:other scientific term", "used for", "this paper:generic"], ["event terms:other scientific term", "used for", "this paper:generic"], ["event elements:other scientific term", "used for", "this paper:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "79": {"text": "Some of the extracts were expert human translations, others were machine translation outputs.", "true": [["machine translation outputs:other scientific term", "conjunction", "expert human translations:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "81": {"text": "The integrated learning system has been experimentally validated in simulated construction and ooce domains.", "true": [["integrated learning system:method", "evaluated for", "simulated construction:task"], ["simulated construction:task", "conjunction", "ooce domains:task"], ["integrated learning system:method", "evaluated for", "ooce domains:task"]], "pred": [["ooce domains:other scientific term", "part of", "integrated learning system:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "82": {"text": "Our combination methods rely on predominant senses which are derived automatically from raw text.", "true": [["predominant senses:other scientific term", "used for", "combination methods:method"], ["raw text:material", "used for", "predominant senses:other scientific term"]], "pred": [["predominant senses:other scientific term", "used for", "combination methods:method"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "83": {"text": "The system is implemented entirely in Prolog, a programming language based on logic.", "true": [["Prolog:other scientific term", "used for", "system:generic"], ["Prolog:other scientific term", "hyponym of", "programming language:other scientific term"], ["logic:other scientific term", "used for", "programming language:other scientific term"]], "pred": [["Prolog:material", "part of", "programming language:other scientific term"], ["programming language:other scientific term", "part of", "system:generic"], ["Prolog:material", "part of", "system:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "84": {"text": "The scheme was implemented by gathering statistics on the output of other linguistic tools.", "true": [], "pred": [["statistics:material", "part of", "scheme:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "85": {"text": "We present a novel method for discovering parallel sentences in comparable, non-parallel corpora.", "true": [["method:generic", "used for", "discovering parallel sentences:task"], ["comparable, non-parallel corpora:material", "used for", "discovering parallel sentences:task"]], "pred": [["parallel sentences:other scientific term", "used for", "method:generic"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "86": {"text": "This theory provides a framework for describing the processing of utterances in a discourse.", "true": [], "pred": [["theory:other scientific term", "used for", "discourse:other scientific term"], ["theory:other scientific term", "used for", "processing of utterances:task"], ["theory:other scientific term", "feature of", "framework:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "87": {"text": "We then turn to a discussion comparing the linguistic expressiveness of the two formalisms.", "true": [["linguistic expressiveness:other scientific term", "feature of", "formalisms:generic"]], "pred": [["linguistic expressiveness:other scientific term", "compare", "two formalisms:other scientific term"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "88": {"text": "The modified graph is then sent to the UNL-L0 deconverter and the result shown.", "true": [["graph:other scientific term", "used for", "UNL-L0 deconverter:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "89": {"text": "We then derive a scalable stochastic gradient descent algorithm for the resulting learning problem.", "true": [["stochastic gradient descent algorithm:method", "used for", "learning problem:generic"]], "pred": [["resulting learning problem:task", "used for", "scalable stochastic gradient descent algorithm:method"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "90": {"text": "We also derive an efficient non-linear extension of WARCA by using the kernel trick.", "true": [["kernel trick:method", "used for", "non-linear extension of WARCA:method"]], "pred": [["efficient non-linear extension of WARCA:method", "used for", "kernel trick:method"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "91": {"text": "A model-based approach to on-line cursive handwriting analysis and recognition is presented and evaluated.", "true": [["model-based approach:method", "used for", "on-line cursive handwriting analysis and recognition:task"]], "pred": [["on-line cursive handwriting analysis:task", "evaluated for", "recognition:task"], ["on-line cursive handwriting analysis:task", "part of", "model-based approach:method"]], "response": "(1) \"evaluated for\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "92": {"text": "In contrast, object pose estimation using these approaches has received relatively less attention.", "true": [["approaches:generic", "used for", "object pose estimation:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "93": {"text": "Light fields are image-based representations that use densely sampled rays as a scene description.", "true": [], "pred": [["densely sampled rays:other scientific term", "part of", "image-based representations:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "94": {"text": "GLOSSER is designed to support reading and learning to read in a foreign language.", "true": [["GLOSSER:method", "used for", "reading and learning:task"]], "pred": [["foreign language:other scientific term", "used for", "reading:task"], ["foreign language:other scientific term", "used for", "learning to read:task"], ["reading:task", "part of", "learning to read:task"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "96": {"text": "First, it uses several kinds of dictionaries to segment and tag Japanese character strings.", "true": [["dictionaries:other scientific term", "used for", "it:generic"], ["dictionaries:other scientific term", "used for", "Japanese character strings:other scientific term"]], "pred": [["segment:task", "used for", "tag:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "97": {"text": "A domain independent model is proposed for the automated interpretation of nominal compounds in English.", "true": [["domain independent model:method", "used for", "automated interpretation of nominal compounds:task"], ["English:material", "feature of", "nominal compounds:other scientific term"]], "pred": [["nominal compounds:other scientific term", "used for", "automated interpretation:task"], ["nominal compounds:other scientific term", "part of", "domain independent model:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "99": {"text": "This model was shown to be more appropriate for blind separation of natural speech signals.", "true": [["model:generic", "used for", "blind separation of natural speech signals.:task"]], "pred": [["natural speech signals:other scientific term", "used for", "blind separation of natural speech signals:task"], ["blind separation of natural speech signals:task", "part of", "model:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "100": {"text": "We evaluate the proposed methods through several transliteration/backtransliteration experiments for English/Chinese and English/Japanese language pairs.", "true": [["methods:generic", "evaluated for", "transliteration/backtransliteration:task"], ["transliteration/backtransliteration:task", "used for", "English/Chinese and English/Japanese language pairs:material"]], "pred": [["English/Chinese:material", "evaluated for", "transliteration/backtransliteration experiments:task"], ["English/Japanese:material", "evaluated for", "transliteration/backtransliteration experiments:task"]], "response": "(1) \"evaluated for\"  \n(2) \"evaluated for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "102": {"text": "This paper solves a specialized regression problem to obtain sampling probabilities for records in databases.", "true": [["specialized regression problem:task", "used for", "sampling probabilities:other scientific term"], ["sampling probabilities:other scientific term", "used for", "records:material"], ["records:material", "part of", "databases:material"]], "pred": [["sampling probabilities:metric", "used for", "specialized regression problem:task"], ["records:material", "part of", "databases:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "104": {"text": "Branch and bound strategies have previously attempted to curb this complexity whilst maintaining global optimality.", "true": [["Branch and bound strategies:method", "used for", "complexity:generic"], ["global optimality:other scientific term", "feature of", "Branch and bound strategies:method"]], "pred": [["Branch and bound strategies:method", "used for", "global optimality:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "105": {"text": "To improve topical blog post retrieval we incorporate textual credibility indicators in the retrieval process.", "true": [["textual credibility indicators:other scientific term", "used for", "topical blog post retrieval:task"], ["textual credibility indicators:other scientific term", "part of", "retrieval process:method"]], "pred": [["textual credibility indicators:other scientific term", "used for", "topical blog post retrieval:task"], ["textual credibility indicators:other scientific term", "used for", "retrieval process:method"], ["topical blog post retrieval:task", "part of", "retrieval process:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "107": {"text": "To our knowledge, this is the first a posteriori bound for joint matrix decomposition.", "true": [["posteriori bound:other scientific term", "used for", "joint matrix decomposition:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "108": {"text": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision.", "true": [["Learned confidence measures:method", "used for", "outlier removal:task"], ["Learned confidence measures:method", "used for", "quality improvement:task"], ["outlier removal:task", "conjunction", "quality improvement:task"], ["outlier removal:task", "part of", "stereo vision:task"], ["quality improvement:task", "part of", "stereo vision:task"]], "pred": [["learned confidence measures:other scientific term", "used for", "stereo vision:other scientific term"], ["learned confidence measures:other scientific term", "used for", "outlier removal:task"], ["learned confidence measures:other scientific term", "used for", "quality improvement:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "110": {"text": "To evaluate our proposed model, we build a large streaming video dataset with annotations.", "true": [["model:generic", "evaluated for", "streaming video dataset:material"]], "pred": [["large streaming video dataset:material", "evaluated for", "model:method"], ["annotations:material", "part of", "large streaming video dataset:material"]], "response": "(1) \"evaluated for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"part of\"  \n"}, "111": {"text": "A search restriction especially useful for the translation direction from German to English is presented.", "true": [], "pred": [["German:material", "used for", "translation direction:other scientific term"], ["English:material", "used for", "translation direction:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "112": {"text": "A purely functional implementation of LR-parsers is given, together with a simple correctness proof.", "true": [["correctness proof:method", "conjunction", "LR-parsers:method"]], "pred": [["correctness proof:other scientific term", "part of", "purely functional implementation:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "113": {"text": "The linguistic structure consists of segments of the discourse into which the utterances naturally aggregate.", "true": [], "pred": [["segments of the discourse:other scientific term", "hyponym of", "linguistic structure:other scientific term"], ["utterances:other scientific term", "part of", "linguistic structure:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"hyponym of\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n"}, "114": {"text": "Our experiments clearly indicate the potential of this dynamic representation for complete cursive handwriting recognition.", "true": [["dynamic representation:method", "used for", "cursive handwriting recognition:task"]], "pred": [["complete cursive handwriting recognition:task", "used for", "dynamic representation:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "115": {"text": "Recent progress in computer vision has been driven by high-capacity models trained on large datasets.", "true": [["high-capacity models:method", "used for", "computer vision:task"], ["large datasets:material", "used for", "high-capacity models:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "116": {"text": "These mattes are implied by a set of hypothesized object boundary fragments in the scene.", "true": [["hypothesized object boundary fragments:other scientific term", "used for", "mattes:generic"]], "pred": [["mattes:other scientific term", "part of", "scene:other scientific term"], ["set of hypothesized object boundary fragments:other scientific term", "part of", "scene:other scientific term"]], "response": "(1) \"none\"  \n(2) \"part of\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "117": {"text": "They improve the reconstruction results and enforce their consistency with a priori knowledge about object shape.", "true": [["They:generic", "used for", "reconstruction:task"], ["object shape:other scientific term", "feature of", "priori knowledge:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "118": {"text": "The request is passed to a mobile, intelligent agent for execution at the appropriate database.", "true": [], "pred": [["request:generic", "used for", "mobile intelligent agent:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "119": {"text": "An extension of our method to space-time interest point detection for action classification is also presented.", "true": [["method:generic", "used for", "space-time interest point detection:task"], ["space-time interest point detection:task", "used for", "action classification:task"]], "pred": [["extension:generic", "used for", "space-time interest point detection:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "121": {"text": "Objects are represented as a coherent ensemble of parts that are consistent under 3D viewpoint transformations.", "true": [], "pred": [["coherent ensemble of parts:other scientific term", "part of", "Objects:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "122": {"text": "Our approach is among the first to propose a generative proba-bilistic framework for 3D object categorization.", "true": [["generative proba-bilistic framework:method", "used for", "3D object categorization:task"]], "pred": [["3D object categorization:task", "used for", "generative probabilistic framework:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "123": {"text": "The analysis is based on the hypothesis that people are better decoders of their own emotions.", "true": [], "pred": [["hypothesis:other scientific term", "part of", "analysis:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "124": {"text": "We use gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities.", "true": [["gray-level band-pass white noise patterns:other scientific term", "evaluated for", "robustness:metric"], ["indirect lighting:other scientific term", "feature of", "robustness:metric"], ["indirect lighting:other scientific term", "conjunction", "scene discontinuities:other scientific term"], ["scene discontinuities:other scientific term", "feature of", "robustness:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "125": {"text": "Computing power per area and power consumption is amongst the highest reported for a single chip.", "true": [["Computing power per area:metric", "conjunction", "power consumption:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "126": {"text": "This probably occurs because each model has different strengths and weaknesses for modeling the knowledge sources.", "true": [["model:generic", "used for", "knowledge sources:material"]], "pred": [["model:other scientific term", "used for", "modeling the knowledge sources:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "127": {"text": "The psycholinguistic literature provides evidence for syntactic priming, i.e., the tendency to repeat structures.", "true": [["psycholinguistic literature:other scientific term", "used for", "syntactic priming:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "129": {"text": "The goal of this work is the enrichment of human-machine interactions in a natural language environment.", "true": [["natural language environment:other scientific term", "feature of", "human-machine interactions:task"]], "pred": [["human-machine interactions:other scientific term", "used for", "enrichment:task"], ["goal:generic", "part of", "work:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "130": {"text": "Chat-80 has been designed to be both efficient and easily adaptable to a variety of applications.", "true": [], "pred": [["easily adaptable:generic", "feature of", "Chat-80:method"], ["variety of applications:task", "used for", "Chat-80:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "131": {"text": "Our technique is based on an improved, dynamic-programming, stereo algorithm for efficient novel-view generation.", "true": [["technique:generic", "used for", "novel-view generation:task"], ["dynamic-programming, stereo algorithm:method", "used for", "technique:generic"]], "pred": [["technique:method", "used for", "stereo algorithm:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "132": {"text": "This paper presents an automatic scheme for collecting statistics on cooccurrence patterns in a large corpus.", "true": [], "pred": [["cooccurrence patterns:other scientific term", "part of", "large corpus:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "133": {"text": "Memo-functions also facilitate a simple way to construct a very compact representation of the parse forest.", "true": [["Memo-functions:method", "used for", "parse forest:other scientific term"]], "pred": [["compact representation:other scientific term", "feature of", "parse forest:other scientific term"], ["compact representation:other scientific term", "used for", "Memo-functions:method"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "134": {"text": "We examine the relationship between the two grammatical formalisms: Tree Adjoining Grammars and Head Grammars.", "true": [["Tree Adjoining Grammars:method", "hyponym of", "grammatical formalisms:method"], ["Tree Adjoining Grammars:method", "compare", "Head Grammars:method"], ["Head Grammars:method", "hyponym of", "grammatical formalisms:method"]], "pred": [["Tree Adjoining Grammars:method", "compare", "Head Grammars:method"], ["Head Grammars:method", "compare", "Tree Adjoining Grammars:method"]], "response": "(1) \"compare\"  \n(2) \"compare\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "135": {"text": "We propose a novel metric learning formulation called Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-.", "true": [["Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-:method", "hyponym of", "metric learning formulation:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "136": {"text": "We present a variant of TAGs, called synchronous TAGs, which characterize correspondences between languages.", "true": [], "pred": [["correspondences between languages:other scientific term", "part of", "variant of TAGs:method"], ["correspondences between languages:other scientific term", "feature of", "synchronous TAGs:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "138": {"text": "With the rise of deep archi-tectures, the prime focus has been on object category recognition.", "true": [["deep archi-tectures:method", "used for", "object category recognition:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "140": {"text": "Almost all the special cases of and exceptions to phonological and morphological rules have been implemented.", "true": [], "pred": [["special cases:other scientific term", "part of", "phonological and morphological rules:other scientific term"], ["exceptions:other scientific term", "part of", "phonological and morphological rules:other scientific term"]], "response": "(1) \"none\"  \n(2) \"part of\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "142": {"text": "The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes.", "true": [["approach:generic", "used for", "cluttered scenes:other scientific term"]], "pred": [["segmentation stage:other scientific term", "part of", "proposed approach:method"], ["proposed approach:method", "used for", "cluttered scenes:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "144": {"text": "Experiment results on ACE corpora show that this spectral clustering based approach outperforms the other clustering methods.", "true": [["spectral clustering based approach:method", "evaluated for", "ACE corpora:material"], ["clustering methods:method", "evaluated for", "ACE corpora:material"], ["spectral clustering based approach:method", "compare", "clustering methods:method"]], "pred": [["spectral clustering based approach:method", "compare", "other clustering methods:method"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "145": {"text": "The perception of transparent objects from images is known to be a very hard problem in vision.", "true": [["images:material", "used for", "perception of transparent objects:task"]], "pred": [["hard problem:other scientific term", "part of", "perception of transparent objects:task"], ["perception of transparent objects:task", "hyponym of", "hard problem:other scientific term"], ["perception of transparent objects:task", "part of", "vision:other scientific term"], ["images:material", "part of", "vision:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"hyponym of\"  \n(6) \"part of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "146": {"text": "In this paper, we explore what can be said about transparent objects by a moving observer.", "true": [], "pred": [["transparent objects:other scientific term", "used for", "this paper:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "147": {"text": "We show promising results in both the detection and viewpoint classification tasks on these two challenging datasets.", "true": [["detection and viewpoint classification tasks:task", "evaluated for", "datasets:generic"]], "pred": [["promising results:metric", "used for", "detection:task"], ["promising results:metric", "used for", "viewpoint classification:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "148": {"text": "The fact that Turkish is an agglutinating free word order language presents a challenge for language theories.", "true": [["Turkish:material", "hyponym of", "agglutinating free word order language:material"]], "pred": [["Turkish:material", "hyponym of", "agglutinating free word order language:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"hyponym of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "149": {"text": "In this paper we discuss object detection when only a small number of training examples are given.", "true": [], "pred": [["small number of training examples:material", "used for", "object detection:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "151": {"text": "Subpixel accuracy is achieved by considering several zero-crossings defined by the difference between pairs of unstructured patterns.", "true": [["zero-crossings:other scientific term", "used for", "Subpixel accuracy:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "152": {"text": "We analyzed eye gaze, head nods and attentional focus in the context of a direction-giving task.", "true": [["eye gaze:other scientific term", "conjunction", "head nods:other scientific term"], ["eye gaze:other scientific term", "part of", "direction-giving task:task"], ["head nods:other scientific term", "conjunction", "attentional focus:other scientific term"], ["head nods:other scientific term", "part of", "direction-giving task:task"], ["attentional focus:other scientific term", "part of", "direction-giving task:task"]], "pred": [["eye gaze:other scientific term", "used for", "direction-giving task:task"], ["head nods:other scientific term", "used for", "direction-giving task:task"], ["attentional focus:other scientific term", "used for", "direction-giving task:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "153": {"text": "Moreover, a cost zero solution always exists and can only be excluded by hard budget constraints.", "true": [["hard budget constraints:other scientific term", "used for", "cost zero solution:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "154": {"text": "We present results on addressee identification in four-participants face-to-face meetings using Bayesian Network and Naive Bayes classifiers.", "true": [["Bayesian Network:method", "used for", "addressee identification in four-participants face-to-face meetings:task"], ["Naive Bayes classifiers:method", "used for", "addressee identification in four-participants face-to-face meetings:task"], ["Naive Bayes classifiers:method", "conjunction", "Bayesian Network:method"]], "pred": [["four-participants face-to-face meetings:material", "used for", "addressee identification:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "155": {"text": "This distribution has numerous applications in computer Go, including serving as an efficient stand-alone Go player.", "true": [["distribution:generic", "used for", "computer Go:other scientific term"]], "pred": [["distribution:other scientific term", "used for", "applications:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "156": {"text": "We investigate several voting - and arbiter-based combination strategies over a diverse pool of unsupervised WSD systems.", "true": [["voting - and arbiter-based combination strategies:method", "used for", "unsupervised WSD systems:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "157": {"text": "This paper gives an overall account of a prototype natural language question answering system, called Chat-80.", "true": [["Chat-80:method", "hyponym of", "natural language question answering system:method"]], "pred": [["Chat-80:material", "part of", "prototype natural language question answering system:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "158": {"text": "Human action recognition from well-segmented 3D skeleton data has been intensively studied and attracting an increasing attention.", "true": [["well-segmented 3D skeleton data:material", "used for", "Human action recognition:task"]], "pred": [["well-segmented 3D skeleton data:material", "part of", "Human action recognition:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "160": {"text": "MINPRAN's properties are connrmed experimentally on synthetic data and compare favorably to least median of squares.", "true": [["MINPRAN:method", "evaluated for", "synthetic data:material"], ["least median of squares:method", "compare", "MINPRAN:method"]], "pred": [["MINPRAN's properties:other scientific term", "compare", "least median of squares:other scientific term"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "161": {"text": "We evaluate several proposals for constraining them, basing our assessment on computational tractability and explanatory adequacy.", "true": [["them:generic", "evaluated for", "computational tractability and explanatory adequacy:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "162": {"text": "There are four language pairs currently supported by GLOSSER: English-Bulgarian, English-Estonian, English-Hungarian and French-Dutch.", "true": [["language pairs:generic", "used for", "GLOSSER:method"], ["English-Bulgarian:material", "hyponym of", "language pairs:generic"], ["English-Bulgarian:material", "conjunction", "English-Estonian:material"], ["English-Estonian:material", "hyponym of", "language pairs:generic"], ["English-Estonian:material", "conjunction", "English-Hungarian:material"], ["English-Hungarian:material", "hyponym of", "language pairs:generic"], ["English-Hungarian:material", "conjunction", "French-Dutch:material"], ["French-Dutch:material", "hyponym of", "language pairs:generic"]], "pred": [["English-Bulgarian:material", "part of", "four language pairs:generic"], ["English-Estonian:material", "part of", "four language pairs:generic"], ["English-Hungarian:material", "part of", "four language pairs:generic"], ["French-Dutch:material", "part of", "four language pairs:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"part of\"  \n(9) \"part of\"  \n(10) \"part of\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "163": {"text": "The program is operational on UNIX and Windows '95 platforms, and has undergone a pilot user-study.", "true": [], "pred": [["UNIX:material", "part of", "program:generic"], ["Windows '95:material", "part of", "program:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "164": {"text": "In practice, the current deep embedding methods use the Euclidean distance for the training and test.", "true": [["Euclidean distance:other scientific term", "used for", "deep embedding methods:method"]], "pred": [["training:task", "used for", "test:task"], ["training:task", "feature of", "deep embedding methods:method"], ["Euclidean distance:metric", "feature of", "deep embedding methods:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "165": {"text": "Our proposed approach builds on recent advances in spectral clustering, image matting, and boundary detection.", "true": [["spectral clustering:method", "used for", "approach:generic"], ["spectral clustering:method", "conjunction", "image matting:method"], ["image matting:method", "used for", "approach:generic"], ["image matting:method", "conjunction", "boundary detection:method"], ["boundary detection:method", "used for", "approach:generic"]], "pred": [["proposed approach:method", "used for", "recent advances:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"used for\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "166": {"text": "Indeed, automatic evaluations need high-quality data that allow the comparison of both automatic and human translations.", "true": [["automatic evaluations:task", "evaluated for", "high-quality data:material"]], "pred": [["automatic translations:other scientific term", "compare", "human translations:other scientific term"], ["human translations:other scientific term", "compare", "automatic translations:other scientific term"], ["high-quality data:material", "used for", "automatic evaluations:task"]], "response": "(1) \"compare\"  \n(2) \"compare\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "167": {"text": "Thus, the limitations of the automatic metrics used within MT are also discussed in this regard.", "true": [["MT:task", "evaluated for", "automatic metrics:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "168": {"text": "In this paper, we propose a new method for the modeling and subtraction of such scenes.", "true": [["method:generic", "used for", "modeling and subtraction of such scenes:task"]], "pred": [["modeling and subtraction of such scenes:task", "used for", "new method:method"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "169": {"text": "Fast algorithms for nearest neighbor -LRB- NN -RRB- search have in large part focused on 2 distance.", "true": [["Fast algorithms:generic", "used for", "nearest neighbor -LRB- NN -RRB- search:task"]], "pred": [["nearest neighbor -LRB- NN -RRB-:other scientific term", "used for", "Fast algorithms:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "170": {"text": "Structural or numerical constraints can then be added locally to the reconstruction process through a constrained optimization scheme.", "true": [["Structural or numerical constraints:other scientific term", "used for", "reconstruction process:method"], ["constrained optimization scheme:method", "used for", "Structural or numerical constraints:other scientific term"]], "pred": [["structural or numerical constraints:other scientific term", "used for", "reconstruction process:task"], ["structural or numerical constraints:other scientific term", "used for", "constrained optimization scheme:method"], ["reconstruction process:task", "part of", "constrained optimization scheme:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "171": {"text": "We integrate a spoken language understanding system with intelligent mobile agents that mediate between users and information sources.", "true": [["intelligent mobile agents:method", "part of", "spoken language understanding system:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "173": {"text": "In particular, we make extensive use of Pustejovsky's principles concerning the predicative information associated with nominals.", "true": [["nominals:other scientific term", "feature of", "predicative information:other scientific term"]], "pred": [["Pustejovsky's principles:other scientific term", "used for", "predicative information:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "174": {"text": "We argue that it is necessary to draw a line between generalizable semantic principles and domain-specific semantic information.", "true": [["generalizable semantic principles:other scientific term", "compare", "domain-specific semantic information:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "175": {"text": "This has the advantages of efficiency on grammatical input, and robustness in the face of ungrammatical input.", "true": [["ungrammatical input:other scientific term", "feature of", "robustness:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "176": {"text": "The objects can be complex in that they may be composed of multiple layers with different refractive indices.", "true": [["multiple layers:other scientific term", "part of", "they:generic"], ["refractive indices:other scientific term", "feature of", "multiple layers:other scientific term"]], "pred": [["multiple layers:other scientific term", "part of", "objects:other scientific term"], ["different refractive indices:other scientific term", "part of", "multiple layers:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"part of\"  \n"}, "177": {"text": "With relevant approach, we identify important contents by PageRank algorithm on the event map constructed from documents.", "true": [["PageRank algorithm:method", "used for", "relevant approach:method"], ["event map:other scientific term", "used for", "PageRank algorithm:method"], ["documents:material", "used for", "event map:other scientific term"]], "pred": [["relevant approach:method", "used for", "PageRank algorithm:method"], ["important contents:other scientific term", "part of", "event map:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "178": {"text": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance.", "true": [["translation:task", "evaluated for", "loss functions:other scientific term"]], "pred": [["expected loss of translation errors:metric", "used for", "translation performance:metric"], ["loss functions:other scientific term", "part of", "statistical approach:method"], ["expected loss of translation errors:metric", "part of", "statistical approach:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"part of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "179": {"text": "Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions.", "true": [["MBR decoding:method", "used for", "statistical MT:method"], ["MBR decoding:method", "used for", "loss functions:other scientific term"]], "pred": [["specific loss functions:other scientific term", "used for", "MBR decoding:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "180": {"text": "Both classifiers perform the best when conversational context and utterance features are combined with speaker's gaze information.", "true": [["conversational context:other scientific term", "used for", "classifiers:method"], ["conversational context:other scientific term", "conjunction", "utterance features:other scientific term"], ["utterance features:other scientific term", "used for", "classifiers:method"], ["speaker's gaze information:other scientific term", "used for", "classifiers:method"], ["speaker's gaze information:other scientific term", "conjunction", "utterance features:other scientific term"]], "pred": [["conversational context:other scientific term", "conjunction", "utterance features:other scientific term"], ["conversational context:other scientific term", "used for", "classifiers:method"], ["utterance features:other scientific term", "used for", "classifiers:method"], ["speaker's gaze information:other scientific term", "used for", "classifiers:method"]], "response": "(1) \"conjunction\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "181": {"text": "This, the first experiment in a series of experiments, looks at the intelligibility of MT output.", "true": [], "pred": [["intelligibility:other scientific term", "part of", "series of experiments:task"], ["first experiment:task", "part of", "series of experiments:task"], ["MT output:material", "used for", "first experiment:task"]], "response": "(1) \"none\"  \n(2) \"part of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "182": {"text": "We extract a set of heuristic principles from a corpus-based sample and formulate them as probabilistic Horn clauses.", "true": [["corpus-based sample:material", "used for", "heuristic principles:method"], ["probabilistic Horn clauses:other scientific term", "feature of", "heuristic principles:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "183": {"text": "In particular, we obtain a probability distribution over legal moves for professional play in a given position.", "true": [], "pred": [["probability distribution:other scientific term", "used for", "legal moves:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "184": {"text": "The applicability of many current information extraction techniques is severely limited by the need for supervised training data.", "true": [["supervised training data:material", "used for", "information extraction techniques:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "186": {"text": "Experimental results on our dataset and the public G3D dataset both demonstrate very promising performance of our scheme.", "true": [["dataset:generic", "conjunction", "G3D dataset:material"]], "pred": [["experimental results:other scientific term", "feature of", "our scheme:method"], ["our dataset:material", "part of", "our scheme:method"], ["public G3D dataset:material", "part of", "our scheme:method"], ["promising performance:metric", "feature of", "our scheme:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"part of\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "187": {"text": "We apply cluster analysis on the sampled parameter space to redetect the object and renew the local tracker.", "true": [["cluster analysis:method", "used for", "sampled parameter space:other scientific term"], ["cluster analysis:method", "used for", "local tracker:method"]], "pred": [["cluster analysis:method", "used for", "local tracker:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "189": {"text": "We provide a unified account of sentence-level and text-level anaphora within the framework of a dependency-based grammar model.", "true": [["dependency-based grammar model:method", "used for", "sentence-level and text-level anaphora:other scientific term"]], "pred": [["unified account:method", "feature of", "dependency-based grammar model:method"], ["sentence-level and text-level anaphora:other scientific term", "part of", "unified account:method"], ["sentence-level and text-level anaphora:other scientific term", "feature of", "dependency-based grammar model:method"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "190": {"text": "In this paper, we discuss language model adaptation methods given a word list and a raw corpus.", "true": [["word list:other scientific term", "used for", "language model adaptation methods:method"], ["word list:other scientific term", "conjunction", "raw corpus:material"], ["raw corpus:material", "used for", "language model adaptation methods:method"]], "pred": [["word list:material", "part of", "language model adaptation methods:method"], ["raw corpus:material", "part of", "language model adaptation methods:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "191": {"text": "Many practical modeling problems involve discrete data that are best represented as draws from multinomial or categorical distributions.", "true": [["discrete data:material", "used for", "modeling problems:task"], ["multinomial or categorical distributions:method", "used for", "modeling problems:task"]], "pred": [["multinomial or categorical distributions:other scientific term", "feature of", "modeling problems:task"], ["discrete data:material", "feature of", "modeling problems:task"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "192": {"text": "A general procedure for the estimation and quantization of these cycloidal motion parameters for arbitrary handwriting is presented.", "true": [["cycloidal motion parameters:other scientific term", "used for", "arbitrary handwriting:material"]], "pred": [["cycloidal motion parameters:other scientific term", "used for", "arbitrary handwriting:other scientific term"], ["cycloidal motion parameters:other scientific term", "feature of", "general procedure:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"feature of\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "194": {"text": "Person re-identification is challenging due to the large variations of pose, illumination, occlusion and camera view.", "true": [], "pred": [["pose:other scientific term", "feature of", "Person re-identification:task"], ["illumination:other scientific term", "feature of", "Person re-identification:task"], ["occlusion:other scientific term", "feature of", "Person re-identification:task"], ["camera view:other scientific term", "feature of", "Person re-identification:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"feature of\"  \n(14) \"feature of\"  \n(15) \"feature of\"  \n(16) \"feature of\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "195": {"text": "We further propose a parameter training algorithm for the present model based on a decision tree-based context clustering.", "true": [["parameter training algorithm:method", "used for", "model:generic"], ["decision tree-based context clustering:method", "used for", "parameter training algorithm:method"]], "pred": [["parameter training algorithm:method", "used for", "decision tree-based context clustering:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "196": {"text": "The NCA is created statistically from a large corpus and recomposed under concept hierarchy constraints and frequency of occurrences.", "true": [["concept hierarchy constraints:other scientific term", "used for", "NCA:method"], ["frequency of occurrences:other scientific term", "used for", "NCA:method"]], "pred": [["large corpus:material", "used for", "NCA:other scientific term"], ["NCA:other scientific term", "part of", "large corpus:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"part of\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "197": {"text": "Given a single image, it is difficult to even detect the presence of transparent objects in the scene.", "true": [], "pred": [["single image:material", "part of", "scene:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "198": {"text": "We present a novel model-based approach to recover the shapes and the poses of transparent objects from known motion.", "true": [["model-based approach:method", "used for", "shapes and the poses of transparent objects:other scientific term"], ["known motion:other scientific term", "used for", "shapes and the poses of transparent objects:other scientific term"]], "pred": [["shapes:other scientific term", "used for", "model-based approach:method"], ["poses:other scientific term", "used for", "model-based approach:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "199": {"text": "This paper proposes to use a convolution kernel over parse trees to model syntactic structure information for relation extraction.", "true": [["convolution kernel over parse trees:method", "used for", "syntactic structure information:other scientific term"], ["syntactic structure information:other scientific term", "used for", "relation extraction:task"]], "pred": [["parse trees:other scientific term", "used for", "syntactic structure information:other scientific term"], ["parse trees:other scientific term", "used for", "relation extraction:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "200": {"text": "We compare our results to state of the art methods such as mi-cro phase shifting and modulated phase shifting.", "true": [["mi-cro phase shifting:method", "hyponym of", "state of the art methods:generic"], ["mi-cro phase shifting:method", "conjunction", "modulated phase shifting:method"], ["modulated phase shifting:method", "hyponym of", "state of the art methods:generic"]], "pred": [["results:generic", "compare", "state of the art methods:method"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "201": {"text": "It uses a powerful pattern-matching language to classify grs into frames hierarchically in a way that mirrors inheritance-based lexica.", "true": [["pattern-matching language:other scientific term", "used for", "It:generic"], ["pattern-matching language:other scientific term", "used for", "grs:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "202": {"text": "We provide a principled and provable solution for this problem; it is parameterless and requires no data insights.", "true": [["principled and provable solution:method", "used for", "problem:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "203": {"text": "We evaluate the demands that task dialogues collected using this technique, place upon a prototype Natural Language system.", "true": [["task dialogues:material", "used for", "prototype Natural Language system:method"], ["technique:generic", "used for", "task dialogues:material"]], "pred": [["task dialogues:material", "part of", "prototype Natural Language system:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "204": {"text": "A language learning experiment showed that assessors can differentiate native from non-native language essays in less than 100 words.", "true": [["assessors:generic", "evaluated for", "language learning:task"]], "pred": [["100 words:metric", "used for", "language learning experiment:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "205": {"text": "We tested this to see if similar criteria could be elicited from duplicating the experiment using machine translation output.", "true": [], "pred": [["machine translation output:material", "used for", "duplicating the experiment:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "206": {"text": "This work presents an automated technique for detecting reflections in image sequences by analyzing motion trajectories of feature points.", "true": [["technique:generic", "used for", "detecting reflections in image sequences:task"], ["motion trajectories:other scientific term", "used for", "technique:generic"], ["feature points:other scientific term", "feature of", "motion trajectories:other scientific term"]], "pred": [["reflections:other scientific term", "used for", "automated technique:method"], ["motion trajectories:other scientific term", "used for", "automated technique:method"], ["feature points:other scientific term", "used for", "automated technique:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"used for\"  \n(12) \"used for\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "207": {"text": "As a Monte Carlo approach, ASA stochastically samples the parameter space, in contrast to local deterministic search.", "true": [["ASA:method", "hyponym of", "Monte Carlo approach:method"], ["ASA:method", "compare", "local deterministic search:method"]], "pred": [["Monte Carlo approach:method", "compare", "ASA:method"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "208": {"text": "Using this approach, we extract parallel data from large Chinese, Arabic, and English non-parallel newspaper corpora.", "true": [["approach:generic", "used for", "parallel data:material"], ["parallel data:material", "part of", "Chinese, Arabic, and English non-parallel newspaper corpora:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "209": {"text": "This paper presents a phrase-based statistical machine translation method, based on non-contiguous phrases, i.e. phrases with gaps.", "true": [["non-contiguous phrases:material", "used for", "phrase-based statistical machine translation method:method"]], "pred": [["non-contiguous phrases:other scientific term", "feature of", "phrases with gaps:other scientific term"], ["non-contiguous phrases:other scientific term", "part of", "phrase-based statistical machine translation method:method"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "211": {"text": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels.", "true": [["ambiguities:other scientific term", "feature of", "computation of features:task"], ["data-dependent bandwidth:other scientific term", "used for", "ambiguities:other scientific term"], ["data-dependent bandwidth:other scientific term", "used for", "density estimation:task"], ["kernels:method", "used for", "density estimation:task"]], "pred": [["data-dependent bandwidth:method", "used for", "density estimation:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "212": {"text": "In this paper, we present our approach for using information extraction annotations to augment document retrieval for distillation.", "true": [["information extraction annotations:other scientific term", "used for", "document retrieval for distillation:task"]], "pred": [["information extraction annotations:other scientific term", "used for", "document retrieval:task"], ["information extraction annotations:other scientific term", "part of", "approach:generic"], ["document retrieval:task", "part of", "approach:generic"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "213": {"text": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships.", "true": [["representation:generic", "used for", "three-dimensional objects:other scientific term"], ["affine-invariant image patches:other scientific term", "feature of", "three-dimensional objects:other scientific term"], ["spatial relationships:other scientific term", "feature of", "affine-invariant image patches:other scientific term"]], "pred": [["affine-invariant image patches:other scientific term", "hyponym of", "three-dimensional objects:other scientific term"], ["three-dimensional objects:other scientific term", "part of", "representation:method"], ["affine-invariant image patches:other scientific term", "part of", "representation:method"], ["spatial relationships:other scientific term", "part of", "representation:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"hyponym of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"part of\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "214": {"text": "It has also been studied in the framework of Japanese information extraction -LRB- -LSB- 3 -RSB- -RRB- in recent years.", "true": [["Japanese information extraction:task", "used for", "It:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "215": {"text": "Our approach is based on the iterative deformation of a 3--D surface mesh to minimize an objective function.", "true": [["iterative deformation of a 3--D surface mesh:method", "used for", "approach:generic"], ["iterative deformation of a 3--D surface mesh:method", "used for", "objective function:other scientific term"]], "pred": [["approach:generic", "used for", "iterative deformation:method"], ["objective function:other scientific term", "part of", "iterative deformation:method"], ["3--D surface mesh:material", "part of", "iterative deformation:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "216": {"text": "The model is evaluated on English and Czech newspaper texts, and is then validated on French broadcast news transcriptions.", "true": [["model:generic", "evaluated for", "English and Czech newspaper texts:material"], ["model:generic", "evaluated for", "French broadcast news transcriptions:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "217": {"text": "At the core of the externally digital architecture is a high-density, low-power analog array performing binary-binary partial matrix-vector multiplication.", "true": [["high-density, low-power analog array:other scientific term", "part of", "externally digital architecture:method"], ["binary-binary partial matrix-vector multiplication:method", "used for", "high-density, low-power analog array:other scientific term"]], "pred": [["externally digital architecture:method", "part of", "analog array:method"], ["binary-binary partial matrix-vector multiplication:task", "part of", "externally digital architecture:method"], ["high-density:metric", "part of", "externally digital architecture:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"none\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "219": {"text": "Specifically, we show how to incorporate a simple prior on the distribution of natural images into support vector machines.", "true": [["prior on the distribution of natural images:other scientific term", "used for", "support vector machines:method"]], "pred": [["simple prior:other scientific term", "used for", "support vector machines:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "220": {"text": "Based on these results, we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state.", "true": [["verbal and nonverbal grounding acts:other scientific term", "used for", "ECA:method"], ["verbal and nonverbal grounding acts:other scientific term", "used for", "dialogue state:other scientific term"]], "pred": [["ECA:method", "used for", "verbal and nonverbal grounding acts:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "222": {"text": "Our extensive experimental results significantly improve over both uniform sampling and standard stratified sampling which are de-facto the industry standards.", "true": [["uniform sampling:method", "conjunction", "stratified sampling:method"]], "pred": [["uniform sampling:method", "compare", "standard stratified sampling:method"], ["standard stratified sampling:method", "compare", "uniform sampling:method"]], "response": "(1) \"compare\"  \n(2) \"compare\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "223": {"text": "Topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic.", "true": [["Topical blog post retrieval:task", "hyponym of", "ranking blog posts:task"], ["relevance:metric", "feature of", "blog posts:material"]], "pred": [["given topic:other scientific term", "used for", "topical blog post retrieval:task"], ["relevance:metric", "feature of", "topical blog post retrieval:task"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "224": {"text": "We describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models.", "true": [["them:generic", "part of", "retrieval approach:method"], ["language models:method", "used for", "them:generic"]], "pred": [["indicators:other scientific term", "used for", "retrieval approach:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"used for\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "225": {"text": "Three models are compared, which involve priming of rules between sentences, within sentences, and within coordinate structures.", "true": [], "pred": [["models:method", "compare", "priming of rules:method"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "226": {"text": "The combined approach is formulated in the framework of Bayesian statistics to account for the robust-ness requirement in image understanding.", "true": [["approach:generic", "used for", "robust-ness requirement in image understanding:task"], ["Bayesian statistics:method", "used for", "approach:generic"]], "pred": [["robustness requirement:other scientific term", "feature of", "image understanding:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "228": {"text": "Experiments using the SemCor and Senseval-3 data sets demonstrate that our ensembles yield significantly better results when compared with state-of-the-art.", "true": [["ensembles:generic", "evaluated for", "SemCor and Senseval-3 data sets:material"], ["state-of-the-art:generic", "evaluated for", "SemCor and Senseval-3 data sets:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "229": {"text": "We propose a multi-task end-to-end Joint Classification-Regression Recurrent Neural Network to better explore the action type and temporal localiza-tion information.", "true": [["multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method", "used for", "action type:other scientific term"], ["multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method", "used for", "temporal localiza-tion information:other scientific term"], ["action type:other scientific term", "conjunction", "temporal localiza-tion information:other scientific term"]], "pred": [["action type:other scientific term", "part of", "multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method"], ["temporal localization information:other scientific term", "part of", "multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "230": {"text": "The task of machine translation -LRB- MT -RRB- evaluation is closely related to the task of sentence-level semantic equivalence classification.", "true": [["machine translation -LRB- MT -RRB- evaluation:task", "conjunction", "sentence-level semantic equivalence classification:task"]], "pred": [["machine translation -LRB- MT -RRB-:task", "conjunction", "sentence-level semantic equivalence classification:task"]], "response": "(1) \"conjunction\"  \n(2) \"none\"\n"}, "231": {"text": "Our technique gives a substantial improvement in paraphrase classification accuracy over all of the other models used in the experiments.", "true": [["technique:generic", "compare", "models:generic"], ["technique:generic", "evaluated for", "paraphrase classification accuracy:metric"], ["models:generic", "evaluated for", "paraphrase classification accuracy:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "232": {"text": "In this paper We experimentally evaluate a trainable sentence planner for a spoken dialogue system by eliciting subjective human judgments.", "true": [["trainable sentence planner:method", "used for", "spoken dialogue system:method"], ["trainable sentence planner:method", "evaluated for", "subjective human judgments:other scientific term"]], "pred": [["trainable sentence planner:method", "part of", "spoken dialogue system:method"], ["subjective human judgments:metric", "used for", "trainable sentence planner:method"], ["subjective human judgments:metric", "used for", "spoken dialogue system:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"used for\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "233": {"text": "Thus, our method can be applied with great benefit to language pairs for which only scarce resources are available.", "true": [["scarce resources:material", "used for", "method:generic"]], "pred": [["method:generic", "used for", "language pairs:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "234": {"text": "We report experiments conducted on a multilingual corpus to estimate the number of analogies among the sentences that it contains.", "true": [["analogies:other scientific term", "evaluated for", "multilingual corpus:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "237": {"text": "However, the distribution is unknown, so it is difficult to use the geodesic distance when comparing two samples.", "true": [], "pred": [["distribution:other scientific term", "compare", "geodesic distance:other scientific term"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "238": {"text": "Thus the ASR system is designed to deal with what we refer to as Word Spotting and Noise Spotting capabilities.", "true": [["ASR system:method", "used for", "Word Spotting:task"], ["ASR system:method", "used for", "Noise Spotting capabilities:task"]], "pred": [["Word Spotting:task", "part of", "ASR system:method"], ["Noise Spotting:task", "part of", "ASR system:method"], ["ASR system:method", "feature of", "Word Spotting:task"], ["ASR system:method", "feature of", "Noise Spotting:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"part of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"feature of\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "239": {"text": "Unfortunately, creating large datasets with pixel-level labels has been extremely costly due to the amount of human effort required.", "true": [["pixel-level labels:other scientific term", "feature of", "large datasets:material"]], "pred": [["pixel-level labels:other scientific term", "used for", "creating:task"], ["large datasets:material", "part of", "creating:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "240": {"text": "Turkish is an agglutinative language with word structures formed by productive affixations of derivational and inflectional suffixes to root words.", "true": [["Turkish:material", "hyponym of", "agglutinative language:material"], ["word structures:other scientific term", "feature of", "agglutinative language:material"], ["productive affixations of derivational and inflectional suffixes:other scientific term", "part of", "word structures:other scientific term"]], "pred": [["Turkish:material", "hyponym of", "agglutinative language:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"hyponym of\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "241": {"text": "The surface realizations of morphological constructions are constrained and modified by a number of phonetic rules such as vowel harmony.", "true": [["phonetic rules:other scientific term", "used for", "surface realizations of morphological constructions:task"], ["vowel harmony:other scientific term", "hyponym of", "phonetic rules:other scientific term"]], "pred": [["surface realizations:other scientific term", "feature of", "morphological constructions:other scientific term"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "242": {"text": "When the scene exhibits a persistent dynamic behavior in time, such an assumption is violated and detection performance deteriorates.", "true": [["persistent dynamic behavior:other scientific term", "feature of", "scene:generic"]], "pred": [["persistent dynamic behavior:other scientific term", "part of", "scene:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "243": {"text": "It is based on a weakly supervised dependency parser that can model speech syntax without relying on any annotated training corpus.", "true": [["weakly supervised dependency parser:task", "used for", "speech syntax:other scientific term"]], "pred": [["speech syntax:other scientific term", "hyponym of", "weakly supervised dependency parser:method"], ["weakly supervised dependency parser:method", "feature of", "speech syntax:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"hyponym of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"feature of\"  \n"}, "245": {"text": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy.", "true": [["it:generic", "used for", "real scenes:material"], ["it:generic", "used for", "shapes of the objects:other scientific term"], ["transparent objects:other scientific term", "part of", "real scenes:material"], ["shapes of the objects:other scientific term", "evaluated for", "accuracy:metric"]], "pred": [["high accuracy:metric", "feature of", "shapes of the objects:other scientific term"], ["it:generic", "part of", "real scenes:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"part of\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "246": {"text": "We propose a novel probabilistic framework for learning visual models of 3D object categories by combining appearance information and geometric constraints.", "true": [["probabilistic framework:method", "used for", "visual models of 3D object categories:task"], ["appearance information:other scientific term", "used for", "probabilistic framework:method"], ["appearance information:other scientific term", "conjunction", "geometric constraints:other scientific term"], ["geometric constraints:other scientific term", "used for", "probabilistic framework:method"]], "pred": [["probabilistic framework:method", "used for", "visual models of 3D object categories:method"], ["appearance information:other scientific term", "feature of", "probabilistic framework:method"], ["appearance information:other scientific term", "part of", "visual models of 3D object categories:method"], ["geometric constraints:other scientific term", "part of", "probabilistic framework:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"part of\"  \n(7) \"part of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "247": {"text": "Furthermore, we propose the use of standard parser evaluation methods for automatically evaluating the summarization quality of sentence condensation systems.", "true": [["summarization quality:metric", "evaluated for", "parser evaluation methods:method"], ["sentence condensation systems:method", "evaluated for", "summarization quality:metric"]], "pred": [["summarization quality:metric", "evaluated for", "sentence condensation systems:task"]], "response": "(1) \"evaluated for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "248": {"text": "In the case of natural speech signals, the method is shown to have separation accuracy better than the state-of-the-art methods.", "true": [["method:generic", "used for", "natural speech signals:other scientific term"], ["method:generic", "compare", "methods:generic"], ["method:generic", "evaluated for", "separation accuracy:metric"], ["methods:generic", "evaluated for", "separation accuracy:metric"], ["methods:generic", "used for", "natural speech signals:other scientific term"]], "pred": [["separation accuracy:metric", "feature of", "method:generic"], ["method:generic", "used for", "natural speech signals:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "249": {"text": "It also shows that our method significantly outperforms the previous two dependency tree kernels on the 5 ACE relation major types.", "true": [["method:generic", "compare", "dependency tree kernels:method"]], "pred": [["our method:method", "compare", "previous two dependency tree kernels:method"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "250": {"text": "This paper presents the results of automatically inducing a Combinatory Categorial Grammar -LRB- CCG -RRB- lexicon from a Turkish dependency treebank.", "true": [["Combinatory Categorial Grammar -LRB- CCG -RRB- lexicon:other scientific term", "part of", "Turkish dependency treebank:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "251": {"text": "The experiments show that the system is able to detect scf types with 70% precision and 66% recall rate.", "true": [["system:generic", "evaluated for", "precision:metric"], ["precision:metric", "conjunction", "recall:metric"], ["system:generic", "evaluated for", "recall:metric"]], "pred": [["experiments:generic", "part of", "system:generic"], ["70% precision:metric", "feature of", "scf types:other scientific term"], ["66% recall rate:metric", "feature of", "scf types:other scientific term"], ["scf types:other scientific term", "part of", "experiments:generic"], ["scf types:other scientific term", "part of", "system:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"feature of\"  \n(7) \"part of\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "252": {"text": "We demonstrate our approach with multiple PTZ camera sequences in typical outdoor surveillance settings and show a comparison with state-of-the-art approaches.", "true": [["approach:generic", "used for", "outdoor surveillance settings:other scientific term"], ["approach:generic", "compare", "state-of-the-art approaches:generic"], ["multiple PTZ camera sequences:other scientific term", "used for", "approach:generic"]], "pred": [["our approach:method", "compare", "state-of-the-art approaches:method"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "253": {"text": "This paper presents a critical discussion of the various approaches that have been used in the evaluation of Natural Language systems.", "true": [["approaches:generic", "used for", "evaluation of Natural Language systems:task"]], "pred": [["critical discussion:task", "used for", "evaluation of Natural Language systems:task"], ["critical discussion:task", "feature of", "various approaches:method"], ["evaluation of Natural Language systems:task", "part of", "various approaches:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"part of\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "254": {"text": "We investigate the problem of learning to predict moves in the board game of Go from game records of expert players.", "true": [["game records of expert players:material", "used for", "board game of Go:task"]], "pred": [["board game of Go:material", "part of", "problem:task"], ["game records of expert players:material", "part of", "problem:task"], ["game records of expert players:material", "used for", "learning to predict moves:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "255": {"text": "In order to build robust automatic abstracting systems, there is a need for better training resources than are currently available.", "true": [["training resources:material", "used for", "automatic abstracting systems:task"]], "pred": [["better training resources:material", "used for", "robust automatic abstracting systems:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "257": {"text": "Our numerical hybrid local and global mode-seeking tracker is validated on challenging airborne videos with heavy occlusion and large camera motions.", "true": [["numerical hybrid local and global mode-seeking tracker:method", "evaluated for", "airborne videos:material"], ["heavy occlusion:other scientific term", "feature of", "airborne videos:material"], ["heavy occlusion:other scientific term", "conjunction", "camera motions:other scientific term"], ["camera motions:other scientific term", "feature of", "airborne videos:material"]], "pred": [["heavy occlusion:other scientific term", "feature of", "numerical hybrid local and global mode-seeking tracker:method"], ["large camera motions:other scientific term", "feature of", "numerical hybrid local and global mode-seeking tracker:method"], ["airborne videos:material", "feature of", "numerical hybrid local and global mode-seeking tracker:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"feature of\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "258": {"text": "Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams.", "true": [["algorithm:generic", "evaluated for", "robustness:metric"], ["algorithm:generic", "used for", "spatial and temporal artefacts:other scientific term"], ["spatial and temporal artefacts:other scientific term", "used for", "long stereo video streams:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "259": {"text": "To a large extent, these statistics reflect semantic constraints and thus are used to disambiguate anaphora references and syntactic ambiguities.", "true": [["semantic constraints:other scientific term", "used for", "anaphora references:other scientific term"], ["semantic constraints:other scientific term", "used for", "syntactic ambiguities:other scientific term"], ["anaphora references:other scientific term", "conjunction", "syntactic ambiguities:other scientific term"]], "pred": [["statistics:other scientific term", "used for", "semantic constraints:other scientific term"], ["statistics:other scientific term", "used for", "anaphora references:other scientific term"], ["statistics:other scientific term", "used for", "syntactic ambiguities:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "260": {"text": "In this paper we explore a new theory of discourse structure that stresses the role of purpose and processing in discourse.", "true": [], "pred": [["new theory of discourse structure:other scientific term", "part of", "discourse:other scientific term"], ["new theory of discourse structure:other scientific term", "used for", "this paper:generic"], ["role of purpose and processing:other scientific term", "used for", "this paper:generic"], ["discourse:other scientific term", "used for", "this paper:generic"]], "response": "(1) \"none\"  \n(2) \"part of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "261": {"text": "The intentional structure captures the discourse-relevant purposes, expressed in each of the linguistic segments as well as relationships among them.", "true": [["intentional structure:other scientific term", "used for", "discourse-relevant purposes:other scientific term"]], "pred": [["discourse-relevant purposes:other scientific term", "part of", "intentional structure:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "263": {"text": "A central goal of this research is to merge approaches from pivot MT, interactive MT, and multilingual text authoring.", "true": [["pivot MT:task", "conjunction", "interactive MT:task"], ["interactive MT:task", "conjunction", "multilingual text authoring:task"]], "pred": [["central goal:generic", "part of", "research:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"part of\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "264": {"text": "Therefore, the study presented in this paper may be useful in inspiring new designs of deep models for person re-identification.", "true": [["deep models:method", "used for", "person re-identification:task"]], "pred": [["study:generic", "used for", "deep models:method"], ["person re-identification:task", "used for", "study:generic"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "265": {"text": "A critical step in encoding sound for neuronal processing occurs when the analog pressure wave is coded into discrete nerve-action potentials.", "true": [["encoding sound:task", "used for", "neuronal processing:task"], ["discrete nerve-action potentials:other scientific term", "used for", "analog pressure wave:other scientific term"]], "pred": [["analog pressure wave:other scientific term", "used for", "discrete nerve-action potentials:other scientific term"], ["analog pressure wave:other scientific term", "used for", "encoding sound:task"], ["analog pressure wave:other scientific term", "used for", "neuronal processing:task"], ["discrete nerve-action potentials:other scientific term", "used for", "encoding sound:task"], ["discrete nerve-action potentials:other scientific term", "used for", "neuronal processing:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"used for\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "266": {"text": "Rather than trying to find or define a single\" best\" segmentation, we generate multiple segmentations of an image.", "true": [], "pred": [["multiple segmentations:task", "used for", "image:material"]], "response": "(1) \"none\"  \n(2) \"used for\"\n"}, "268": {"text": "Full digital resolution is maintained even with low-resolution analog-to-digital conversion, owing to random statistics in the analog summation of binary products.", "true": [["random statistics:other scientific term", "part of", "analog summation of binary products:other scientific term"]], "pred": [["low-resolution analog-to-digital conversion:other scientific term", "used for", "analog summation of binary products:other scientific term"], ["full digital resolution:metric", "feature of", "low-resolution analog-to-digital conversion:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "269": {"text": "We show how features that are imaged through a transparent object behave differently from those that are rigidly attached to the scene.", "true": [["those:generic", "compare", "features:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "270": {"text": "A generative framework is used for learning a model that captures the relative position of parts within each of the discretized viewpoints.", "true": [["generative framework:method", "used for", "model:generic"]], "pred": [["generative framework:method", "used for", "model:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "271": {"text": "An experimental evaluation of summarization quality shows a close correlation between the automatic parse-based evaluation and a manual evaluation of generated strings.", "true": [["automatic parse-based evaluation:method", "evaluated for", "summarization quality:metric"], ["automatic parse-based evaluation:method", "compare", "manual evaluation:method"]], "pred": [["automatic parse-based evaluation:method", "compare", "manual evaluation:method"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "272": {"text": "This paper describes a novel system for acquiring adjectival subcategorization frames -LRB- scfs -RRB- and associated frequency information from English corpus data.", "true": [["system:generic", "used for", "acquiring adjectival subcategorization frames -LRB- scfs -RRB-:task"]], "pred": [["adjectival subcategorization frames -LRB- scfs -RRB-:other scientific term", "used for", "novel system:method"], ["frequency information:other scientific term", "used for", "novel system:method"], ["English corpus data:material", "used for", "novel system:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"used for\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "273": {"text": "Our study reveals that the proposed method not only reduces an extensive system development effort but also improves the transliteration accuracy significantly.", "true": [["method:generic", "evaluated for", "transliteration accuracy:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "274": {"text": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output.", "true": [["human transcriptions:other scientific term", "evaluated for", "corpora:generic"], ["speech recognition output:other scientific term", "evaluated for", "corpora:generic"], ["conversational telephone speech:material", "hyponym of", "corpora:generic"], ["conversational telephone speech:material", "conjunction", "broadcast news speech:material"], ["broadcast news speech:material", "hyponym of", "corpora:generic"], ["human transcriptions:other scientific term", "conjunction", "speech recognition output:other scientific term"]], "pred": [["conversational telephone speech:material", "part of", "two corpora:material"], ["conversational telephone speech:material", "part of", "broadcast news speech:material"], ["broadcast news speech:material", "part of", "two corpora:material"], ["human transcriptions:material", "part of", "two corpora:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"part of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"part of\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "275": {"text": "The goal is to sample a small set of records over which evaluating aggregate queries can be done both efficiently and accurately.", "true": [["records:material", "evaluated for", "aggregate queries:other scientific term"]], "pred": [["small set of records:material", "part of", "evaluating aggregate queries:task"], ["efficiently:metric", "used for", "evaluating aggregate queries:task"], ["accurately:metric", "used for", "evaluating aggregate queries:task"], ["evaluating aggregate queries:task", "part of", "goal:generic"], ["small set of records:material", "part of", "goal:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"used for\"  \n(7) \"used for\"  \n(8) \"part of\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "276": {"text": "We show that there is a closed-form -LRB- analytical -RRB- solution for one part of the Kullback-Leibler distance, viz the cross-entropy.", "true": [["closed-form -LRB- analytical -RRB- solution:method", "used for", "Kullback-Leibler distance:method"], ["closed-form -LRB- analytical -RRB- solution:method", "used for", "cross-entropy:method"], ["cross-entropy:method", "part of", "Kullback-Leibler distance:method"]], "pred": [["Kullback-Leibler distance:other scientific term", "part of", "closed-form -LRB- analytical -RRB- solution:method"], ["cross-entropy:other scientific term", "part of", "closed-form -LRB- analytical -RRB- solution:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "277": {"text": "Finally, a novel feature weighting and selection function is presented, which yields superior feature vectors and better word similarity performance.", "true": [["feature weighting and selection function:method", "used for", "feature vectors:other scientific term"], ["feature weighting and selection function:method", "used for", "word similarity:task"], ["feature vectors:other scientific term", "conjunction", "word similarity:task"]], "pred": [["superior feature vectors:metric", "feature of", "word similarity performance:metric"], ["superior feature vectors:metric", "part of", "feature weighting and selection function:method"], ["feature weighting and selection function:method", "used for", "word similarity performance:metric"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n"}, "278": {"text": "With the aid of a logic-based grammar formalism called extraposition grammars, Chat-80 translates English questions into the Prolog subset of logic.", "true": [["extraposition grammars:method", "hyponym of", "logic-based grammar formalism:method"], ["extraposition grammars:method", "used for", "Chat-80:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "279": {"text": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog, cf. query optimisation in a relational database.", "true": [["planning algorithm:method", "used for", "logical expression:other scientific term"], ["relational database:material", "used for", "query optimisation:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "280": {"text": "Our results show that MT evaluation techniques are able to produce useful features for paraphrase classification and to a lesser extent entailment.", "true": [["MT evaluation techniques:method", "used for", "features:other scientific term"], ["MT evaluation techniques:method", "used for", "paraphrase classification:task"], ["MT evaluation techniques:method", "used for", "entailment:task"], ["paraphrase classification:task", "conjunction", "entailment:task"]], "pred": [["useful features:other scientific term", "used for", "paraphrase classification:task"], ["useful features:other scientific term", "feature of", "MT evaluation techniques:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "281": {"text": "An experiment was performed to resolve references of the pronoun \"it\" in sentences that were randomly selected from the corpus.", "true": [], "pred": [["experiment:task", "used for", "references of the pronoun 'it':task"], ["sentences:material", "part of", "experiment:task"], ["sentences:material", "part of", "references of the pronoun 'it':task"], ["corpus:material", "part of", "experiment:task"], ["sentences:material", "part of", "corpus:material"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"part of\"  \n(20) \"none\"  \n"}, "282": {"text": "We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system.", "true": [["it:generic", "used for", "statistical machine translation system:method"]], "pred": [["quality:metric", "evaluated for", "extracted data:material"]], "response": "(1) \"evaluated for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "283": {"text": "The theory of attention, intention, and aggregation of utterances is illustrated in the paper with a number of example discourses.", "true": [], "pred": [["and aggregation of utterances:other scientific term", "part of", "paper:generic"], ["example discourses:material", "part of", "paper:generic"]], "response": "(1) \"none\"  \n(2) \"part of\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "284": {"text": "This method allows us to avoid these problems and go directly to capturing the statistical behavior of specific words in the application.", "true": [], "pred": [["method:generic", "used for", "application:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "285": {"text": "Unlike other techniques that handle large outlier percentages, MINPRAN does not rely on a known error bound for the good data.", "true": [["techniques:generic", "used for", "large outlier percentages:metric"], ["techniques:generic", "compare", "MINPRAN:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "287": {"text": "The result is a discrete motor control representation of the continuous pen motion, via the quantized levels of the model parameters.", "true": [["discrete motor control representation:method", "used for", "continuous pen motion:other scientific term"]], "pred": [["discrete motor control representation:method", "part of", "result:generic"], ["continuous pen motion:other scientific term", "feature of", "discrete motor control representation:method"], ["quantized levels of the model parameters:other scientific term", "part of", "discrete motor control representation:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"feature of\"  \n(6) \"part of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "288": {"text": "This piece of work has also laid a foundation for exploring and harvesting English-Chinese bitexts in a larger volume from the Web.", "true": [], "pred": [["piece of work:generic", "used for", "foundation:generic"], ["Web:material", "used for", "exploring and harvesting English-Chinese bitexts:task"], ["exploring and harvesting English-Chinese bitexts:task", "part of", "piece of work:generic"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "289": {"text": "In this paper, we explore geometric structures of 3D lines in ray space for improving light field triangulation and stereo matching.", "true": [["geometric structures of 3D lines:task", "used for", "light field triangulation:task"], ["geometric structures of 3D lines:task", "used for", "stereo matching:task"], ["ray space:other scientific term", "feature of", "geometric structures of 3D lines:task"], ["light field triangulation:task", "conjunction", "stereo matching:task"]], "pred": [["geometric structures of 3D lines:other scientific term", "used for", "ray space:other scientific term"], ["geometric structures of 3D lines:other scientific term", "used for", "light field triangulation:task"], ["geometric structures of 3D lines:other scientific term", "used for", "stereo matching:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "290": {"text": "The triangulation problem aims to fill in the ray space with continuous and non-overlapping simplices anchored at sampled points -LRB- rays -RRB-.", "true": [], "pred": [["ray space:other scientific term", "used for", "triangulation problem:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "291": {"text": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality.", "true": [["triangulation and LAGC algorithms:method", "evaluated for", "synthetic and real data:material"], ["state-of-the-art solutions:generic", "evaluated for", "synthetic and real data:material"], ["triangulation and LAGC algorithms:method", "compare", "state-of-the-art solutions:generic"], ["triangulation and LAGC algorithms:method", "evaluated for", "accuracy:metric"], ["state-of-the-art solutions:generic", "evaluated for", "accuracy:metric"], ["triangulation and LAGC algorithms:method", "evaluated for", "visual quality:metric"], ["state-of-the-art solutions:generic", "evaluated for", "visual quality:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "292": {"text": "In this paper, we present an approach to rapidly creating pixel-accurate semantic label maps for images extracted from modern computer games.", "true": [["approach:generic", "used for", "pixel-accurate semantic label maps:other scientific term"], ["pixel-accurate semantic label maps:other scientific term", "used for", "images:material"], ["images:material", "part of", "modern computer games:other scientific term"]], "pred": [["approach:generic", "used for", "pixel-accurate semantic label maps:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "293": {"text": "Towards the modeling of the dynamic characteristics, optical flow is computed and utilized as a feature in a higher dimensional space.", "true": [["optical flow:other scientific term", "used for", "modeling of the dynamic characteristics:task"], ["optical flow:other scientific term", "used for", "feature:other scientific term"], ["feature:other scientific term", "used for", "modeling of the dynamic characteristics:task"], ["higher dimensional space:other scientific term", "feature of", "feature:other scientific term"]], "pred": [["optical flow:other scientific term", "used for", "feature:other scientific term"], ["optical flow:other scientific term", "used for", "modeling of the dynamic characteristics:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "294": {"text": "We have demonstrated this capability in several field exercises with the Marines and are currently developing applications of this technology in new domains.", "true": [], "pred": [["capability:generic", "feature of", "technology:generic"], ["field exercises:material", "part of", "applications:task"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "295": {"text": "We present an application of ambiguity packing and stochastic disambiguation techniques for Lexical-Functional Grammars -LRB- LFG -RRB- to the domain of sentence condensation.", "true": [["ambiguity packing and stochastic disambiguation techniques:method", "used for", "Lexical-Functional Grammars -LRB- LFG -RRB-:method"], ["ambiguity packing and stochastic disambiguation techniques:method", "used for", "sentence condensation:task"]], "pred": [["ambiguity packing:method", "used for", "stochastic disambiguation techniques:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "296": {"text": "This paper presents necessary and sufficient conditions for the use of demonstrative expressions in English and discusses implications for current discourse processing algorithms.", "true": [["demonstrative expressions:other scientific term", "feature of", "English:material"], ["implications:generic", "used for", "discourse processing algorithms:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "297": {"text": "We present a scanning method that recovers dense sub-pixel camera-projector correspondence without requiring any photometric calibration nor preliminary knowledge of their relative geometry.", "true": [["scanning method:method", "used for", "dense sub-pixel camera-projector correspondence:other scientific term"]], "pred": [["dense sub-pixel camera-projector correspondence:other scientific term", "feature of", "scanning method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"feature of\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "298": {"text": "We discuss several applications of the result to the problem of distributional approximation of probabilistic context-free grammars by means of probabilistic finite automata.", "true": [["distributional approximation:task", "feature of", "probabilistic context-free grammars:method"], ["probabilistic finite automata:method", "used for", "distributional approximation:task"]], "pred": [["result:generic", "used for", "probabilistic finite automata:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "299": {"text": "This paper considers the problem of reconstructing the motion of a 3D articulated tree from 2D point correspondences subject to some temporal prior.", "true": [["2D point correspondences:other scientific term", "used for", "reconstructing the motion of a 3D articulated tree:task"]], "pred": [["temporal prior:other scientific term", "used for", "reconstructing the motion of a 3D articulated tree:task"], ["2D point correspondences:material", "used for", "reconstructing the motion of a 3D articulated tree:task"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "300": {"text": "Given a particular concept, or word sense, a topic signature is a set of words that tend to co-occur with it.", "true": [], "pred": [["particular concept:other scientific term", "feature of", "topic signature:other scientific term"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "301": {"text": "An important area of learning in autonomous agents is the ability to learn domain-speciic models of actions to be used by planning systems.", "true": [["learning in autonomous agents:task", "used for", "domain-speciic models of actions:method"], ["planning systems:task", "used for", "domain-speciic models of actions:method"]], "pred": [["domain-specific models of actions:method", "used for", "planning systems:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "302": {"text": "Training instances are generated from experience and observation, and a variant of GOLEM is used to learn action models from these instances.", "true": [["GOLEM:method", "used for", "action models:method"]], "pred": [["variant of GOLEM:method", "used for", "action models:method"], ["training instances:material", "part of", "action models:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "303": {"text": "The automated segmentation of images into semantically meaningful parts requires shape information since low-level feature analysis alone often fails to reach this goal.", "true": [["images:material", "used for", "automated segmentation:task"]], "pred": [["semantically meaningful parts:other scientific term", "used for", "automated segmentation:task"], ["shape information:other scientific term", "used for", "automated segmentation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "304": {"text": "In this paper, we describe a search procedure for statistical machine translation -LRB- MT -RRB- based on dynamic programming -LRB- DP -RRB-.", "true": [["search procedure:generic", "used for", "statistical machine translation -LRB- MT -RRB-:task"], ["dynamic programming -LRB- DP -RRB-:method", "used for", "statistical machine translation -LRB- MT -RRB-:task"]], "pred": [["this paper:generic", "used for", "search procedure:method"], ["this paper:generic", "used for", "dynamic programming -LRB- DP -RRB-:method"], ["statistical machine translation -LRB- MT -RRB-:other scientific term", "part of", "search procedure:method"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "305": {"text": "The experimental tests are carried out on the Verbmobil task -LRB- German-English, 8000-word vocabulary -RRB-, which is a limited-domain spoken-language task.", "true": [["Verbmobil task:material", "hyponym of", "limited-domain spoken-language task:task"]], "pred": [["experimental tests:task", "used for", "limited-domain spoken-language task:task"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "306": {"text": "Various properties of discourse are described, and explanations for the behaviour of cue phrases, referring expressions, and interruptions are explored.", "true": [], "pred": [["cue phrases:other scientific term", "feature of", "properties of discourse:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "307": {"text": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks.", "true": [["loss:other scientific term", "used for", "Mahalanobis distance:task"], ["weighted sum:other scientific term", "feature of", "precision:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "309": {"text": "MINPRAN, a new robust operator, nds good ts in data sets where more than 50% of the points are outliers.", "true": [["MINPRAN:method", "hyponym of", "robust operator:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "311": {"text": "In addition, we improve the learning by a metric weight constraint, so that the learned metric has a better generalization ability.", "true": [["metric weight constraint:other scientific term", "used for", "learning:generic"], ["generalization ability:other scientific term", "feature of", "learned metric:other scientific term"]], "pred": [["learned metric:other scientific term", "used for", "learning:task"], ["learned metric:other scientific term", "used for", "metric weight constraint:method"], ["metric weight constraint:method", "part of", "learning:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"part of\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "312": {"text": "This poster paper describes a full scale two-level morphological description -LRB- Karttunen, 1983; Koskenniemi, 1983 -RRB- of Turkish word structures.", "true": [["full scale two-level morphological description:task", "used for", "Turkish word structures:material"]], "pred": [["full scale two-level morphological description:method", "part of", "poster paper:generic"], ["Turkish word structures:other scientific term", "part of", "full scale two-level morphological description:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"part of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "313": {"text": "Experiments on the PASCAL VOC 2006 dataset show an acceleration of more than 50% by our method compared to standard cascade evaluation.", "true": [["method:generic", "evaluated for", "PASCAL VOC 2006 dataset:material"], ["cascade evaluation:method", "evaluated for", "PASCAL VOC 2006 dataset:material"], ["cascade evaluation:method", "compare", "method:generic"]], "pred": [["acceleration:metric", "used for", "our method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "314": {"text": "Here we develop an approach for 1 distance that begins with an explicit and exactly distance-preserving embedding of the points into 2 2.", "true": [["approach:generic", "used for", "1 distance:other scientific term"]], "pred": [["approach:generic", "used for", "explicit and exactly distance-preserving embedding:method"], ["explicit and exactly distance-preserving embedding:method", "part of", "approach:generic"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "315": {"text": "We rigorously establish the correctness of the methodology and show by experimentation using LSH that it is competitive in practice with available alternatives.", "true": [["it:generic", "compare", "alternatives:generic"]], "pred": [["LSH:other scientific term", "feature of", "methodology:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "316": {"text": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices.", "true": [["anisotropic meshing:method", "conjunction", "non-quadratic approach:method"], ["anisotropic meshing:method", "used for", "reconstruction:task"], ["non-quadratic approach:method", "used for", "regularization:other scientific term"], ["non-quadratic approach:method", "used for", "reconstruction:task"], ["triangulations:other scientific term", "used for", "reconstruction:task"]], "pred": [["satisfactory reconstruction results:metric", "feature of", "triangulations:other scientific term"], ["satisfactory reconstruction results:metric", "used for", "anisotropic meshing:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "317": {"text": "This model is meant to account for productive rules of interpretation which are inferred from the morpho-syntactic and semantic characteristics of the nominal constituents.", "true": [["model:generic", "used for", "productive rules of interpretation:other scientific term"], ["morpho-syntactic and semantic characteristics:other scientific term", "used for", "productive rules of interpretation:other scientific term"], ["morpho-syntactic and semantic characteristics:other scientific term", "feature of", "nominal constituents:other scientific term"]], "pred": [["morpho-syntactic:other scientific term", "used for", "productive rules of interpretation:task"], ["semantic characteristics:other scientific term", "used for", "productive rules of interpretation:task"], ["nominal constituents:other scientific term", "used for", "productive rules of interpretation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "318": {"text": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation in very high dimensions, suitable for efficient implementation of kernels in image processing.", "true": [["mixed-signal paradigm:method", "used for", "high-resolution parallel inner-product computation:task"], ["mixed-signal paradigm:method", "used for", "kernels:method"], ["kernels:method", "used for", "image processing:task"]], "pred": [["very high dimensions:other scientific term", "part of", "high-resolution parallel inner-product computation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "319": {"text": "The approach is validated with real image data, and with experimental results from a CID/DRAM analog array prototype in 0.5 cents m CMOS.", "true": [["approach:generic", "evaluated for", "real image data:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "320": {"text": "The problem of blind separation of underdetermined instantaneous mixtures of independent signals is addressed through a method relying on nonstationarity of the original signals.", "true": [["method:generic", "used for", "blind separation of underdetermined instantaneous mixtures of independent signals:task"], ["nonstationarity:other scientific term", "used for", "method:generic"]], "pred": [["nonstationarity of the original signals:other scientific term", "feature of", "blind separation of underdetermined instantaneous mixtures of independent signals:task"], ["nonstationarity of the original signals:other scientific term", "used for", "method:generic"], ["blind separation of underdetermined instantaneous mixtures of independent signals:task", "used for", "method:generic"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "321": {"text": "In this paper, we present our work on the detection of question-answer pairs in an email conversation for the task of email summarization.", "true": [["detection of question-answer pairs:task", "used for", "email summarization:task"], ["email conversation:material", "used for", "detection of question-answer pairs:task"]], "pred": [["question-answer pairs:other scientific term", "used for", "email summarization:task"], ["this paper:generic", "part of", "our work:generic"]], "response": "(1) \"used for\"  \n(2) \"part of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "322": {"text": "We propose a novel approach to associate objects across multiple PTZ cameras that can be used to perform camera handoff in wide-area surveillance scenarios.", "true": [["approach:generic", "used for", "camera handoff in wide-area surveillance scenarios:task"]], "pred": [["objects:other scientific term", "used for", "camera handoff:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "323": {"text": "We conclude that previous approaches have neglected to evaluate systems in the context of their use, e.g. solving a task requiring data retrieval.", "true": [["systems:generic", "evaluated for", "approaches:generic"], ["systems:generic", "used for", "task:generic"], ["data retrieval:task", "part of", "task:generic"]], "pred": [["data retrieval:task", "used for", "task:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"used for\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "324": {"text": "First, we investigate how well the addressee of a dialogue act can be predicted based on gaze, utterance and conversational context features.", "true": [["gaze:other scientific term", "used for", "addressee of a dialogue act:other scientific term"], ["gaze:other scientific term", "conjunction", "utterance:other scientific term"], ["utterance:other scientific term", "used for", "addressee of a dialogue act:other scientific term"], ["utterance:other scientific term", "conjunction", "conversational context features:other scientific term"], ["conversational context features:other scientific term", "used for", "addressee of a dialogue act:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "325": {"text": "The results of this experiment, along with a preliminary analysis of the factors involved in the decision making process will be presented here.", "true": [], "pred": [["results:other scientific term", "part of", "experiment:task"], ["factors:other scientific term", "part of", "experiment:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"part of\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "326": {"text": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players.", "true": [["It:generic", "used for", "move selector:method"], ["It:generic", "used for", "move sorter:method"], ["It:generic", "used for", "training tool:task"], ["move selector:method", "conjunction", "move sorter:method"], ["move selector:method", "used for", "game tree search:method"], ["move sorter:method", "used for", "game tree search:method"], ["training tool:task", "used for", "Go players:other scientific term"]], "pred": [["game tree search:task", "used for", "move selector:method"], ["game tree search:task", "used for", "move sorter:method"], ["game tree search:task", "used for", "training tool:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"used for\"  \n(15) \"used for\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "327": {"text": "This paper highlights a particular class of miscommunication--reference problems--by describing a case study and techniques for avoiding failures of reference.", "true": [["reference problems:task", "hyponym of", "miscommunication:task"], ["techniques:generic", "used for", "failures of reference:task"]], "pred": [["miscommunication:other scientific term", "hyponym of", "reference problems:other scientific term"], ["reference problems:other scientific term", "hyponym of", "miscommunication:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"hyponym of\"  \n(6) \"hyponym of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "328": {"text": "We show that the trainable sentence planner performs better than the rule-based systems and the baselines, and as well as the hand-crafted system.", "true": [["trainable sentence planner:method", "compare", "rule-based systems:method"], ["trainable sentence planner:method", "compare", "baselines:generic"], ["trainable sentence planner:method", "compare", "hand-crafted system:method"], ["rule-based systems:method", "conjunction", "baselines:generic"], ["baselines:generic", "conjunction", "hand-crafted system:method"]], "pred": [["baselines:generic", "compare", "trainable sentence planner:method"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "330": {"text": "This processing description specifies in these recognition tasks the role of information from the discourse and from the participants' knowledge of the domain.", "true": [], "pred": [["processing description:other scientific term", "used for", "recognition tasks:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "332": {"text": "Our core motivation is that minimizing a weighted rank loss is a natural criterion for many problems in computer vision such as person re-identification.", "true": [["weighted rank loss:other scientific term", "used for", "computer vision:task"], ["weighted rank loss:other scientific term", "used for", "person re-identification:task"], ["person re-identification:task", "hyponym of", "computer vision:task"]], "pred": [["weighted rank loss:other scientific term", "used for", "problems in computer vision:task"], ["weighted rank loss:other scientific term", "used for", "person re-identification:task"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "333": {"text": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB-.", "true": [["OA:method", "used for", "phase locking in the auditory nerve -LRB- AN -RRB-:task"], ["OA:method", "used for", "features:other scientific term"], ["features:other scientific term", "evaluated for", "ASR accuracy:metric"], ["AN fibers -LRB- ANFs -RRB-:other scientific term", "used for", "features:other scientific term"]], "pred": [["phase locking:other scientific term", "used for", "features derived from AN fibers -LRB- ANFs -RRB-:other scientific term"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "334": {"text": "Multi-layer perceptrons -LRB- MLPs -RRB- performed much better than standard Gaussian mixture models -LRB- GMMs -RRB- for both our ANF-based and ON-based auditory features.", "true": [["Multi-layer perceptrons -LRB- MLPs -RRB-:method", "compare", "Gaussian mixture models -LRB- GMMs -RRB-:method"], ["Multi-layer perceptrons -LRB- MLPs -RRB-:method", "used for", "ANF-based and ON-based auditory features:other scientific term"], ["Gaussian mixture models -LRB- GMMs -RRB-:method", "used for", "ANF-based and ON-based auditory features:other scientific term"]], "pred": [["Multi-layer perceptrons -LRB- MLPs -RRB-:method", "compare", "Gaussian mixture models -LRB- GMMs -RRB-:method"], ["Gaussian mixture models -LRB- GMMs -RRB-:method", "compare", "Multi-layer perceptrons -LRB- MLPs -RRB-:method"]], "response": "(1) \"compare\"  \n(2) \"compare\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "335": {"text": "It is demonstrated qualitatively and quantitatively on a dataset of scenes and is suitable for current work in unsupervised object discovery without top-down knowledge.", "true": [["It:generic", "used for", "unsupervised object discovery:task"], ["It:generic", "evaluated for", "dataset of scenes:material"]], "pred": [["dataset of scenes:material", "used for", "current work in unsupervised object discovery:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "336": {"text": "This paper deals with the problem of generating the fundamental frequency -LRB- F0 -RRB- contour of speech from a text input for text-to-speech synthesis.", "true": [["fundamental frequency -LRB- F0 -RRB- contour of speech:other scientific term", "used for", "text-to-speech synthesis:task"], ["text input:material", "used for", "fundamental frequency -LRB- F0 -RRB- contour of speech:other scientific term"]], "pred": [["fundamental frequency -LRB- F0 -RRB- contour:other scientific term", "used for", "speech:other scientific term"], ["text input:material", "part of", "problem:task"], ["fundamental frequency -LRB- F0 -RRB- contour:other scientific term", "part of", "text-to-speech synthesis:method"], ["speech:other scientific term", "part of", "text-to-speech synthesis:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"part of\"  \n(11) \"part of\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "337": {"text": "The strong description and modeling properties of differential features make them useful tools that can be efficiently used as constraints for 3--D reconstruction.", "true": [["them:generic", "used for", "3--D reconstruction:task"]], "pred": [["differential features:other scientific term", "used for", "constraints:other scientific term"], ["differential features:other scientific term", "used for", "3--D reconstruction:task"], ["differential features:other scientific term", "feature of", "tools:generic"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "338": {"text": "This paper presents an unsupervised learning approach to disambiguate various relations between named entities by use of various lexical and syntactic features from the contexts.", "true": [["unsupervised learning approach:method", "used for", "relations between named entities:other scientific term"], ["lexical and syntactic features:other scientific term", "used for", "unsupervised learning approach:method"]], "pred": [["named entities:other scientific term", "used for", "unsupervised learning approach:method"], ["lexical and syntactic features:other scientific term", "used for", "unsupervised learning approach:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"used for\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "339": {"text": "Finally, we show how the estimation of the tensors from point correspondences is achieved through factorization, and discuss the estimation from line correspondences.", "true": [["point correspondences:other scientific term", "used for", "estimation of the tensors:task"], ["factorization:method", "used for", "tensors:generic"], ["line correspondences:other scientific term", "used for", "estimation:generic"]], "pred": [["point correspondences:other scientific term", "used for", "estimation of the tensors:task"], ["point correspondences:other scientific term", "used for", "estimation from line correspondences:task"], ["point correspondences:other scientific term", "used for", "factorization:method"], ["estimation of the tensors:task", "used for", "factorization:method"], ["estimation from line correspondences:task", "used for", "factorization:method"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "340": {"text": "As far as we can do in the rule-based approach is to give a default rule to pick up a corresponding classifier of each noun.", "true": [], "pred": [["classifier:other scientific term", "used for", "rule-based approach:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "342": {"text": "Contrary to most of the existing mixture of viewpoints models, our model establishes explicit correspondences of parts across different viewpoints of the object class.", "true": [["model:generic", "compare", "mixture of viewpoints models:method"]], "pred": [["mixture of viewpoints models:method", "compare", "model:method"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "343": {"text": "Overall summarization quality of the proposed system is state-of-the-art, with guaranteed grammaticality of the system output due to the use of a constraint-based parser/generator.", "true": [["system:generic", "evaluated for", "summarization quality:metric"], ["system:generic", "evaluated for", "grammaticality:metric"], ["constraint-based parser/generator:method", "used for", "system:generic"]], "pred": [["summarization quality:metric", "feature of", "state-of-the-art:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"feature of\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "344": {"text": "This research is part of a larger study of anaphoric expressions, the results of which will be incorporated into a natural language generation system.", "true": [["anaphoric expressions:other scientific term", "used for", "natural language generation system:method"]], "pred": [["research:generic", "part of", "results:generic"], ["anaphoric expressions:other scientific term", "part of", "research:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "346": {"text": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing.", "true": [["features:other scientific term", "used for", "lexical similarity:other scientific term"], ["features:other scientific term", "used for", "question-answer pairing:task"], ["structure of email-threads:other scientific term", "used for", "features:other scientific term"], ["lexical similarity:other scientific term", "feature of", "discourse segments:other scientific term"]], "pred": [["features:other scientific term", "used for", "structure of email-threads:other scientific term"], ["features:other scientific term", "used for", "discourse segments:other scientific term"], ["features:other scientific term", "used for", "question-answer pairing:task"], ["lexical similarity:metric", "feature of", "features:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"feature of\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "347": {"text": "SVMs are known to be robust to overfitting; however, a few training examples usually do not represent well the structure of the class.", "true": [["SVMs:method", "used for", "overfitting:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "348": {"text": "Sentence boundary detection in speech is important for enriching speech recognition output, making it easier for humans to read and downstream modules to process.", "true": [["Sentence boundary detection:task", "used for", "speech recognition output:other scientific term"], ["speech:material", "used for", "Sentence boundary detection:task"]], "pred": [["speech recognition output:other scientific term", "feature of", "speech:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"feature of\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "349": {"text": "In spite of over two decades of intense research, illumination and pose invariance remain prohibitively challenging aspects of face recognition for most practical applications.", "true": [["illumination:task", "conjunction", "pose invariance:task"], ["illumination:task", "part of", "face recognition:task"], ["pose invariance:task", "part of", "face recognition:task"]], "pred": [["illumination:other scientific term", "feature of", "face recognition:task"], ["pose invariance:other scientific term", "feature of", "face recognition:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "350": {"text": "We use novel priors, generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion.", "true": [["priors:other scientific term", "used for", "sparse and dense detection maps:other scientific term"], ["pathological motion:other scientific term", "conjunction", "occlusion:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "351": {"text": "These models simulate the reading time advantage for parallel structures found in human data, and also yield a small increase in overall parsing accuracy.", "true": [["parallel structures:other scientific term", "part of", "human data:material"]], "pred": [["reading time advantage:other scientific term", "used for", "models:method"], ["parallel structures:other scientific term", "used for", "models:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"used for\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "352": {"text": "This paper describes FERRET, an interactive question-answering -LRB- Q/A -RRB- system designed to address the challenges of integrating automatic Q/A applications into real-world environments.", "true": [["FERRET:method", "hyponym of", "interactive question-answering -LRB- Q/A -RRB- system:method"], ["FERRET:method", "used for", "integrating automatic Q/A applications into real-world environments:task"]], "pred": [["FERRET:method", "used for", "automatic Q/A applications:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "353": {"text": "In this paper, we introduce an annotation scheme for scientific articles which can be used to build such a resource in a consistent way.", "true": [["annotation scheme:method", "used for", "scientific articles:material"], ["annotation scheme:method", "used for", "resource:generic"]], "pred": [["annotation scheme:method", "used for", "resource:generic"], ["scientific articles:material", "part of", "annotation scheme:method"], ["scientific articles:material", "part of", "resource:generic"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "354": {"text": "These mistakes can lead to various kinds of misunderstandings between speaker and listener, including reference failures or failure to understand the speaker's intention.", "true": [], "pred": [["reference failures:other scientific term", "part of", "misunderstandings:other scientific term"], ["failure to understand the speaker's intention:task", "used for", "mistakes:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"part of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"used for\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "355": {"text": "The distinction among these components is essential to provide an adequate explanation of such discourse phenomena as cue phrases, referring expressions, and interruptions.", "true": [["cue phrases:other scientific term", "hyponym of", "discourse phenomena:other scientific term"], ["cue phrases:other scientific term", "conjunction", "referring expressions:other scientific term"], ["referring expressions:other scientific term", "hyponym of", "discourse phenomena:other scientific term"], ["referring expressions:other scientific term", "conjunction", "interruptions:other scientific term"], ["interruptions:other scientific term", "hyponym of", "discourse phenomena:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "356": {"text": "Coedition of a natural language text and its representation in some interlingual form seems the best and simplest way to share text revision across languages.", "true": [["Coedition:task", "used for", "text revision:other scientific term"], ["natural language text:material", "used for", "Coedition:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "357": {"text": "In the experiments, we used a variety of methods for preparing a segmented corpus and compared the language models by their speech recognition accuracies.", "true": [["methods:generic", "used for", "preparing a segmented corpus:task"], ["language models:method", "evaluated for", "speech recognition accuracies:metric"]], "pred": [["speech recognition accuracies:metric", "used for", "segmented corpus:material"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "358": {"text": "Metagrammatical formalisms that combine context-free phrase structure rules and metarules -LRB- MPS grammars -RRB- allow concise statement of generalizations about the syntax of natural languages.", "true": [["context-free phrase structure rules:other scientific term", "part of", "Metagrammatical formalisms:method"], ["context-free phrase structure rules:other scientific term", "conjunction", "metarules -LRB- MPS grammars -RRB-:other scientific term"], ["metarules -LRB- MPS grammars -RRB-:other scientific term", "part of", "Metagrammatical formalisms:method"]], "pred": [["context-free phrase structure rules:other scientific term", "used for", "Metagrammatical formalisms:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "360": {"text": "We also found that OA is crucial for auditory processing by onset neurons -LRB- ONs -RRB- in the next neuronal stage, the auditory brainstem.", "true": [["OA:method", "used for", "auditory processing:task"], ["onset neurons -LRB- ONs -RRB-:other scientific term", "used for", "OA:method"]], "pred": [["OA:other scientific term", "used for", "onset neurons -LRB- ONs -RRB-:other scientific term"], ["onset neurons -LRB- ONs -RRB-:other scientific term", "part of", "auditory brainstem:other scientific term"], ["OA:other scientific term", "used for", "auditory processing:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "361": {"text": "Many of the resources used are derived from data created by human beings out of an NLP context, especially regarding MT and reference translations.", "true": [["MT:task", "hyponym of", "NLP:task"], ["MT:task", "conjunction", "reference translations:task"], ["reference translations:task", "hyponym of", "NLP:task"]], "pred": [["resources:material", "part of", "human beings:other scientific term"], ["resources:material", "part of", "NLP context:other scientific term"], ["resources:material", "part of", "MT:other scientific term"], ["reference translations:material", "part of", "NLP context:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"part of\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"part of\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "362": {"text": "We have previously introduced a statistical model describing the generating process of speech F0 contours, based on the discrete-time version of the Fujisaki model.", "true": [["statistical model:method", "used for", "speech F0 contours:other scientific term"], ["Fujisaki model:method", "used for", "statistical model:method"]], "pred": [["speech F0 contours:other scientific term", "feature of", "Fujisaki model:other scientific term"], ["discrete-time version:other scientific term", "part of", "Fujisaki model:other scientific term"], ["speech F0 contours:other scientific term", "feature of", "generating process:task"], ["speech F0 contours:other scientific term", "feature of", "statistical model:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"feature of\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "363": {"text": "We introduce a method to accelerate the evaluation of object detection cascades with the help of a divide-and-conquer procedure in the space of candidate regions.", "true": [["method:generic", "used for", "evaluation of object detection cascades:task"], ["divide-and-conquer procedure:method", "used for", "method:generic"], ["space of candidate regions:method", "feature of", "divide-and-conquer procedure:method"]], "pred": [["method:generic", "used for", "object detection cascades:method"], ["candidate regions:other scientific term", "part of", "object detection cascades:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "364": {"text": "Information distillation aims to extract relevant pieces of information related to a given query from massive, possibly multilingual, audio and textual document sources.", "true": [], "pred": [["relevant pieces of information:other scientific term", "part of", "information distillation:task"], ["audio and textual document sources:material", "used for", "information distillation:task"], ["audio and textual document sources:material", "part of", "relevant pieces of information:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "365": {"text": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese.", "true": [["approach:generic", "used for", "Multi-lingual Evaluation Task -LRB- MET -RRB-:task"], ["Multi-lingual Evaluation Task -LRB- MET -RRB-:task", "used for", "Japanese text:material"], ["morphological analysis problem:task", "used for", "task:generic"], ["Japanese:material", "used for", "morphological analysis problem:task"]], "pred": [["Multi-lingual Evaluation Task -LRB- MET -RRB-:task", "used for", "morphological analysis problem:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "366": {"text": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns, and exhibit strong invariance to rotation, illumination variation, and blur.", "true": [["detectors:generic", "used for", "large-scale structures:other scientific term"], ["detectors:generic", "used for", "distinctive textured patterns:other scientific term"], ["detectors:generic", "used for", "rotation:other scientific term"], ["detectors:generic", "used for", "illumination variation:other scientific term"], ["detectors:generic", "used for", "blur:other scientific term"], ["large-scale structures:other scientific term", "conjunction", "distinctive textured patterns:other scientific term"], ["rotation:other scientific term", "conjunction", "illumination variation:other scientific term"], ["illumination variation:other scientific term", "conjunction", "blur:other scientific term"]], "pred": [["large-scale structures:other scientific term", "feature of", "proposed detectors:method"], ["distinctive textured patterns:other scientific term", "feature of", "proposed detectors:method"], ["strong invariance:other scientific term", "feature of", "proposed detectors:method"], ["rotation:other scientific term", "feature of", "proposed detectors:method"], ["illumination variation:other scientific term", "feature of", "proposed detectors:method"], ["blur:other scientific term", "feature of", "proposed detectors:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"feature of\"  \n(32) \"feature of\"  \n(33) \"feature of\"  \n(34) \"feature of\"  \n(35) \"feature of\"  \n(36) \"feature of\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "367": {"text": "This paper proposes a generic mathematical formalism for the combination of various structures: strings, trees, dags, graphs, and products of them.", "true": [["strings:other scientific term", "hyponym of", "structures:generic"], ["strings:other scientific term", "conjunction", "trees:other scientific term"], ["trees:other scientific term", "hyponym of", "structures:generic"], ["trees:other scientific term", "conjunction", "dags:other scientific term"], ["dags:other scientific term", "hyponym of", "structures:generic"], ["dags:other scientific term", "conjunction", "graphs:other scientific term"], ["graphs:other scientific term", "hyponym of", "structures:generic"]], "pred": [["strings:other scientific term", "part of", "various structures:other scientific term"], ["trees:other scientific term", "part of", "various structures:other scientific term"], ["dags:other scientific term", "part of", "various structures:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"part of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"part of\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"part of\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "368": {"text": "We consider the problem of computing the Kullback-Leibler distance, also called the relative entropy, between a probabilistic context-free grammar and a probabilistic finite automaton.", "true": [["probabilistic context-free grammar:method", "compare", "probabilistic finite automaton:other scientific term"]], "pred": [["Kullback-Leibler distance:other scientific term", "compare", "relative entropy:other scientific term"], ["Kullback-Leibler distance:other scientific term", "used for", "computing:task"], ["relative entropy:other scientific term", "used for", "computing:task"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"used for\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "369": {"text": "The subjects were given three minutes per extract to determine whether they believed the sample output to be an expert human translation or a machine translation.", "true": [["expert human translation:other scientific term", "compare", "machine translation:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "370": {"text": "We evaluated the topic signatures on a WSD task, where we trained a second-order vector cooccurrence algorithm on standard WSD datasets, with promising results.", "true": [["topic signatures:other scientific term", "evaluated for", "WSD task:task"], ["WSD datasets:material", "used for", "second-order vector cooccurrence algorithm:method"]], "pred": [["topic signatures:other scientific term", "used for", "WSD task:task"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "371": {"text": "Joint matrix triangularization is often used for estimating the joint eigenstructure of a set M of matrices, with applications in signal processing and machine learning.", "true": [["Joint matrix triangularization:task", "used for", "joint eigenstructure:other scientific term"], ["joint eigenstructure:other scientific term", "used for", "signal processing:task"], ["joint eigenstructure:other scientific term", "used for", "machine learning:task"], ["signal processing:task", "conjunction", "machine learning:task"]], "pred": [["joint eigenstructure:other scientific term", "used for", "signal processing:task"], ["joint eigenstructure:other scientific term", "used for", "machine learning:task"], ["joint eigenstructure:other scientific term", "part of", "joint matrix triangularization:method"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"part of\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "372": {"text": "However, acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction, active sensing devices and/or synthetic scenes.", "true": [["manual interaction:other scientific term", "used for", "task:generic"], ["manual interaction:other scientific term", "conjunction", "active sensing devices:other scientific term"], ["active sensing devices:other scientific term", "used for", "task:generic"], ["active sensing devices:other scientific term", "conjunction", "synthetic scenes:other scientific term"], ["synthetic scenes:other scientific term", "used for", "task:generic"]], "pred": [["training data:material", "part of", "tedious and time consuming task:task"], ["synthetic scenes:material", "part of", "tedious and time consuming task:task"], ["manual interaction:method", "used for", "tedious and time consuming task:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"used for\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "374": {"text": "By employing a joint classification and regression optimization objective, this network is capable of automatically localizing the start and end points of actions more accurately.", "true": [["joint classification and regression optimization objective:other scientific term", "used for", "network:generic"]], "pred": [["joint classification and regression optimization objective:method", "used for", "network:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "376": {"text": "When a segment is found to be an NE item, this information is added to the segment and it is used to generate the final output.", "true": [], "pred": [["segment:other scientific term", "used for", "NE item:other scientific term"], ["segment:other scientific term", "used for", "final output:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "377": {"text": "Building on previous work at Carnegie-Mellon University e.g. -LSB- 4, 5, 8 -RSB-, Plume's approach to parsing is based on semantic caseframe instantiation.", "true": [["Plume's approach:method", "used for", "parsing:task"], ["semantic caseframe instantiation:other scientific term", "used for", "Plume's approach:method"]], "pred": [["parsing:task", "part of", "Plume's approach:method"], ["parsing:task", "part of", "semantic caseframe instantiation:method"], ["Plume's approach:method", "part of", "parsing:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "378": {"text": "In the simpler case of affine cameras we give neccessary and sufficient constraints on the components of the trifocal tensor, together with a simple geometric interpretation.", "true": [], "pred": [["necessary and sufficient constraints:other scientific term", "part of", "affine cameras:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "379": {"text": "Given a new image, detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects.", "true": [["image:material", "used for", "detection:task"], ["image:material", "used for", "classification:task"], ["detection:task", "conjunction", "classification:task"], ["position:other scientific term", "used for", "detection:task"], ["position:other scientific term", "used for", "classification:task"], ["position:other scientific term", "conjunction", "viewpoint:other scientific term"], ["viewpoint:other scientific term", "used for", "detection:task"], ["viewpoint:other scientific term", "used for", "classification:task"]], "pred": [["position:other scientific term", "part of", "model:other scientific term"], ["position:other scientific term", "used for", "detection:task"], ["position:other scientific term", "used for", "classification:task"], ["viewpoint:other scientific term", "used for", "detection:task"], ["viewpoint:other scientific term", "used for", "classification:task"], ["model:other scientific term", "used for", "detection:task"], ["model:other scientific term", "used for", "classification:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"used for\"  \n(15) \"used for\"  \n(16) \"used for\"  \n(17) \"used for\"  \n(18) \"used for\"  \n(19) \"used for\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "380": {"text": "Using the IEMOCAP database, discrete -LRB- categorical -RRB- and continuous -LRB- attribute -RRB- emotional assessments evaluated by the actors and na \u00a8 \u0131ve listeners are compared.", "true": [["IEMOCAP database:material", "used for", "discrete -LRB- categorical -RRB- and continuous -LRB- attribute -RRB- emotional assessments:task"]], "pred": [["discrete -LRB- categorical -RRB- emotional assessments:other scientific term", "compare", "continuous -LRB- attribute -RRB- emotional assessments:other scientific term"], ["continuous -LRB- attribute -RRB- emotional assessments:other scientific term", "compare", "discrete -LRB- categorical -RRB- emotional assessments:other scientific term"], ["IEMOCAP database:material", "used for", "discrete -LRB- categorical -RRB- emotional assessments:other scientific term"], ["IEMOCAP database:material", "used for", "continuous -LRB- attribute -RRB- emotional assessments:other scientific term"]], "response": "(1) \"compare\"  \n(2) \"compare\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "381": {"text": "A separation method is proposed that is nearly statistically efficient -LRB- approaching the corresponding Cram\u00e9r-Rao lower bound -RRB-, if the separated signals obey the assumed model.", "true": [["Cram\u00e9r-Rao lower bound -RRB-:other scientific term", "feature of", "separation method:method"]], "pred": [["Cram\u00e9r-Rao lower bound:other scientific term", "feature of", "separation method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "382": {"text": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision, and that it can handle many challenges of active reconstruction systems.", "true": [["method:generic", "used for", "scene geometry:other scientific term"], ["subpixel precision:metric", "feature of", "scene geometry:other scientific term"], ["it:generic", "used for", "active reconstruction systems:task"]], "pred": [["high subpixel precision:metric", "feature of", "simulated and experimental results:material"], ["scene geometry:other scientific term", "part of", "our method:method"], ["active reconstruction systems:other scientific term", "part of", "our method:method"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"part of\"  \n(7) \"part of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "383": {"text": "We believe that these evaluation techniques will provide information about both the human language learning process, the translation process and the development of machine translation systems.", "true": [["evaluation techniques:generic", "used for", "human language learning process:task"], ["evaluation techniques:generic", "used for", "translation process:task"], ["evaluation techniques:generic", "used for", "machine translation systems:task"], ["human language learning process:task", "conjunction", "translation process:task"], ["translation process:task", "conjunction", "machine translation systems:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "384": {"text": "Hitherto, smooth motion has been encouraged using a trajectory basis, yielding a hard combinatorial problem with time complexity growing exponentially in the number of frames.", "true": [["trajectory basis:other scientific term", "used for", "smooth motion:other scientific term"], ["hard combinatorial problem:task", "evaluated for", "time complexity:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "385": {"text": "Given an object model and a black-box measure of similarity between the model and candidate targets, we consider visual object tracking as a numerical optimization problem.", "true": [["numerical optimization problem:task", "used for", "visual object tracking:task"]], "pred": [["object model:other scientific term", "used for", "visual object tracking:task"], ["object model:other scientific term", "used for", "numerical optimization problem:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "386": {"text": "In order to perform an exhaustive comparison, we also evaluate a hand-crafted template-based generation component, two rule-based sentence planners, and two baseline sentence planners.", "true": [["hand-crafted template-based generation component:method", "conjunction", "rule-based sentence planners:method"], ["rule-based sentence planners:method", "conjunction", "baseline sentence planners:method"]], "pred": [["hand-crafted template-based generation component:method", "evaluated for", "rule-based sentence planners:method"], ["hand-crafted template-based generation component:method", "evaluated for", "baseline sentence planners:method"], ["hand-crafted template-based generation component:method", "used for", "exhaustive comparison:task"]], "response": "(1) \"evaluated for\"  \n(2) \"evaluated for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "387": {"text": "In this work, we study how Convolutional Neural Networks -LRB- CNN -RRB- architectures can be adapted to the task of simultaneous object recognition and pose estimation.", "true": [["Convolutional Neural Networks -LRB- CNN -RRB- architectures:method", "used for", "object recognition:task"], ["Convolutional Neural Networks -LRB- CNN -RRB- architectures:method", "used for", "pose estimation:task"], ["object recognition:task", "conjunction", "pose estimation:task"]], "pred": [["task of simultaneous object recognition and pose estimation:task", "used for", "Convolutional Neural Networks -LRB- CNN -RRB-:method"]], "response": "(1) \"used for\"  \n(2) \"none\"\n"}, "388": {"text": "Based on our analysis, we further develop a novel line-assisted graph-cut -LRB- LAGC -RRB- algorithm that effectively encodes 3D line constraints into light field stereo matching.", "true": [], "pred": [["analysis:generic", "used for", "line-assisted graph-cut -LRB- LAGC -RRB-:method"], ["3D line constraints:other scientific term", "used for", "light field stereo matching:task"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "389": {"text": "The description has been implemented using the PC-KIMMO environment -LRB- Antworth, 1990 -RRB- and is based on a root word lexicon of about 23,000 roots words.", "true": [["PC-KIMMO environment:method", "used for", "description:generic"], ["root word lexicon:material", "used for", "description:generic"]], "pred": [["root word lexicon:material", "part of", "description:generic"], ["000 roots words:material", "part of", "description:generic"], ["description:generic", "used for", "root word lexicon:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"part of\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "390": {"text": "To associate a sequence of the Fujisaki-model parameters with a text input based on statistical learning, this paper proposes extending this model to a context-dependent one.", "true": [["text input:material", "used for", "Fujisaki-model parameters:other scientific term"], ["statistical learning:method", "used for", "Fujisaki-model parameters:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "391": {"text": "Bayesian inference then samples the rules, disambiguating and combining them to create complex tree structures that maximize a discriminative model's posterior on a target unlabeled corpus.", "true": [["Bayesian inference:method", "used for", "rules:other scientific term"], ["them:generic", "used for", "complex tree structures:other scientific term"], ["complex tree structures:other scientific term", "used for", "discriminative model's posterior:other scientific term"], ["unlabeled corpus:material", "used for", "discriminative model's posterior:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "392": {"text": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms, such as rewriting systems, dependency grammars, TAG, HPSG and LFG.", "true": [["formalism:generic", "used for", "grammar formalisms:method"], ["rewriting systems:method", "hyponym of", "grammar formalisms:method"], ["rewriting systems:method", "conjunction", "dependency grammars:method"], ["dependency grammars:method", "hyponym of", "grammar formalisms:method"], ["dependency grammars:method", "conjunction", "TAG:other scientific term"], ["TAG:other scientific term", "hyponym of", "grammar formalisms:method"], ["TAG:other scientific term", "conjunction", "HPSG:other scientific term"], ["HPSG:other scientific term", "hyponym of", "grammar formalisms:method"], ["HPSG:other scientific term", "conjunction", "LFG:other scientific term"], ["LFG:other scientific term", "hyponym of", "grammar formalisms:method"]], "pred": [["grammar formalisms:other scientific term", "hyponym of", "formalism:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"hyponym of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "393": {"text": "In comparison with previous works, in this paper it is assumed that the signals are not i.i.d. in each epoch, but obey a first-order autoregressive model.", "true": [["first-order autoregressive model:method", "used for", "signals:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "394": {"text": "We explored possible ways to obtain a compact lexicon, consistent with CCG principles, from a treebank which is an order of magnitude smaller than Penn WSJ.", "true": [["compact lexicon:other scientific term", "part of", "treebank:generic"], ["treebank:generic", "compare", "Penn WSJ:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "395": {"text": "In this paper, a novel framework for machine transliteration/backtransliteration that allows us to carry out direct orthographical mapping -LRB- DOM -RRB- between two different languages is presented.", "true": [["framework:generic", "used for", "machine transliteration/backtransliteration:task"], ["machine transliteration/backtransliteration:task", "used for", "direct orthographical mapping -LRB- DOM -RRB-:method"]], "pred": [["novel framework:method", "used for", "machine transliteration/backtransliteration:task"], ["direct orthographical mapping -LRB- DOM -RRB-:method", "used for", "machine transliteration/backtransliteration:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "396": {"text": "Under this framework, a joint source-channel transliteration model, also called n-gram transliteration model -LRB- n-gram TM -RRB-, is further proposed to model the transliteration process.", "true": [["framework:generic", "used for", "joint source-channel transliteration model:method"], ["n-gram transliteration model -LRB- n-gram TM -RRB-:method", "used for", "transliteration process:method"]], "pred": [["transliteration process:task", "used for", "joint source-channel transliteration model:method"], ["transliteration process:task", "used for", "n-gram transliteration model -LRB- n-gram TM -RRB-:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "398": {"text": "In the second half of the paper, we report a laboratory study using the Wizard of Oz technique to identify NL requirements for carrying out this task.", "true": [["Wizard of Oz technique:method", "used for", "NL requirements:other scientific term"], ["Wizard of Oz technique:method", "used for", "task:generic"]], "pred": [["NL requirements:other scientific term", "used for", "carrying out this task:task"], ["laboratory study:method", "part of", "second half of the paper:generic"], ["Wizard of Oz technique:method", "part of", "second half of the paper:generic"], ["NL requirements:other scientific term", "part of", "laboratory study:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"part of\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "400": {"text": "This phenomenon causes many image processing techniques to fail as they assume the presence of only one layer at each examined site e.g. motion estimation and object recognition.", "true": [["motion estimation:task", "conjunction", "object recognition:task"]], "pred": [["one layer:other scientific term", "part of", "each examined site:other scientific term"], ["phenomenon:other scientific term", "used for", "motion estimation:task"], ["phenomenon:other scientific term", "used for", "object recognition:task"], ["motion estimation:task", "used for", "image processing techniques:method"], ["object recognition:task", "used for", "image processing techniques:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"used for\"  \n(25) \"used for\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "401": {"text": "Experiments on the TREC Blog track test set show that both groups of credibility indicators significantly improve retrieval effectiveness; the best performance is achieved when combining them.", "true": [["credibility indicators:other scientific term", "evaluated for", "TREC Blog track test set:material"], ["credibility indicators:other scientific term", "evaluated for", "retrieval effectiveness:metric"]], "pred": [["retrieval effectiveness:metric", "feature of", "best performance:metric"], ["TREC Blog track test set:material", "part of", "Experiments:task"], ["retrieval effectiveness:metric", "feature of", "credibility indicators:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "402": {"text": "Topic signatures can be useful in a number of Natural Language Processing -LRB- NLP -RRB- applications, such as Word Sense Disambiguation -LRB- WSD -RRB- and Text Summarisation.", "true": [["Topic signatures:other scientific term", "used for", "Natural Language Processing -LRB- NLP -RRB- applications:task"], ["Topic signatures:other scientific term", "used for", "Word Sense Disambiguation -LRB- WSD -RRB-:task"], ["Topic signatures:other scientific term", "used for", "Text Summarisation:task"], ["Word Sense Disambiguation -LRB- WSD -RRB-:task", "hyponym of", "Natural Language Processing -LRB- NLP -RRB- applications:task"], ["Word Sense Disambiguation -LRB- WSD -RRB-:task", "conjunction", "Text Summarisation:task"], ["Text Summarisation:task", "hyponym of", "Natural Language Processing -LRB- NLP -RRB- applications:task"]], "pred": [["topic signatures:other scientific term", "used for", "Word Sense Disambiguation -LRB- WSD -RRB-:task"], ["topic signatures:other scientific term", "used for", "Text Summarisation:task"], ["topic signatures:other scientific term", "used for", "Natural Language Processing -LRB- NLP -RRB-:method"], ["Text Summarisation:task", "used for", "Natural Language Processing -LRB- NLP -RRB-:method"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "403": {"text": "The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm.", "true": [["view points:other scientific term", "used for", "approach:generic"]], "pred": [["key idea:generic", "part of", "approach:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "404": {"text": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge.", "true": [["method:method", "used for", "shape constrained image segmentation:task"], ["mixtures of feature distributions:other scientific term", "used for", "method:method"], ["mixtures of feature distributions:other scientific term", "used for", "color:other scientific term"], ["mixtures of feature distributions:other scientific term", "used for", "texture:other scientific term"], ["mixtures of feature distributions:other scientific term", "used for", "probabilistic shape knowledge:other scientific term"], ["color:other scientific term", "conjunction", "texture:other scientific term"], ["texture:other scientific term", "conjunction", "probabilistic shape knowledge:other scientific term"]], "pred": [["method:generic", "used for", "mixtures of feature distributions:method"], ["color:other scientific term", "used for", "shape constrained image segmentation:task"], ["texture:other scientific term", "used for", "shape constrained image segmentation:task"], ["probabilistic shape knowledge:other scientific term", "used for", "shape constrained image segmentation:task"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "405": {"text": "Extended CF grammars -LRB- grammars with regular expressions at the right hand side -RRB- can be parsed with a simple modification of the LR-parser for normal CF grammars.", "true": [["regular expressions:other scientific term", "feature of", "grammars:method"], ["LR-parser:method", "used for", "Extended CF grammars:method"], ["LR-parser:method", "used for", "CF grammars:method"]], "pred": [["grammars with regular expressions:other scientific term", "part of", "normal CF grammars:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "406": {"text": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features.", "true": [["Kernel space embedding:other scientific term", "used for", "inarbitrary distance measures:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "407": {"text": "In this paper, we propose to concentrate on correcting the positions in which the words in the list appear by taking a word as a correction unit.", "true": [], "pred": [["words in the list:material", "used for", "correcting the positions:task"], ["word as a correction unit:method", "part of", "this paper:generic"], ["correcting the positions:task", "part of", "word as a correction unit:method"], ["words in the list:material", "part of", "word as a correction unit:method"], ["correcting the positions:task", "part of", "this paper:generic"], ["word as a correction unit:method", "used for", "correcting the positions:task"], ["words in the list:material", "part of", "this paper:generic"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"part of\"  \n(6) \"part of\"  \n(7) \"used for\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "408": {"text": "In this paper, we propose a novel moderate positive sample mining method to train robust CNN for person re-identification, dealing with the problem of large variation.", "true": [["moderate positive sample mining method:method", "used for", "robust CNN:method"], ["robust CNN:method", "used for", "person re-identification:task"]], "pred": [["novel moderate positive sample mining method:method", "used for", "robust CNN:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "409": {"text": "We propose a novel step toward the unsupervised seg-mentation of whole objects by combining\" hints\" of partial scene segmentation offered by multiple soft, binary mattes.", "true": [["partial scene segmentation:task", "used for", "unsupervised seg-mentation of whole objects:task"], ["soft, binary mattes:other scientific term", "used for", "partial scene segmentation:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "411": {"text": "Furthermore, we show how the recently developed efficient subwindow search -LRB- ESS -RRB- procedure -LSB- 11 -RSB- can be integrated into the last stage of our method.", "true": [["subwindow search -LRB- ESS -RRB- procedure:method", "part of", "method:generic"]], "pred": [["last stage:generic", "part of", "our method:method"], ["efficient subwindow search -LRB- ESS -RRB-:method", "used for", "our method:method"]], "response": "(1) \"none\"  \n(2) \"part of\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "412": {"text": "We show how this can efficiently be combined with random-projection based methods for 2 NN search, such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees.", "true": [["this:generic", "conjunction", "random-projection based methods:method"], ["random-projection based methods:method", "used for", "NN search:task"], ["locality-sensitive hashing -LRB- LSH -RRB-:method", "hyponym of", "random-projection based methods:method"], ["locality-sensitive hashing -LRB- LSH -RRB-:method", "conjunction", "random projection trees:method"], ["random projection trees:method", "hyponym of", "random-projection based methods:method"]], "pred": [["this:generic", "used for", "random-projection based methods:method"], ["2 NN search:task", "used for", "random-projection based methods:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "413": {"text": "Second, based on the information resulting from the dictionary lookup stage, a set of rules is applied to the segmented strings in order to identify NE items.", "true": [["dictionary lookup stage:method", "used for", "rules:other scientific term"], ["rules:other scientific term", "used for", "NE items:other scientific term"]], "pred": [["segmented strings:material", "used for", "NE items:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "414": {"text": "We explain this distinction and we show how this model may be applied to the interpretation of compounds in real texts, provided that complementary semantic information are retrieved.", "true": [["model:generic", "used for", "interpretation of compounds:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "415": {"text": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives, relative clauses, and interrogatives in a general manner.", "true": [["Plume:method", "used for", "passives:other scientific term"], ["Plume:method", "used for", "relative clauses:other scientific term"], ["Plume:method", "used for", "interrogatives:other scientific term"], ["passives:other scientific term", "conjunction", "relative clauses:other scientific term"], ["relative clauses:other scientific term", "conjunction", "interrogatives:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "416": {"text": "Our system incorporates a linguistic parser/generator for LFG, a transfer component for parse reduction operating on packed parse forests, and a maximum-entropy model for stochastic output selection.", "true": [["linguistic parser/generator:method", "part of", "system:generic"], ["linguistic parser/generator:method", "used for", "LFG:method"], ["linguistic parser/generator:method", "conjunction", "transfer component:method"], ["transfer component:method", "part of", "system:generic"], ["transfer component:method", "used for", "parse reduction:task"], ["transfer component:method", "conjunction", "maximum-entropy model:method"], ["packed parse forests:other scientific term", "used for", "parse reduction:task"], ["maximum-entropy model:method", "part of", "system:generic"], ["maximum-entropy model:method", "used for", "stochastic output selection:task"]], "pred": [["system:generic", "used for", "linguistic parser/generator for LFG:method"], ["system:generic", "used for", "transfer component for parse reduction:method"], ["system:generic", "used for", "maximum-entropy model:method"], ["linguistic parser/generator for LFG:method", "part of", "system:generic"], ["transfer component for parse reduction:method", "part of", "system:generic"], ["maximum-entropy model:method", "part of", "system:generic"], ["packed parse forests:other scientific term", "part of", "linguistic parser/generator for LFG:method"], ["packed parse forests:other scientific term", "part of", "transfer component for parse reduction:method"], ["packed parse forests:other scientific term", "part of", "maximum-entropy model:method"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"part of\"  \n(13) \"part of\"  \n(14) \"part of\"  \n(15) \"part of\"  \n(16) \"part of\"  \n(17) \"part of\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "417": {"text": "Thus, in this paper, we study the problem of robust PCA with side information, where both prior structure and features of entities are exploited for recovery.", "true": [["side information:other scientific term", "used for", "robust PCA:method"], ["prior structure:other scientific term", "conjunction", "features of entities:other scientific term"], ["prior structure:other scientific term", "used for", "recovery:task"], ["features of entities:other scientific term", "used for", "recovery:task"]], "pred": [["side information:other scientific term", "used for", "features of entities:other scientific term"], ["prior structure:other scientific term", "part of", "features of entities:other scientific term"], ["side information:other scientific term", "used for", "robust PCA:task"], ["prior structure:other scientific term", "used for", "robust PCA:task"], ["features of entities:other scientific term", "used for", "robust PCA:task"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"used for\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "419": {"text": "The system incorporates a decision-tree classifier for 30 scf types which tests for the presence of grammatical relations -LRB- grs -RRB- in the output of a robust statistical parser.", "true": [["decision-tree classifier:method", "part of", "system:generic"], ["decision-tree classifier:method", "used for", "grammatical relations -LRB- grs -RRB-:other scientific term"]], "pred": [["decision-tree classifier:method", "part of", "system:generic"], ["30 scf types:material", "part of", "grammatical relations -LRB- grs -RRB-:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "420": {"text": "A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition.", "true": [["tool:generic", "used for", "linguistic annotation of scfs:task"], ["training and test data:material", "used for", "subcategorization acquisition:task"]], "pred": [["tool:method", "used for", "linguistic annotation:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "421": {"text": "This model mimics the way in which images are processed in the visual pathway, rendering a feasible alternative for the implementation of early vision applications in standard technologies.", "true": [["visual pathway:method", "used for", "images:material"]], "pred": [["visual pathway:other scientific term", "feature of", "model:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "422": {"text": "In this paper, we evaluate the use of a conditional random field -LRB- CRF -RRB- for this task and relate results with this model to our prior work.", "true": [["conditional random field -LRB- CRF -RRB-:method", "used for", "task:generic"]], "pred": [["task:generic", "evaluated for", "conditional random field -LRB- CRF -RRB-:method"]], "response": "(1) \"evaluated for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "423": {"text": "To overcome this problem, we propose a new, flexible, and scalable way for generating training data that only requires a set of stereo images as input.", "true": [], "pred": [["training data:material", "used for", "and scalable way:method"], ["set of stereo images:material", "used for", "and scalable way:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "424": {"text": "Online action detection goes one step further and is more challenging, which identifies the action type and localizes the action positions on the fly from the untrimmed stream.", "true": [["Online action detection:task", "used for", "action type:other scientific term"], ["Online action detection:task", "used for", "action positions:other scientific term"], ["action type:other scientific term", "conjunction", "action positions:other scientific term"], ["untrimmed stream:material", "used for", "Online action detection:task"]], "pred": [["action type:other scientific term", "part of", "online action detection:task"], ["action positions:other scientific term", "part of", "online action detection:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "425": {"text": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU, NIST, WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment.", "true": [["MT evaluation methods:metric", "used for", "classifiers:method"], ["BLEU:metric", "hyponym of", "MT evaluation methods:metric"], ["BLEU:metric", "conjunction", "NIST:metric"], ["NIST:metric", "hyponym of", "MT evaluation methods:metric"], ["NIST:metric", "conjunction", "WER:metric"], ["WER:metric", "hyponym of", "MT evaluation methods:metric"], ["WER:metric", "conjunction", "PER:metric"], ["PER:metric", "hyponym of", "MT evaluation methods:metric"], ["classifiers:method", "used for", "semantic equivalence:task"], ["classifiers:method", "used for", "entailment:task"], ["semantic equivalence:task", "conjunction", "entailment:task"]], "pred": [["standard MT evaluation methods:method", "used for", "classifiers:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "426": {"text": "We also introduce a novel classification method based on PER which leverages part of speech information of the words contributing to the word matches and non-matches in the sentence.", "true": [["PER:metric", "used for", "classification method:method"], ["PER:metric", "used for", "part of speech information:other scientific term"], ["part of speech information:other scientific term", "used for", "word matches and non-matches:task"]], "pred": [["part of speech information:other scientific term", "hyponym of", "PER:other scientific term"], ["word matches:other scientific term", "part of", "part of speech information:other scientific term"], ["PER:other scientific term", "used for", "classification method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"hyponym of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"used for\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "428": {"text": "For example, nucleotides in a DNA sequence, children's names in a given state and year, and text documents are all commonly modeled with multinomial distributions.", "true": [["multinomial distributions:method", "used for", "nucleotides in a DNA sequence:material"], ["multinomial distributions:method", "used for", "text documents:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "429": {"text": "Based on this, MINPRAN uses random sampling to search for the t and the number of inliers to the t that are least likely to have occurred randomly.", "true": [["random sampling:method", "used for", "MINPRAN:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "430": {"text": "We take advantage of the fact that some of the distillation queries can be associated with annotation elements introduced for the NIST Automatic Content Extraction -LRB- ACE -RRB- task.", "true": [], "pred": [["distillation queries:other scientific term", "used for", "NIST Automatic Content Extraction -LRB- ACE -RRB-:task"], ["distillation queries:other scientific term", "used for", "task:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "431": {"text": "While Plume is well adapted to simple declarative and imperative utterances, it handles passives, relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage.", "true": [["Plume:method", "used for", "declarative and imperative utterances:material"], ["it:generic", "used for", "passives:other scientific term"], ["it:generic", "used for", "relative clauses:other scientific term"], ["it:generic", "used for", "interrogatives:other scientific term"], ["passives:other scientific term", "conjunction", "relative clauses:other scientific term"], ["relative clauses:other scientific term", "conjunction", "interrogatives:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "432": {"text": "In addition to the high accuracy of the model, the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results.", "true": [["model:generic", "evaluated for", "accuracy:metric"], ["smoothing:method", "used for", "unlexicalized parser:method"]], "pred": [["model:generic", "part of", "unlexicalized parser:method"], ["smoothing:method", "feature of", "model:generic"], ["unlexicalized parser:method", "part of", "model:generic"]], "response": "(1) \"none\"  \n(2) \"part of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "433": {"text": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions.", "true": [["convex problem:task", "used for", "side information:other scientific term"], ["side information:other scientific term", "part of", "robust PCA:method"], ["method:generic", "used for", "low rank matrix:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "434": {"text": "Evaluation on the ACE 2003 corpus shows that the convolution kernel over parse trees can achieve comparable performance with the previous best-reported feature-based methods on the 24 ACE relation subtypes.", "true": [["convolution kernel over parse trees:method", "evaluated for", "ACE 2003 corpus:material"], ["feature-based methods:method", "compare", "convolution kernel over parse trees:method"]], "pred": [["convolution kernel over parse trees:method", "compare", "previous best-reported feature-based methods:method"]], "response": "(1) \"none\"  \n(2) \"compare\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "435": {"text": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage, sum-of-pairs, k-means, and k-median.", "true": [["single-linkage:method", "hyponym of", "well-studied clustering techniques:method"], ["single-linkage:method", "conjunction", "sum-of-pairs:method"], ["sum-of-pairs:method", "hyponym of", "well-studied clustering techniques:method"], ["sum-of-pairs:method", "conjunction", "k-means:method"], ["k-means:method", "hyponym of", "well-studied clustering techniques:method"], ["k-means:method", "conjunction", "k-median:method"], ["k-median:method", "hyponym of", "well-studied clustering techniques:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "436": {"text": "The results of the experiment show that in most of the cases the cooccurrence statistics indeed reflect the semantic constraints and thus provide a basis for a useful disambiguation tool.", "true": [["cooccurrence statistics:other scientific term", "used for", "disambiguation tool:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "437": {"text": "For LR -LRB- 0 -RRB- grammars, our algorithm is closely related to the recursive ascent parsers recently discovered by Kruse-man Aretz -LSB- 1 -RSB- and Roberts -LSB- 2 -RSB-.", "true": [["algorithm:generic", "used for", "LR -LRB- 0 -RRB- grammars:method"], ["algorithm:generic", "conjunction", "recursive ascent parsers:other scientific term"]], "pred": [["algorithm:method", "compare", "recursive ascent parsers:method"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "438": {"text": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB's binding theory, while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model.", "true": [["Criteria:generic", "used for", "anaphora resolution within sentence boundaries:task"], ["GB's binding theory:method", "used for", "Criteria:generic"], ["those:generic", "used for", "text-level anaphora:other scientific term"], ["Grosz-Sidner-style focus model:method", "part of", "those:generic"]], "pred": [["sentence boundaries:other scientific term", "used for", "anaphora resolution:task"], ["GB's binding theory:other scientific term", "used for", "anaphora resolution:task"], ["text-level anaphora:other scientific term", "used for", "anaphora resolution:task"], ["Grosz-Sidner-style focus model:other scientific term", "used for", "anaphora resolution:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"used for\"  \n(15) \"used for\"  \n(16) \"used for\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "442": {"text": "b -RRB- The UV procedure is based on three different confidence tests, two based on acoustic measures and one founded on linguistic information, applied in a hierarchical structure.", "true": [["confidence tests:method", "used for", "UV procedure:method"], ["confidence tests:method", "used for", "hierarchical structure:other scientific term"], ["two:generic", "hyponym of", "confidence tests:method"], ["acoustic measures:metric", "used for", "two:generic"], ["one:generic", "hyponym of", "confidence tests:method"], ["linguistic information:other scientific term", "used for", "one:generic"]], "pred": [["three different confidence tests:other scientific term", "part of", "UV procedure:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "443": {"text": "It works by calculating eigenvectors of an adjacency graph's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors.", "true": [["It:generic", "used for", "submanifold:other scientific term"], ["eigenvectors:other scientific term", "used for", "It:generic"], ["adjacency graph's Laplacian:other scientific term", "feature of", "eigenvectors:other scientific term"], ["high dimensionality space:other scientific term", "used for", "submanifold:other scientific term"], ["cluster number estimation:task", "used for", "It:generic"], ["cluster number estimation:task", "used for", "eigenvectors:other scientific term"]], "pred": [["eigenvectors:other scientific term", "used for", "cluster number estimation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "444": {"text": "We test our algorithm on the detection task and the viewpoint classification task by using\" car\" category from both the Savarese et al. 2007 and PASCAL VOC 2006 datasets.", "true": [["algorithm:generic", "used for", "detection task:task"], ["algorithm:generic", "used for", "viewpoint classification task:task"], ["detection task:task", "conjunction", "viewpoint classification task:task"], ["algorithm:generic", "evaluated for", "PASCAL VOC 2006 datasets:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "445": {"text": "In particular, our guarantee suggests that a substantial amount of low rank matrices, which cannot be recovered by standard robust PCA, become re-coverable by our proposed method.", "true": [["method:generic", "used for", "low rank matrices:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "446": {"text": "In the study of expressive speech communication, it is commonly accepted that the emotion perceived by the listener is a good approximation of the intended emotion conveyed by the speaker.", "true": [], "pred": [["emotion:other scientific term", "hyponym of", "expressive speech communication:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"hyponym of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "447": {"text": "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel.", "true": [["syntactic structure features:other scientific term", "feature of", "parse tree:other scientific term"], ["syntactic structure features:other scientific term", "used for", "relation extraction:task"], ["convolution tree kernel:method", "used for", "features:generic"]], "pred": [["syntactic structure features:other scientific term", "feature of", "parse tree:other scientific term"], ["syntactic structure features:other scientific term", "used for", "relation extraction:task"], ["syntactic structure features:other scientific term", "used for", "convolution tree kernel:method"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "448": {"text": "In previous work, we have developed hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers that integrate textual and prosodic knowledge sources for detecting sentence boundaries.", "true": [["hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers:method", "used for", "detecting sentence boundaries:task"], ["textual and prosodic knowledge sources:material", "used for", "hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers:method"]], "pred": [["hidden Markov model -LRB- HMM -RRB-:method", "part of", "classifiers:method"], ["textual and prosodic knowledge sources:other scientific term", "used for", "detecting sentence boundaries:task"], ["textual and prosodic knowledge sources:other scientific term", "feature of", "hidden Markov model -LRB- HMM -RRB-:method"]], "response": "(1) \"none\"  \n(2) \"part of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "450": {"text": "Although hidden Markov models -LRB- HMMs -RRB- provide a suitable generative model for field structured text, general unsupervised HMM learning fails to learn useful structure in either of our domains.", "true": [["hidden Markov models -LRB- HMMs -RRB-:method", "used for", "generative model:method"], ["generative model:method", "used for", "field structured text:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "451": {"text": "We also show that a good-quality MT system can be built from scratch by starting with a very small parallel corpus -LRB- 100,000 words -RRB- and exploiting a large non-parallel corpus.", "true": [["parallel corpus:material", "used for", "MT system:method"], ["parallel corpus:material", "conjunction", "non-parallel corpus:material"], ["non-parallel corpus:material", "used for", "MT system:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "452": {"text": "For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions, i.e. functions that memorize the results of previous invocations.", "true": [["parser:method", "evaluated for", "time-complexity:metric"], ["parser:method", "used for", "non-LR grammars:method"], ["memo-functions:method", "used for", "parser:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "453": {"text": "The resultant bilingual corpus, 10.4 M English words and 18.3 M Chinese characters, is an authoritative and comprehensive text collection covering the specific and special domain of HK laws.", "true": [], "pred": [["bilingual corpus:material", "part of", "authoritative and comprehensive text collection:other scientific term"], ["bilingual corpus:material", "part of", "specific and special domain of HK laws:other scientific term"], ["10.4 M English words:material", "part of", "authoritative and comprehensive text collection:other scientific term"], ["10.4 M English words:material", "part of", "specific and special domain of HK laws:other scientific term"], ["18.3 M Chinese characters:material", "part of", "authoritative and comprehensive text collection:other scientific term"], ["18.3 M Chinese characters:material", "part of", "specific and special domain of HK laws:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"part of\"  \n(6) \"part of\"  \n(7) \"part of\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "454": {"text": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours.", "true": [["remarkable feature:other scientific term", "feature of", "model:generic"], ["algorithm:generic", "used for", "Fujisaki-model parameters:other scientific term"], ["statistical methods:method", "used for", "algorithm:generic"], ["raw F0 contours:other scientific term", "used for", "Fujisaki-model parameters:other scientific term"]], "pred": [["model:method", "part of", "efficient algorithm:method"], ["Fujisaki-model parameters:other scientific term", "part of", "model:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"part of\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "455": {"text": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation, the proposed method requires fewer evaluations of the classifier functions, thereby speeding up the search.", "true": [["exhaustive procedure:method", "used for", "cascade evaluation:task"], ["exhaustive procedure:method", "compare", "method:generic"], ["method:generic", "used for", "search:task"]], "pred": [["exhaustive procedure:method", "compare", "proposed method:method"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "456": {"text": "In addition, we conduct synthetic experiments as well as a real application on noisy image classification to show that our method also improves the performance in practice by exploiting side information.", "true": [["method:generic", "evaluated for", "noisy image classification:task"], ["side information:other scientific term", "used for", "method:generic"]], "pred": [["side information:other scientific term", "used for", "noisy image classification:task"], ["side information:other scientific term", "used for", "our method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "457": {"text": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB-, based on studies on the vertebrate retina, has permitted the realization of complex programmable spatio-temporal dynamics in VLSI.", "true": [["bio-inspired model:method", "used for", "analog programmable array processor -LRB- APAP -RRB-:task"], ["bio-inspired model:method", "used for", "complex programmable spatio-temporal dynamics:other scientific term"], ["vertebrate retina:other scientific term", "used for", "bio-inspired model:method"], ["complex programmable spatio-temporal dynamics:other scientific term", "feature of", "VLSI:task"]], "pred": [["bio-inspired model:method", "used for", "analog programmable array processor -LRB- APAP -RRB-:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "458": {"text": "In this paper we propose a logical formalism, which, among other things, is suitable for representing determiners without forcing a particular interpretation when their meaning is still not clear.", "true": [["logical formalism:method", "used for", "determiners:task"]], "pred": [["logical formalism:method", "part of", "this paper:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "459": {"text": "We investigate the verbal and nonverbal means for grounding, and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction.", "true": [["verbal and nonverbal means:method", "used for", "grounding:task"], ["design:generic", "used for", "embodied conversational agents:method"], ["common ground:task", "used for", "human-computer interaction:task"]], "pred": [["verbal and nonverbal means:other scientific term", "used for", "grounding:task"], ["verbal and nonverbal means:other scientific term", "used for", "design for embodied conversational agents:method"], ["signals:other scientific term", "used for", "design for embodied conversational agents:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"used for\"  \n(22) \"used for\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "460": {"text": "The new criterion--meaning-entailing substitutability--fits the needs of semantic-oriented NLP applications and can be evaluated directly -LRB- independent of an application -RRB- at a good level of human agreement.", "true": [["meaning-entailing substitutability:metric", "used for", "semantic-oriented NLP applications:task"], ["meaning-entailing substitutability:metric", "evaluated for", "human agreement:metric"]], "pred": [["criterion:other scientific term", "used for", "semantic-oriented NLP applications:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "461": {"text": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results, proposing an objective measure for evaluating feature vector quality.", "true": [["distributional word feature vectors:other scientific term", "evaluated for", "semantic criterion:metric"], ["distributional word feature vectors:other scientific term", "used for", "word similarity:task"], ["feature vector quality:metric", "evaluated for", "measure:generic"]], "pred": [["empirical quality:metric", "feature of", "distributional word feature vectors:material"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "462": {"text": "Our main result is a first-order upper bound on the distance between any approximate joint triangularizer of the matrices in M' and any exact joint triangularizer of the matrices in M.", "true": [["approximate joint triangularizer:method", "conjunction", "exact joint triangularizer:method"]], "pred": [["approximate joint triangularizer:method", "compare", "exact joint triangularizer:method"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "465": {"text": "Owing to these variations, the pedestrian data is distributed as highly-curved manifolds in the feature space, despite the current convolutional neural networks -LRB- CNN -RRB-'s capability of feature extraction.", "true": [["highly-curved manifolds:method", "used for", "pedestrian data:material"], ["feature space:other scientific term", "feature of", "highly-curved manifolds:method"], ["convolutional neural networks -LRB- CNN -RRB-:method", "used for", "feature extraction:other scientific term"]], "pred": [["pedestrian data:material", "part of", "feature space:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "467": {"text": "Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB-.", "true": [["Recognition of proper nouns:task", "part of", "morphological analysis:task"], ["proper nouns:other scientific term", "part of", "Japanese text:material"], ["morphological analysis:task", "used for", "Japanese text processing:task"]], "pred": [["proper nouns:other scientific term", "part of", "morphological analysis:task"], ["proper nouns:other scientific term", "part of", "Japanese text processing:task"], ["morphological analysis:task", "part of", "proper nouns:other scientific term"], ["Japanese text processing:task", "part of", "morphological analysis:task"], ["proper nouns:other scientific term", "part of", "Japanese text:material"]], "response": "(1) \"part of\"  \n(2) \"part of\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"part of\"  \n"}, "468": {"text": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes, in terms of repeatability and distinctiveness.", "true": [["histogram-based interest point detectors:method", "used for", "matching textured scenes:task"], ["histogram-based interest point detectors:method", "evaluated for", "repeatability:metric"], ["repeatability:metric", "conjunction", "distinctiveness:metric"], ["histogram-based interest point detectors:method", "evaluated for", "distinctiveness:metric"]], "pred": [["blur:other scientific term", "used for", "matching textured scenes:task"], ["illumination changes:other scientific term", "used for", "matching textured scenes:task"], ["blur:other scientific term", "feature of", "histogram-based interest point detectors:method"], ["illumination changes:other scientific term", "feature of", "histogram-based interest point detectors:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"feature of\"  \n(15) \"feature of\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "469": {"text": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination, pose and head motion variation.", "true": [["method:generic", "used for", "fully automatic recognition system:method"], ["fully automatic recognition system:method", "evaluated for", "video sequences:material"], ["illumination:other scientific term", "feature of", "video sequences:material"], ["illumination:other scientific term", "conjunction", "pose:other scientific term"], ["pose:other scientific term", "feature of", "video sequences:material"], ["pose:other scientific term", "conjunction", "head motion variation:other scientific term"], ["head motion variation:other scientific term", "feature of", "video sequences:material"]], "pred": [["extreme illumination:other scientific term", "feature of", "fully automatic recognition system:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"feature of\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "471": {"text": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them.", "true": [["method:generic", "evaluated for", "person re-identification datasets:material"], ["scale Market-1501:material", "hyponym of", "person re-identification datasets:material"], ["CUHK03 datasets:material", "hyponym of", "person re-identification datasets:material"], ["CUHK03 datasets:material", "conjunction", "scale Market-1501:material"]], "pred": [["new method:method", "evaluated for", "current state-of-the-art methods:method"]], "response": "(1) \"evaluated for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "472": {"text": "A statistical translation model is also presented that deals such phrases, as well as a training method based on the maximization of translation accuracy, as measured with the NIST evaluation metric.", "true": [["statistical translation model:method", "used for", "phrases:generic"], ["maximization of translation accuracy:metric", "used for", "training method:method"], ["statistical translation model:method", "evaluated for", "NIST evaluation metric:metric"]], "pred": [["NIST evaluation metric:metric", "feature of", "maximization of translation accuracy:task"], ["maximization of translation accuracy:task", "part of", "statistical translation model:method"], ["NIST evaluation metric:metric", "feature of", "statistical translation model:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"feature of\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "473": {"text": "On the other hand, the manifold learning methods suggest to use the Euclidean distance in the local range, combining with the graphical relationship between samples, for approximating the geodesic distance.", "true": [["Euclidean distance:other scientific term", "used for", "manifold learning methods:method"], ["Euclidean distance:other scientific term", "conjunction", "graphical relationship:other scientific term"], ["Euclidean distance:other scientific term", "used for", "geodesic distance:other scientific term"], ["local range:other scientific term", "feature of", "Euclidean distance:other scientific term"], ["graphical relationship:other scientific term", "used for", "geodesic distance:other scientific term"]], "pred": [["Euclidean distance:other scientific term", "used for", "local range:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "474": {"text": "Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification, and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification.", "true": [["robust deep metrics:other scientific term", "used for", "person re-identification:task"], ["deep model:method", "compare", "state-of-the-art methods:generic"], ["deep model:method", "used for", "person re-identification:task"], ["state-of-the-art methods:generic", "used for", "person re-identification:task"]], "pred": [["several benchmarks:material", "feature of", "person re-identification:task"], ["deep metrics:metric", "used for", "person re-identification:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"feature of\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"used for\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "475": {"text": "Our morphological analyzer has done all the necessary work for the recognition and classification of proper names, numerical and temporal expressions, i.e. Named Entity -LRB- NE -RRB- items in the Japanese text.", "true": [["morphological analyzer:method", "used for", "recognition and classification of proper names, numerical and temporal expressions:task"], ["Named Entity -LRB- NE -RRB- items:other scientific term", "hyponym of", "proper names, numerical and temporal expressions:other scientific term"], ["Named Entity -LRB- NE -RRB- items:other scientific term", "part of", "Japanese text:material"]], "pred": [["proper names:other scientific term", "hyponym of", "Named Entity -LRB- NE -RRB-:other scientific term"], ["proper names:other scientific term", "used for", "recognition and classification:task"], ["numerical and temporal expressions:other scientific term", "used for", "recognition and classification:task"], ["proper names:other scientific term", "used for", "morphological analyzer:method"], ["numerical and temporal expressions:other scientific term", "used for", "morphological analyzer:method"], ["Named Entity -LRB- NE -RRB-:other scientific term", "used for", "morphological analyzer:method"]], "response": "(1) \"none\"  \n(2) \"hyponym of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"used for\"  \n(18) \"used for\"  \n(19) \"used for\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "476": {"text": "Unlike existing interest point detectors, which measure pixel-wise differences in image intensity, our detectors incorporate histogram-based representations, and thus can find image regions that present a distinct distribution in the neighborhood.", "true": [["interest point detectors:method", "evaluated for", "pixel-wise differences in image intensity:metric"], ["histogram-based representations:method", "part of", "detectors:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "477": {"text": "In this paper we specialize the projective unifocal, bifo-cal, and trifocal tensors to the affine case, and show how the tensors obtained relate to the registered tensors encountered in previous work.", "true": [["projective unifocal, bifo-cal, and trifocal tensors:method", "used for", "affine case:other scientific term"]], "pred": [["and trifocal tensors:other scientific term", "hyponym of", "tensors:other scientific term"]], "response": "(1) \"none\"  \n(2) \"hyponym of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "478": {"text": "While previous approaches relied on geometric, appearance, or correlation-based information for establishing correspondences between static cameras, they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras.", "true": [["geometric, appearance, or correlation-based information:other scientific term", "used for", "approaches:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}, "479": {"text": "Towards this goal, we also propose a novel Multiple Instance Learning -LRB- MIL -RRB- formulation for the problem based on the logistic softmax function of covariance-based region features within a MAP estimation framework.", "true": [["logistic softmax function of covariance-based region features:other scientific term", "used for", "Multiple Instance Learning -LRB- MIL -RRB- formulation:method"], ["MAP estimation framework:method", "used for", "Multiple Instance Learning -LRB- MIL -RRB- formulation:method"]], "pred": [["this:generic", "used for", "Multiple Instance Learning -LRB- MIL -RRB-:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "480": {"text": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7% on all three databases -RRB-, significantly out-performing state-of-the-art commercial software and methods from the literature.", "true": [["system:generic", "evaluated for", "data set:generic"], ["system:generic", "compare", "commercial software:method"], ["system:generic", "compare", "methods:generic"], ["system:generic", "evaluated for", "recognition rate:metric"], ["commercial software:method", "conjunction", "methods:generic"]], "pred": [["recognition rate:metric", "feature of", "state-of-the-art commercial software:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"feature of\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "481": {"text": "The system is trained on 181,000 expert games and shows excellent prediction performance as indicated by its ability to perfectly predict the moves made by professional Go players in 34% of test positions.", "true": [["expert games:material", "used for", "system:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "482": {"text": "In this situation, the general method is to segment the raw corpus automatically using a word list, correct the output sentences by hand, and build a model from the segmented corpus.", "true": [["method:generic", "used for", "raw corpus:material"], ["word list:other scientific term", "used for", "method:generic"], ["segmented corpus:material", "used for", "model:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "483": {"text": "In this model, on-line handwriting is considered as a modulation of a simple cycloidal pen motion, described by two coupled oscillations with a constant linear drift along the line of the writing.", "true": [["model:generic", "used for", "on-line handwriting:task"], ["on-line handwriting:task", "part of", "cycloidal pen motion:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "484": {"text": "Using these ideas together, the resulting tagger gives a 97.24% accuracy on the Penn Treebank WSJ, an error reduction of 4.4% on the best previous single automatically learned tagging result.", "true": [["tagger:method", "evaluated for", "accuracy:metric"], ["tagger:method", "evaluated for", "Penn Treebank WSJ:material"], ["tagger:method", "evaluated for", "error:metric"]], "pred": [["tagger:method", "used for", "Penn Treebank WSJ:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"used for\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "485": {"text": "In this paper, we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2, higher than previously reported results on the NEGRA corpus.", "true": [["unlexicalized parser:method", "used for", "German:material"], ["smoothing:method", "used for", "unlexicalized parser:method"], ["smoothing:method", "conjunction", "suffix analysis:method"], ["suffix analysis:method", "used for", "unlexicalized parser:method"], ["unlexicalized parser:method", "evaluated for", "labelled bracket F-score:metric"], ["unlexicalized parser:method", "evaluated for", "NEGRA corpus:material"]], "pred": [["unlexicalized parser:method", "used for", "smoothing:method"], ["unlexicalized parser:method", "used for", "suffix analysis:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "486": {"text": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese, and also exploits the large amount of Chinese text available in corpora and on the Web.", "true": [["Chinese text:material", "part of", "corpora:generic"], ["Chinese text:material", "part of", "Web:material"], ["corpora:generic", "conjunction", "Web:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "487": {"text": "We demonstrate that for certain field structured extraction tasks, such as classified advertisements and bibliographic citations, small amounts of prior knowledge can be used to learn effective models in a primarily unsupervised fashion.", "true": [["classified advertisements:material", "hyponym of", "field structured extraction tasks:task"], ["classified advertisements:material", "conjunction", "bibliographic citations:material"], ["bibliographic citations:material", "hyponym of", "field structured extraction tasks:task"], ["prior knowledge:other scientific term", "used for", "field structured extraction tasks:task"]], "pred": [["classified advertisements:material", "part of", "field structured extraction tasks:task"], ["bibliographic citations:material", "part of", "field structured extraction tasks:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "488": {"text": "Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm.", "true": [["technique:generic", "used for", "search algorithm:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "491": {"text": "From this point of view, selecting suitable positive -LRB- i.e. intra-class -RRB- training samples within a local range is critical for training the CNN embedding, especially when the data has large intra-class variations.", "true": [["intra-class variations:other scientific term", "feature of", "data:generic"]], "pred": [["local range:other scientific term", "used for", "training the CNN embedding:task"], ["suitable positive -LRB- i.e. intra-class -RRB- training samples:material", "used for", "training the CNN embedding:task"], ["data:material", "used for", "training the CNN embedding:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "492": {"text": "We propose to incorporate a priori geometric constraints in a 3--D stereo reconstruction scheme to cope with the many cases where image information alone is not sufficient to accurately recover 3--D shape.", "true": [["priori geometric constraints:other scientific term", "part of", "3--D stereo reconstruction scheme:method"], ["image information:other scientific term", "used for", "3--D shape:other scientific term"]], "pred": [["a priori geometric constraints:other scientific term", "used for", "3--D shape:other scientific term"], ["a priori geometric constraints:other scientific term", "used for", "3--D stereo reconstruction scheme:method"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "494": {"text": "We propose a corpus-based method -LRB- Biber,1993; Nagao,1993; Smadja,1993 -RRB- which generates Noun Classifier Associations -LRB- NCA -RRB- to overcome the problems in classifier assignment and semantic construction of noun phrase.", "true": [["corpus-based method:method", "used for", "Noun Classifier Associations -LRB- NCA -RRB-:method"], ["corpus-based method:method", "used for", "classifier assignment:task"], ["corpus-based method:method", "used for", "semantic construction of noun phrase:task"], ["Noun Classifier Associations -LRB- NCA -RRB-:method", "used for", "classifier assignment:task"], ["Noun Classifier Associations -LRB- NCA -RRB-:method", "used for", "semantic construction of noun phrase:task"], ["classifier assignment:task", "conjunction", "semantic construction of noun phrase:task"]], "pred": [["Noun Classifier Associations -LRB- NCA -RRB-:other scientific term", "used for", "problems in classifier assignment:task"], ["Noun Classifier Associations -LRB- NCA -RRB-:other scientific term", "used for", "semantic construction of noun phrase:task"], ["Noun Classifier Associations -LRB- NCA -RRB-:other scientific term", "part of", "corpus-based method:method"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "495": {"text": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings, word-to-word alignments from an MT system, and syntactic structure from parse-trees of source and target language sentences.", "true": [["linguistic information:other scientific term", "used for", "loss functions:other scientific term"], ["word-to-word alignments:other scientific term", "used for", "loss functions:other scientific term"], ["word-to-word alignments:other scientific term", "part of", "MT system:method"], ["syntactic structure:other scientific term", "used for", "loss functions:other scientific term"], ["parse-trees:other scientific term", "part of", "syntactic structure:other scientific term"]], "pred": [["syntactic structure:other scientific term", "part of", "parse-trees:other scientific term"], ["word strings:material", "part of", "linguistic information:other scientific term"], ["word-to-word alignments:material", "part of", "linguistic information:other scientific term"], ["source and target language sentences:material", "part of", "linguistic information:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"part of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"part of\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"part of\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "496": {"text": "The purpose of this research is to test the efficacy of applying automated evaluation techniques, originally devised for the evaluation of human language learners, to the output of machine translation -LRB- MT -RRB- systems.", "true": [["automated evaluation techniques:method", "used for", "evaluation of human language learners:task"]], "pred": [["research:generic", "used for", "automated evaluation techniques:method"], ["output of machine translation -LRB- MT -RRB- systems:other scientific term", "used for", "evaluation of human language learners:task"], ["automated evaluation techniques:method", "part of", "research:generic"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "497": {"text": "The results show that the features in terms of which we formulate our heuristic principles have significant predictive power, and that rules that closely resemble our Horn clauses can be learnt automatically from these features.", "true": [["features:other scientific term", "feature of", "heuristic principles:method"]], "pred": [["features:other scientific term", "feature of", "heuristic principles:other scientific term"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "498": {"text": "Inspired by recent work which reconstructs general trajectories using compact high-pass filters, we develop a dynamic programming approach which scales linearly in the number of frames, leveraging the intrinsically local nature of filter interactions.", "true": [], "pred": [["compact high-pass filters:method", "used for", "recent work:generic"], ["dynamic programming approach:method", "used for", "recent work:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "499": {"text": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently.", "true": [["matrix rank degeneration:other scientific term", "conjunction", "non-isolated minima:other scientific term"], ["matrix rank degeneration:other scientific term", "feature of", "low-rank matrix optimization:task"], ["non-isolated minima:other scientific term", "feature of", "low-rank matrix optimization:task"], ["regularizer:method", "used for", "low-rank matrix optimization:task"], ["regularizer:method", "used for", "or-thonormality:other scientific term"], ["or-thonormality:other scientific term", "feature of", "learned matrix:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "500": {"text": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech, out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present.", "true": [["Utterance Verification -LRB- UV -RRB-:method", "hyponym of", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"]], "pred": [["System:generic", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB-:method"], ["spontaneous speech:other scientific term", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB-:method"], ["Utterance Verification -LRB- UV -RRB-:task", "part of", "Automatic Speech Recognition -LRB- ASR -RRB-:method"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"feature of\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"part of\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "501": {"text": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications, where the goal is to decompose the data matrix to a low rank part plus a sparse residual.", "true": [["robust principal component analysis -LRB- robust PCA -RRB- problem:method", "used for", "machine learning applications:task"], ["low rank part:other scientific term", "part of", "data matrix:other scientific term"], ["low rank part:other scientific term", "conjunction", "sparse residual:other scientific term"], ["sparse residual:other scientific term", "part of", "data matrix:other scientific term"]], "pred": [["robust principal component analysis -LRB- robust PCA -RRB-:other scientific term", "used for", "machine learning applications:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "502": {"text": "We identify three important requirements which arose from the task that we gave our subjects: operators specific to the task of database access, complex contextual reference and reference to the structure of the information source.", "true": [], "pred": [["three important requirements:other scientific term", "used for", "database access:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"used for\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "503": {"text": "We consider the problem of approximate joint matrix triangularization when the matrices in M are jointly diagonalizable and real, but we only observe a set M' of noise perturbed versions of the matrices in M.", "true": [], "pred": [["matrices in M:other scientific term", "part of", "approximate joint matrix triangularization:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"part of\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "504": {"text": "During normal tracking conditions when the object is visible from frame to frame, local optimization is used to track the local mode of the similarity measure in a parameter space of translation, rotation and scale.", "true": [["local optimization:method", "used for", "local mode of the similarity measure:other scientific term"], ["parameter space of translation, rotation and scale:other scientific term", "used for", "local mode of the similarity measure:other scientific term"]], "pred": [["normal tracking conditions:other scientific term", "used for", "local optimization:method"], ["object:other scientific term", "used for", "local optimization:method"], ["similarity measure:other scientific term", "used for", "local optimization:method"], ["parameter space:other scientific term", "used for", "local optimization:method"], ["translation:other scientific term", "used for", "local optimization:method"], ["rotation:other scientific term", "used for", "local optimization:method"], ["scale:other scientific term", "used for", "local optimization:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"used for\"  \n(44) \"used for\"  \n(45) \"used for\"  \n(46) \"used for\"  \n(47) \"used for\"  \n(48) \"used for\"  \n(49) \"used for\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "505": {"text": "Techniques for automatically training modules of a natural language generator have recently been proposed, but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches.", "true": [["Techniques:generic", "used for", "automatically training modules:method"], ["automatically training modules:method", "part of", "natural language generator:method"], ["trainable components:method", "evaluated for", "utterances:other scientific term"], ["hand-crafted template-based or rule-based approaches:method", "evaluated for", "utterances:other scientific term"], ["trainable components:method", "compare", "hand-crafted template-based or rule-based approaches:method"]], "pred": [["techniques:method", "compare", "hand-crafted template-based or rule-based approaches:method"]], "response": "(1) \"none\"  \n(2) \"compare\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "506": {"text": "In this paper we present a new UV procedure with two major features: a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises.", "true": [["Confidence tests:method", "used for", "decoded string hypotheses:other scientific term"], ["noises:other scientific term", "conjunction", "OOV words:other scientific term"]], "pred": [["UV procedure:method", "part of", "this paper:generic"], ["Confidence tests:method", "part of", "this paper:generic"], ["word and garbage models:method", "part of", "this paper:generic"], ["decoded string hypotheses:other scientific term", "part of", "UV procedure:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"part of\"  \n(17) \"part of\"  \n(18) \"part of\"  \n(19) \"part of\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "507": {"text": "This reflects contemporary methods for unsupervised object discovery from groups of images, and it allows us to define intuitive evaluation met-rics for our sets of segmentations based on the accurate and parsimonious delineation of scene objects.", "true": [["contemporary methods:generic", "used for", "unsupervised object discovery:task"]], "pred": [["evaluation metrics:metric", "used for", "sets of segmentations:material"], ["accurate and parsimonious delineation of scene objects:other scientific term", "used for", "unsupervised object discovery:task"], ["evaluation metrics:metric", "feature of", "accurate and parsimonious delineation of scene objects:other scientific term"], ["evaluation metrics:metric", "used for", "unsupervised object discovery:task"]], "response": "(1) \"none\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"feature of\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "508": {"text": "Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples, and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples.", "true": [["detector:method", "evaluated for", "real data sets:material"], ["detector:method", "compare", "linear and kernel SVM:method"]], "pred": [["detector:other scientific term", "used for", "experiments on real data sets:task"], ["10 positive and 10 negative examples:material", "part of", "experiments on real data sets:task"], ["detector:other scientific term", "feature of", "linear and kernel SVM:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"part of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"feature of\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "509": {"text": "These methods diier from previous work in the area in two ways: the use of an action model formalism which is better suited to the needs of a re-active agent, and successful implementation of noise-handling mechanisms.", "true": [["action model formalism:method", "used for", "methods:metric"], ["action model formalism:method", "used for", "re-active agent:method"], ["noise-handling mechanisms:method", "used for", "methods:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "510": {"text": "In this paper we present our recent work on harvesting English-Chinese bitexts of the laws of Hong Kong from the Web and aligning them to the subparagraph level via utilizing the numbering system in the legal text hierarchy.", "true": [], "pred": [["subparagraph level:other scientific term", "part of", "legal text hierarchy:other scientific term"], ["numbering system:other scientific term", "part of", "legal text hierarchy:other scientific term"], ["laws of Hong Kong:material", "part of", "legal text hierarchy:other scientific term"]], "response": "(1) \"none\"  \n(2) \"part of\"  \n(3) \"none\"  \n(4) \"part of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"part of\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "511": {"text": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax, for instance, to the task of semantic interpretation or automatic translation of natural language.", "true": [["TAGs:method", "used for", "semantic interpretation:task"], ["TAGs:method", "used for", "automatic translation of natural language:task"], ["semantic interpretation:task", "conjunction", "automatic translation of natural language:task"]], "pred": [["tree-adjoining grammars -LRB- TAG -RRB-:other scientific term", "used for", "semantic interpretation:task"], ["tree-adjoining grammars -LRB- TAG -RRB-:other scientific term", "used for", "automatic translation of natural language:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"used for\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "512": {"text": "Towards deep analysis of compositional classes of paraphrases, we have examined a class-oriented framework for collecting paraphrase examples, in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement.", "true": [["class-oriented framework:method", "used for", "compositional classes of paraphrases:task"], ["class-oriented framework:method", "used for", "paraphrase examples:material"], ["automatic candidate generation:method", "used for", "sentential paraphrases:material"], ["automatic candidate generation:method", "conjunction", "manual judgement:method"], ["manual judgement:method", "used for", "sentential paraphrases:material"]], "pred": [["automatic candidate generation:method", "part of", "class-oriented framework:method"], ["compositional classes of paraphrases:other scientific term", "hyponym of", "paraphrase class:other scientific term"], ["paraphrase examples:material", "part of", "compositional classes of paraphrases:other scientific term"], ["sentential paraphrases:material", "part of", "compositional classes of paraphrases:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"hyponym of\"  \n(8) \"none\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"part of\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "513": {"text": "However, when the object becomes partially or totally occluded, such local tracking is prone to failure, especially when common prediction techniques like the Kalman filter do not provide a good estimate of object parameters in future frames.", "true": [["Kalman filter:method", "part of", "prediction techniques:method"]], "pred": [["object:other scientific term", "part of", "local tracking:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "514": {"text": "Given the video streams acquired by two cameras placed on either side of a computer monitor, the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact.", "true": [["cameras:other scientific term", "used for", "video streams:material"], ["algorithm:generic", "used for", "eye contact:other scientific term"], ["virtual camera:other scientific term", "used for", "images:material"], ["arbitrary position:other scientific term", "feature of", "virtual camera:other scientific term"]], "pred": [["arbitrary position:other scientific term", "feature of", "proposed algorithm:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"feature of\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "515": {"text": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations.", "true": [["layers:other scientific term", "part of", "CNN models:method"], ["layers of distributed representations:method", "part of", "CNNs:method"], ["layers of distributed representations:method", "used for", "object pose information:other scientific term"], ["this:generic", "compare", "object category representations:method"]], "pred": [["layers:other scientific term", "part of", "distributed representations:other scientific term"], ["layers:other scientific term", "part of", "object pose information:other scientific term"], ["layers:other scientific term", "part of", "object category representations:other scientific term"], ["layers:other scientific term", "part of", "CNN models:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"part of\"  \n(4) \"part of\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"part of\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "516": {"text": "Experimental results from a real telephone application on a natural number recognition task show an 50% reduction in recognition errors with a moderate 12% rejection rate of correct utterances and a low 1.5% rate of false acceptance.", "true": [["natural number recognition task:task", "feature of", "telephone application:task"], ["natural number recognition task:task", "evaluated for", "recognition errors:metric"]], "pred": [["real telephone application:material", "used for", "natural number recognition task:task"], ["natural number recognition task:task", "part of", "experimental results:generic"], ["real telephone application:material", "part of", "experimental results:generic"], ["50% reduction in recognition errors:metric", "part of", "experimental results:generic"], ["12% rejection rate of correct utterances:metric", "part of", "experimental results:generic"], ["1.5% rate of false acceptance:metric", "part of", "experimental results:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"used for\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"part of\"  \n(15) \"part of\"  \n(16) \"part of\"  \n(17) \"part of\"  \n(18) \"part of\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "517": {"text": "FERRET utilizes a novel approach to Q/A known as predictive questioning which attempts to identify the questions -LRB- and answers -RRB- that users need by analyzing how a user interacts with a system while gathering information related to a particular scenario.", "true": [["approach:generic", "used for", "FERRET:method"], ["approach:generic", "used for", "Q/A:method"]], "pred": [["questions:other scientific term", "part of", "Q/A:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"part of\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n"}, "518": {"text": "Discourse processing requires recognizing how the utterances of the discourse aggregate into segments, recognizing the intentions expressed in the discourse and the relationships among intentions, and tracking the discourse through the operation of the mechanisms associated with attentional state.", "true": [], "pred": [["utterances:other scientific term", "used for", "discourse processing:task"], ["segments:other scientific term", "used for", "discourse processing:task"], ["intentions:other scientific term", "used for", "discourse processing:task"], ["relationships:other scientific term", "used for", "discourse processing:task"], ["attentional state:other scientific term", "used for", "discourse processing:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"used for\"  \n(22) \"used for\"  \n(23) \"used for\"  \n(24) \"used for\"  \n(25) \"used for\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "520": {"text": "This allows us to use our method to act not only as a faster procedure for cascade evaluation, but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions, in particular kernel-ized support vector machines.", "true": [["method:generic", "used for", "cascade evaluation:task"], ["method:generic", "used for", "branch-and-bound object detection:task"], ["nonlinear quality functions:other scientific term", "used for", "branch-and-bound object detection:task"], ["kernel-ized support vector machines:method", "hyponym of", "nonlinear quality functions:other scientific term"]], "pred": [["method:generic", "used for", "kernel-ized support vector machines:method"], ["tool:generic", "used for", "kernel-ized support vector machines:method"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "523": {"text": "In both domains, we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples, and that semi-supervised methods can make good use of small amounts of labeled data.", "true": [["unsupervised methods:method", "compare", "supervised methods:method"], ["unsupervised methods:method", "evaluated for", "accuracies:metric"], ["supervised methods:method", "evaluated for", "accuracies:metric"], ["unlabeled examples:material", "used for", "unsupervised methods:method"], ["labeled examples:material", "used for", "supervised methods:method"], ["labeled data:material", "used for", "semi-supervised methods:method"]], "pred": [["unsupervised methods:method", "compare", "supervised methods:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"compare\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "524": {"text": "Specifically, by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork, the proposed model automatically captures the complex long-range temporal dynamics, which naturally avoids the typical sliding window design and thus ensures high computational efficiency.", "true": [["deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork:method", "used for", "model:generic"], ["long-range temporal dynamics:other scientific term", "feature of", "model:generic"]], "pred": [["deep Long Short-Term Memory -LRB- LSTM -RRB-:method", "feature of", "proposed model:method"], ["complex long-range temporal dynamics:other scientific term", "feature of", "proposed model:method"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "525": {"text": "On the internal side, liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary, a morphosyntactic parser of L0, and a canonical graph2tree transformation.", "true": [["resources:generic", "used for", "liaisons:other scientific term"], ["LO-English or better a L0-UNL dictionary:material", "hyponym of", "resources:generic"], ["LO-English or better a L0-UNL dictionary:material", "conjunction", "morphosyntactic parser of L0:method"], ["morphosyntactic parser of L0:method", "hyponym of", "resources:generic"], ["morphosyntactic parser of L0:method", "conjunction", "canonical graph2tree transformation:other scientific term"], ["canonical graph2tree transformation:other scientific term", "hyponym of", "resources:generic"]], "pred": [["broadly available resources:generic", "used for", "morphosyntactic parser of L0:method"], ["broadly available resources:generic", "used for", "canonical graph2tree transformation:method"], ["liaisons:other scientific term", "part of", "elements of the text:other scientific term"], ["morphosyntactic parser of L0:method", "part of", "broadly available resources:generic"], ["canonical graph2tree transformation:method", "part of", "broadly available resources:generic"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"part of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"part of\"  \n(12) \"part of\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "526": {"text": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-, including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples.", "true": [["components:generic", "used for", "intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-:task"], ["disambiguated morphological analysis:method", "hyponym of", "components:generic"], ["disambiguated morphological analysis:method", "conjunction", "lemmatized indexing:method"], ["disambiguated morphological analysis:method", "used for", "aligned bilingual corpus:material"], ["lemmatized indexing:method", "hyponym of", "components:generic"], ["lemmatized indexing:method", "used for", "aligned bilingual corpus:material"]], "pred": [["aligned bilingual corpus of word examples:material", "used for", "disambiguated morphological analysis:task"], ["aligned bilingual corpus of word examples:material", "used for", "lemmatized indexing:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"used for\"  \n(17) \"used for\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "527": {"text": "Although the study of clustering is centered around an intuitively compelling goal, it has been very difficult to develop a unified framework for reasoning about it at a technical level, and profoundly diverse approaches to clustering abound in the research community.", "true": [["unified framework:method", "used for", "reasoning:task"]], "pred": [["reasoning:other scientific term", "used for", "clustering:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"used for\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "528": {"text": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset, and run two different machine learning algorithms: SLIPPER, a rule-based learning algorithm, and TiMBL, a memory-based system.", "true": [["SLIPPER:generic", "hyponym of", "rule-based learning algorithm:method"], ["rule-based learning algorithm:method", "part of", "machine learning algorithms:method"], ["rule-based learning algorithm:method", "compare", "memory-based system:method"], ["TiMBL:generic", "hyponym of", "memory-based system:method"], ["memory-based system:method", "part of", "machine learning algorithms:method"]], "pred": [["domain independent features:method", "used for", "machine learning algorithms:method"], ["domain independent features:method", "used for", "SLIPPER:method"], ["domain independent features:method", "used for", "rule-based learning algorithm:method"], ["domain independent features:method", "used for", "TiMBL:method"], ["domain independent features:method", "used for", "memory-based system:method"], ["predicates:other scientific term", "used for", "clauses:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"used for\"  \n(4) \"used for\"  \n(5) \"used for\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"used for\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}, "530": {"text": "The two main contributions of this paper are: i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming, that encourages correct occlusion labeling; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface.", "true": [["three-plane graph:method", "used for", "dense-stereo dynamic-programming:method"], ["dense-stereo dynamic-programming:method", "used for", "occlusion labeling:task"], ["compact geometric derivation:other scientific term", "used for", "novel-view synthesis:task"], ["direct projection of the minimum-cost surface:method", "used for", "compact geometric derivation:other scientific term"]], "pred": [["three-plane graph:method", "used for", "dense-stereo dynamic-programming:method"]], "response": "(1) \"used for\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "531": {"text": "To recover from these inevitable tracking failures, we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB-, a method that avoids becoming trapped at local modes and is much faster than exhaustive search.", "true": [["global optimization problem:task", "used for", "object detection:task"], ["Adaptive Simulated Annealing -LRB- ASA -RRB-:method", "used for", "it:generic"], ["method:generic", "compare", "exhaustive search:method"]], "pred": [["object detection:task", "part of", "global optimization problem:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"part of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "532": {"text": "Furthermore, this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB-; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space.", "true": [["algorithm:generic", "used for", "temporal maintenance of a background model:task"], ["algorithm:generic", "used for", "rendering of occlusions:task"], ["algorithm:generic", "used for", "temporal artefacts -LRB- flicker -RRB-:other scientific term"], ["cost aggregation algorithm:method", "conjunction", "algorithm:generic"], ["cost aggregation algorithm:method", "used for", "three-dimensional matching cost space:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "533": {"text": "In the Object Recognition task, there exists a di-chotomy between the categorization of objects and estimating object pose, where the former necessitates a view-invariant representation, while the latter requires a representation capable of capturing pose information over different categories of objects.", "true": [["categorization of objects:task", "part of", "Object Recognition task:task"], ["categorization of objects:task", "conjunction", "estimating object pose:task"], ["estimating object pose:task", "part of", "Object Recognition task:task"], ["view-invariant representation:method", "used for", "former:generic"], ["representation:generic", "used for", "latter:generic"], ["representation:generic", "used for", "pose information:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "534": {"text": "While current approaches are developed by only considering the low rank plus sparse structure, in many applications, side information of row and/or column entities may also be given, and it is still unclear to what extent could such information help robust PCA.", "true": [["low rank plus sparse structure:other scientific term", "used for", "approaches:generic"], ["information:generic", "used for", "robust PCA:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "536": {"text": "In general, our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech, although it is interesting to note that the best results are achieved by three-way voting among the classifiers.", "true": [["CRF model:method", "compare", "HMM and Max-ent models:method"], ["CRF model:method", "evaluated for", "error rate:metric"], ["HMM and Max-ent models:method", "evaluated for", "error rate:metric"], ["CRF model:method", "evaluated for", "NIST sentence boundary detection task:material"], ["HMM and Max-ent models:method", "evaluated for", "NIST sentence boundary detection task:material"], ["speech:material", "feature of", "NIST sentence boundary detection task:material"], ["classifiers:method", "used for", "three-way voting:method"]], "pred": [["CRF model:method", "compare", "HMM:method"], ["CRF model:method", "compare", "Max-ent models:method"]], "response": "(1) \"compare\"  \n(2) \"compare\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "537": {"text": "The objective of this work is to recognize faces using video sequences both for training and recognition input, in a realistic, unconstrained setup in which lighting, pose and user motion pattern have a wide variability and face images are of low resolution.", "true": [["lighting:other scientific term", "conjunction", "pose:other scientific term"], ["pose:other scientific term", "conjunction", "user motion pattern:other scientific term"], ["resolution:metric", "feature of", "face images:material"]], "pred": [["faces:other scientific term", "used for", "training:task"], ["faces:other scientific term", "used for", "recognition input:task"], ["objective:generic", "used for", "work:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"used for\"  \n(44) \"used for\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"used for\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n(91) \"none\"  \n(92) \"none\"  \n(93) \"none\"  \n(94) \"none\"  \n(95) \"none\"  \n(96) \"none\"  \n(97) \"none\"  \n(98) \"none\"  \n(99) \"none\"  \n(100) \"none\"  \n(101) \"none\"  \n(102) \"none\"  \n(103) \"none\"  \n(104) \"none\"  \n(105) \"none\"  \n(106) \"none\"  \n(107) \"none\"  \n(108) \"none\"  \n(109) \"none\"  \n(110) \"none\"  \n(111) \"none\"  \n(112) \"none\"  \n(113) \"none\"  \n(114) \"none\"  \n(115) \"none\"  \n(116) \"none\"  \n(117) \"none\"  \n(118) \"none\"  \n(119) \"none\"  \n(120) \"none\"  \n(121) \"none\"  \n(122) \"none\"  \n(123) \"none\"  \n(124) \"none\"  \n(125) \"none\"  \n(126) \"none\"  \n(127) \"none\"  \n(128) \"none\"  \n(129) \"none\"  \n(130) \"none\"  \n(131) \"none\"  \n(132) \"none\"  \n(133) \"none\"  \n(134) \"none\"  \n(135) \"none\"  \n(136) \"none\"  \n(137) \"none\"  \n(138) \"none\"  \n(139) \"none\"  \n(140) \"none\"  \n(141) \"none\"  \n(142) \"none\"  \n(143) \"none\"  \n(144) \"none\"  \n(145) \"none\"  \n(146) \"none\"\n"}, "538": {"text": "Establishing a \"best\" correspondence between the\" UNL-tree + L0\" and the\" MS-L0 structure\", a lattice, may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible.", "true": [["UNL-tree + L0:other scientific term", "conjunction", "MS-L0 structure:other scientific term"], ["dictionary:material", "used for", "lattice:other scientific term"]], "pred": [["UNL-tree + L0:other scientific term", "compare", "MS-L0 structure:other scientific term"]], "response": "(1) \"compare\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "540": {"text": "Among other experiments, we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data.", "true": [["approach:generic", "used for", "learned confidence measures:method"], ["learned confidence measures:method", "evaluated for", "KITTI2012 dataset:material"], ["automatically generated training data:material", "used for", "them:generic"], ["laser ground truth data:material", "compare", "automatically generated training data:material"]], "pred": [["performance:metric", "used for", "learned confidence measures:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"used for\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "541": {"text": "Here, we leverage a logistic stick-breaking representation and recent innovations in P\u00f3lya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods, enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead.", "true": [["logistic stick-breaking representation:method", "used for", "multinomial distribution:method"], ["P\u00f3lya-gamma augmentation:task", "used for", "multinomial distribution:method"], ["latent variables:other scientific term", "part of", "multinomial distribution:method"], ["jointly Gaussian likelihoods:other scientific term", "feature of", "latent variables:other scientific term"], ["Bayesian inference techniques:method", "used for", "Gaussian models:method"], ["minimal overhead:other scientific term", "feature of", "Gaussian models:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "542": {"text": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction, allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint.", "true": [["Multi-view constraints:other scientific term", "conjunction", "normalized representation:method"], ["Multi-view constraints:other scientific term", "used for", "matching:task"], ["Multi-view constraints:other scientific term", "used for", "reconstruction:task"], ["normalized representation:method", "used for", "matching:task"], ["normalized representation:method", "used for", "reconstruction:task"], ["matching:task", "conjunction", "reconstruction:task"], ["images:material", "used for", "acquisition of true three-dimensional affine and Euclidean models:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n"}, "543": {"text": "The formalism's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language, or to their translates in another natural language; in summary, we intend it to allow TAGs to be used beyond their role in syntax proper.", "true": [["logical form language:other scientific term", "used for", "semantics:other scientific term"], ["TAGs:method", "used for", "syntax proper:other scientific term"]], "pred": [["formalism:other scientific term", "used for", "natural languages:other scientific term"], ["formalism:other scientific term", "used for", "semantics:other scientific term"], ["formalism:other scientific term", "used for", "logical form language:other scientific term"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"used for\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "544": {"text": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus, so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB-.", "true": [["pool models:method", "used for", "inner hair cell synapse:other scientific term"], ["visual inspection:method", "conjunction", "automatic speech recognition -LRB- ASR -RRB-:method"], ["visual inspection:method", "used for", "offset adaptation -LRB- OA -RRB- model:method"], ["automatic speech recognition -LRB- ASR -RRB-:method", "used for", "offset adaptation -LRB- OA -RRB- model:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "546": {"text": "In this theory, discourse structure is composed of three separate but interrelated components: the structure of the sequence of utterances -LRB- called the linguistic structure -RRB-, a structure of purposes -LRB- called the intentional structure -RRB-, and the state of focus of attention -LRB- called the attentional state -RRB-.", "true": [["components:generic", "part of", "discourse structure:other scientific term"], ["linguistic structure:other scientific term", "part of", "components:generic"], ["linguistic structure:other scientific term", "conjunction", "intentional structure:other scientific term"], ["intentional structure:other scientific term", "part of", "components:generic"], ["intentional structure:other scientific term", "conjunction", "attentional state:other scientific term"], ["attentional state:other scientific term", "part of", "components:generic"]], "pred": [["three separate but interrelated components:other scientific term", "part of", "discourse structure:other scientific term"], ["sequence of utterances:other scientific term", "part of", "discourse structure:other scientific term"], ["linguistic structure:other scientific term", "part of", "discourse structure:other scientific term"], ["intentional structure:other scientific term", "part of", "discourse structure:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"part of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"part of\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"part of\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"part of\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "547": {"text": "While sentence extraction as an approach to summarization has been shown to work in documents of certain genres, because of the conversational nature of email communication where utterances are made in relation to one made previously, sentence extraction may not capture the necessary segments of dialogue that would make a summary coherent.", "true": [["sentence extraction:method", "used for", "summarization:task"]], "pred": [["documents of certain genres:other scientific term", "used for", "summarization:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"used for\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "548": {"text": "Our method has two major components: a -RRB- a pattern extraction scheme for efficiently harvesting patterns of given size and shape from expert game records and b -RRB- a Bayesian learning algorithm -LRB- in two variants -RRB- that learns a distribution over the values of a move given a board position based on the local pattern context.", "true": [["pattern extraction scheme:method", "part of", "method:generic"], ["pattern extraction scheme:method", "conjunction", "Bayesian learning algorithm:method"], ["Bayesian learning algorithm:method", "part of", "method:generic"]], "pred": [["method:generic", "used for", "pattern extraction scheme:method"], ["method:generic", "used for", "Bayesian learning algorithm:method"], ["distribution over the values of a move:other scientific term", "part of", "local pattern context:other scientific term"], ["pattern extraction scheme:method", "part of", "method:generic"], ["Bayesian learning algorithm:method", "part of", "method:generic"], ["expert game records:material", "part of", "pattern extraction scheme:method"]], "response": "(1) \"used for\"  \n(2) \"used for\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"part of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"part of\"  \n(12) \"part of\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"part of\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "549": {"text": "We present a new part-of-speech tagger that demonstrates the following ideas: -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation, -LRB- ii -RRB- broad use of lexical features, including jointly conditioning on multiple consecutive words, -LRB- iii -RRB- effective use of priors in conditional loglinear models, and -LRB- iv -RRB- fine-grained modeling of unknown word features.", "true": [["tag contexts:other scientific term", "used for", "part-of-speech tagger:method"], ["dependency network representation:method", "used for", "tag contexts:other scientific term"], ["lexical features:other scientific term", "used for", "part-of-speech tagger:method"], ["priors in conditional loglinear models:other scientific term", "used for", "part-of-speech tagger:method"], ["fine-grained modeling of unknown word features:method", "used for", "part-of-speech tagger:method"]], "pred": [["multiple consecutive words:other scientific term", "part of", "lexical features:other scientific term"], ["lexical features:other scientific term", "feature of", "part-of-speech tagger:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"part of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"feature of\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "550": {"text": "In particular there are three areas of novelty: -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation, learnt offline, to generalize in the presence of extreme illumination changes; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses; and -LRB- iii -RRB- we introduce an accurate video sequence\" reillumination\" algorithm to achieve robustness to face motion patterns in video.", "true": [["photometric model:method", "used for", "image formation:task"], ["photometric model:method", "conjunction", "statistical model:method"], ["statistical model:method", "used for", "generic face appearance variation:task"], ["statistical model:method", "used for", "extreme illumination changes:other scientific term"], ["smoothness:other scientific term", "feature of", "geodesically local appearance manifold structure:other scientific term"], ["geodesically local appearance manifold structure:other scientific term", "conjunction", "robust same-identity likelihood:method"], ["video sequence\" reillumination\" algorithm:method", "evaluated for", "robustness:metric"], ["face motion patterns:other scientific term", "feature of", "robustness:metric"], ["face motion patterns:other scientific term", "part of", "video:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}}, "missing_cases": {"3": [["Language resource quality:metric", "feature of", "NLP:task"]], "5": [["ambiguity:other scientific term", "feature of", "determiners:method"]], "8": [["It:generic", "used for", "empirical MT research:task"]], "10": [["Plume:method", "hyponym of", "restricted domain parser:method"]], "13": [["affine projection:method", "used for", "reconstruction:task"]], "15": [["beam-search decoder:method", "used for", "Translations:other scientific term"]], "22": [["approach:generic", "evaluated for", "VIVID benchmark datasets:material"], ["state-of-the-art trackers:generic", "compare", "approach:generic"], ["state-of-the-art trackers:generic", "evaluated for", "VIVID benchmark datasets:material"]], "23": [["translating virtual camera:other scientific term", "used for", "synthesis:task"]], "27": [["Background modeling:task", "part of", "vision systems:task"]], "29": [["approach:generic", "used for", "automatically acquiring English topic signatures:task"]], "31": [["system combination:method", "used for", "unsupervised WSD:task"]], "34": [["recursive descent parser:method", "used for", "It:generic"]], "37": [["different-quality references:other scientific term", "used for", "evaluation:generic"]], "39": [["histogram information:other scientific term", "used for", "detecting interest points:task"], ["method:generic", "used for", "detecting interest points:task"]], "40": [["highly correlated inputs:material", "used for", "random modulation scheme:method"], ["random modulation scheme:method", "used for", "near-Bernoulli statistics:other scientific term"]], "42": [["Minimum Bayes-Risk -LRB- MBR -RRB- decoding:method", "used for", "statistical machine translation:task"]], "44": [["evaluation criterion:metric", "used for", "word similarity measures:metric"]], "49": [["MINPRAN:method", "used for", "complex range:other scientific term"], ["MINPRAN:method", "used for", "intensity data:material"]], "50": [["triangulation:other scientific term", "used for", "piecewise-linear interpolant:other scientific term"]], "51": [["method:generic", "evaluated for", "word-aligned corpora:material"], ["method:generic", "used for", "phrases:generic"]], "53": [["Amorph:method", "used for", "NE items:other scientific term"], ["dictionary lookup:method", "conjunction", "rule application:method"], ["dictionary lookup:method", "part of", "Amorph:method"], ["rule application:method", "part of", "Amorph:method"]], "54": [["posterior:generic", "used for", "sparse se-lectional preferences:other scientific term"]], "55": [["approach:generic", "used for", "LCS-Marine:task"]], "57": [["Machine transliteration/back-transliteration:task", "used for", "multilingual speech and language applications:task"]], "59": [["MBR decoders:method", "used for", "Chinese-to-English translation task:task"]], "61": [["dialogue:material", "used for", "bare slice disambiguation:task"]], "63": [["It:generic", "used for", "reflection:other scientific term"]], "64": [["detectors:generic", "used for", "detector:generic"]], "65": [["they:generic", "compare", "exhaustive search:method"]], "66": [["method:generic", "used for", "priming:other scientific term"], ["priming:other scientific term", "used for", "incremental probabilistic parser:method"]], "67": [["rhetorical moves of argumentation:method", "used for", "scheme:generic"]], "68": [["algorithm:generic", "used for", "novel view generation:task"]], "70": [["motor control representation:method", "used for", "matching of cursive scripts:task"], ["motor control representation:method", "used for", "word spotting:task"], ["word spotting:task", "conjunction", "matching of cursive scripts:task"]], "71": [["hand-crafted rules:other scientific term", "used for", "syntactic knowledge:other scientific term"]], "72": [["Listen-Communicate-Show -LRB- LCS -RRB-:task", "used for", "human interaction with data sources:task"]], "79": [["machine translation outputs:other scientific term", "conjunction", "expert human translations:other scientific term"]], "81": [["integrated learning system:method", "evaluated for", "ooce domains:task"], ["integrated learning system:method", "evaluated for", "simulated construction:task"], ["simulated construction:task", "conjunction", "ooce domains:task"]], "82": [["raw text:material", "used for", "predominant senses:other scientific term"]], "83": [["Prolog:other scientific term", "hyponym of", "programming language:other scientific term"], ["Prolog:other scientific term", "used for", "system:generic"], ["logic:other scientific term", "used for", "programming language:other scientific term"]], "85": [["comparable, non-parallel corpora:material", "used for", "discovering parallel sentences:task"], ["method:generic", "used for", "discovering parallel sentences:task"]], "87": [["linguistic expressiveness:other scientific term", "feature of", "formalisms:generic"]], "88": [["graph:other scientific term", "used for", "UNL-L0 deconverter:method"]], "89": [["stochastic gradient descent algorithm:method", "used for", "learning problem:generic"]], "90": [["kernel trick:method", "used for", "non-linear extension of WARCA:method"]], "91": [["model-based approach:method", "used for", "on-line cursive handwriting analysis and recognition:task"]], "92": [["approaches:generic", "used for", "object pose estimation:task"]], "94": [["GLOSSER:method", "used for", "reading and learning:task"]], "96": [["dictionaries:other scientific term", "used for", "Japanese character strings:other scientific term"], ["dictionaries:other scientific term", "used for", "it:generic"]], "97": [["English:material", "feature of", "nominal compounds:other scientific term"], ["domain independent model:method", "used for", "automated interpretation of nominal compounds:task"]], "99": [["model:generic", "used for", "blind separation of natural speech signals.:task"]], "100": [["methods:generic", "evaluated for", "transliteration/backtransliteration:task"], ["transliteration/backtransliteration:task", "used for", "English/Chinese and English/Japanese language pairs:material"]], "102": [["sampling probabilities:other scientific term", "used for", "records:material"], ["specialized regression problem:task", "used for", "sampling probabilities:other scientific term"]], "104": [["Branch and bound strategies:method", "used for", "complexity:generic"], ["global optimality:other scientific term", "feature of", "Branch and bound strategies:method"]], "105": [["textual credibility indicators:other scientific term", "part of", "retrieval process:method"]], "107": [["posteriori bound:other scientific term", "used for", "joint matrix decomposition:task"]], "108": [["Learned confidence measures:method", "used for", "outlier removal:task"], ["Learned confidence measures:method", "used for", "quality improvement:task"], ["outlier removal:task", "conjunction", "quality improvement:task"], ["outlier removal:task", "part of", "stereo vision:task"], ["quality improvement:task", "part of", "stereo vision:task"]], "110": [["model:generic", "evaluated for", "streaming video dataset:material"]], "112": [["correctness proof:method", "conjunction", "LR-parsers:method"]], "114": [["dynamic representation:method", "used for", "cursive handwriting recognition:task"]], "115": [["high-capacity models:method", "used for", "computer vision:task"], ["large datasets:material", "used for", "high-capacity models:method"]], "116": [["hypothesized object boundary fragments:other scientific term", "used for", "mattes:generic"]], "117": [["They:generic", "used for", "reconstruction:task"], ["object shape:other scientific term", "feature of", "priori knowledge:other scientific term"]], "119": [["method:generic", "used for", "space-time interest point detection:task"], ["space-time interest point detection:task", "used for", "action classification:task"]], "122": [["generative proba-bilistic framework:method", "used for", "3D object categorization:task"]], "124": [["gray-level band-pass white noise patterns:other scientific term", "evaluated for", "robustness:metric"], ["indirect lighting:other scientific term", "conjunction", "scene discontinuities:other scientific term"], ["indirect lighting:other scientific term", "feature of", "robustness:metric"], ["scene discontinuities:other scientific term", "feature of", "robustness:metric"]], "125": [["Computing power per area:metric", "conjunction", "power consumption:metric"]], "126": [["model:generic", "used for", "knowledge sources:material"]], "127": [["psycholinguistic literature:other scientific term", "used for", "syntactic priming:other scientific term"]], "129": [["natural language environment:other scientific term", "feature of", "human-machine interactions:task"]], "131": [["dynamic-programming, stereo algorithm:method", "used for", "technique:generic"], ["technique:generic", "used for", "novel-view generation:task"]], "133": [["Memo-functions:method", "used for", "parse forest:other scientific term"]], "134": [["Head Grammars:method", "hyponym of", "grammatical formalisms:method"], ["Tree Adjoining Grammars:method", "hyponym of", "grammatical formalisms:method"]], "135": [["Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-:method", "hyponym of", "metric learning formulation:method"]], "138": [["deep archi-tectures:method", "used for", "object category recognition:task"]], "142": [["approach:generic", "used for", "cluttered scenes:other scientific term"]], "144": [["clustering methods:method", "evaluated for", "ACE corpora:material"], ["spectral clustering based approach:method", "compare", "clustering methods:method"], ["spectral clustering based approach:method", "evaluated for", "ACE corpora:material"]], "145": [["images:material", "used for", "perception of transparent objects:task"]], "147": [["detection and viewpoint classification tasks:task", "evaluated for", "datasets:generic"]], "148": [["Turkish:material", "hyponym of", "agglutinating free word order language:material"]], "151": [["zero-crossings:other scientific term", "used for", "Subpixel accuracy:metric"]], "152": [["attentional focus:other scientific term", "part of", "direction-giving task:task"], ["eye gaze:other scientific term", "conjunction", "head nods:other scientific term"], ["eye gaze:other scientific term", "part of", "direction-giving task:task"], ["head nods:other scientific term", "conjunction", "attentional focus:other scientific term"], ["head nods:other scientific term", "part of", "direction-giving task:task"]], "153": [["hard budget constraints:other scientific term", "used for", "cost zero solution:method"]], "154": [["Bayesian Network:method", "used for", "addressee identification in four-participants face-to-face meetings:task"], ["Naive Bayes classifiers:method", "conjunction", "Bayesian Network:method"], ["Naive Bayes classifiers:method", "used for", "addressee identification in four-participants face-to-face meetings:task"]], "155": [["distribution:generic", "used for", "computer Go:other scientific term"]], "156": [["voting - and arbiter-based combination strategies:method", "used for", "unsupervised WSD systems:method"]], "157": [["Chat-80:method", "hyponym of", "natural language question answering system:method"]], "158": [["well-segmented 3D skeleton data:material", "used for", "Human action recognition:task"]], "160": [["MINPRAN:method", "evaluated for", "synthetic data:material"], ["least median of squares:method", "compare", "MINPRAN:method"]], "161": [["them:generic", "evaluated for", "computational tractability and explanatory adequacy:metric"]], "162": [["English-Bulgarian:material", "conjunction", "English-Estonian:material"], ["English-Bulgarian:material", "hyponym of", "language pairs:generic"], ["English-Estonian:material", "conjunction", "English-Hungarian:material"], ["English-Estonian:material", "hyponym of", "language pairs:generic"], ["English-Hungarian:material", "conjunction", "French-Dutch:material"], ["English-Hungarian:material", "hyponym of", "language pairs:generic"], ["French-Dutch:material", "hyponym of", "language pairs:generic"], ["language pairs:generic", "used for", "GLOSSER:method"]], "164": [["Euclidean distance:other scientific term", "used for", "deep embedding methods:method"]], "165": [["boundary detection:method", "used for", "approach:generic"], ["image matting:method", "conjunction", "boundary detection:method"], ["image matting:method", "used for", "approach:generic"], ["spectral clustering:method", "conjunction", "image matting:method"], ["spectral clustering:method", "used for", "approach:generic"]], "166": [["automatic evaluations:task", "evaluated for", "high-quality data:material"]], "167": [["MT:task", "evaluated for", "automatic metrics:metric"]], "168": [["method:generic", "used for", "modeling and subtraction of such scenes:task"]], "169": [["Fast algorithms:generic", "used for", "nearest neighbor -LRB- NN -RRB- search:task"]], "170": [["Structural or numerical constraints:other scientific term", "used for", "reconstruction process:method"], ["constrained optimization scheme:method", "used for", "Structural or numerical constraints:other scientific term"]], "171": [["intelligent mobile agents:method", "part of", "spoken language understanding system:method"]], "173": [["nominals:other scientific term", "feature of", "predicative information:other scientific term"]], "174": [["generalizable semantic principles:other scientific term", "compare", "domain-specific semantic information:other scientific term"]], "175": [["ungrammatical input:other scientific term", "feature of", "robustness:metric"]], "176": [["multiple layers:other scientific term", "part of", "they:generic"], ["refractive indices:other scientific term", "feature of", "multiple layers:other scientific term"]], "177": [["PageRank algorithm:method", "used for", "relevant approach:method"], ["documents:material", "used for", "event map:other scientific term"], ["event map:other scientific term", "used for", "PageRank algorithm:method"]], "178": [["translation:task", "evaluated for", "loss functions:other scientific term"]], "179": [["MBR decoding:method", "used for", "loss functions:other scientific term"], ["MBR decoding:method", "used for", "statistical MT:method"]], "180": [["speaker's gaze information:other scientific term", "conjunction", "utterance features:other scientific term"]], "182": [["corpus-based sample:material", "used for", "heuristic principles:method"], ["probabilistic Horn clauses:other scientific term", "feature of", "heuristic principles:method"]], "184": [["supervised training data:material", "used for", "information extraction techniques:method"]], "186": [["dataset:generic", "conjunction", "G3D dataset:material"]], "187": [["cluster analysis:method", "used for", "sampled parameter space:other scientific term"]], "189": [["dependency-based grammar model:method", "used for", "sentence-level and text-level anaphora:other scientific term"]], "190": [["raw corpus:material", "used for", "language model adaptation methods:method"], ["word list:other scientific term", "conjunction", "raw corpus:material"], ["word list:other scientific term", "used for", "language model adaptation methods:method"]], "191": [["discrete data:material", "used for", "modeling problems:task"], ["multinomial or categorical distributions:method", "used for", "modeling problems:task"]], "192": [["cycloidal motion parameters:other scientific term", "used for", "arbitrary handwriting:material"]], "195": [["decision tree-based context clustering:method", "used for", "parameter training algorithm:method"], ["parameter training algorithm:method", "used for", "model:generic"]], "196": [["concept hierarchy constraints:other scientific term", "used for", "NCA:method"], ["frequency of occurrences:other scientific term", "used for", "NCA:method"]], "198": [["known motion:other scientific term", "used for", "shapes and the poses of transparent objects:other scientific term"], ["model-based approach:method", "used for", "shapes and the poses of transparent objects:other scientific term"]], "199": [["convolution kernel over parse trees:method", "used for", "syntactic structure information:other scientific term"], ["syntactic structure information:other scientific term", "used for", "relation extraction:task"]], "200": [["mi-cro phase shifting:method", "conjunction", "modulated phase shifting:method"], ["mi-cro phase shifting:method", "hyponym of", "state of the art methods:generic"], ["modulated phase shifting:method", "hyponym of", "state of the art methods:generic"]], "201": [["pattern-matching language:other scientific term", "used for", "It:generic"], ["pattern-matching language:other scientific term", "used for", "grs:other scientific term"]], "202": [["principled and provable solution:method", "used for", "problem:generic"]], "203": [["task dialogues:material", "used for", "prototype Natural Language system:method"], ["technique:generic", "used for", "task dialogues:material"]], "204": [["assessors:generic", "evaluated for", "language learning:task"]], "206": [["feature points:other scientific term", "feature of", "motion trajectories:other scientific term"], ["motion trajectories:other scientific term", "used for", "technique:generic"], ["technique:generic", "used for", "detecting reflections in image sequences:task"]], "207": [["ASA:method", "compare", "local deterministic search:method"], ["ASA:method", "hyponym of", "Monte Carlo approach:method"]], "208": [["approach:generic", "used for", "parallel data:material"], ["parallel data:material", "part of", "Chinese, Arabic, and English non-parallel newspaper corpora:material"]], "209": [["non-contiguous phrases:material", "used for", "phrase-based statistical machine translation method:method"]], "211": [["ambiguities:other scientific term", "feature of", "computation of features:task"], ["data-dependent bandwidth:other scientific term", "used for", "ambiguities:other scientific term"], ["data-dependent bandwidth:other scientific term", "used for", "density estimation:task"], ["kernels:method", "used for", "density estimation:task"]], "212": [["information extraction annotations:other scientific term", "used for", "document retrieval for distillation:task"]], "213": [["affine-invariant image patches:other scientific term", "feature of", "three-dimensional objects:other scientific term"], ["representation:generic", "used for", "three-dimensional objects:other scientific term"], ["spatial relationships:other scientific term", "feature of", "affine-invariant image patches:other scientific term"]], "214": [["Japanese information extraction:task", "used for", "It:generic"]], "215": [["iterative deformation of a 3--D surface mesh:method", "used for", "approach:generic"], ["iterative deformation of a 3--D surface mesh:method", "used for", "objective function:other scientific term"]], "216": [["model:generic", "evaluated for", "English and Czech newspaper texts:material"], ["model:generic", "evaluated for", "French broadcast news transcriptions:material"]], "217": [["binary-binary partial matrix-vector multiplication:method", "used for", "high-density, low-power analog array:other scientific term"], ["high-density, low-power analog array:other scientific term", "part of", "externally digital architecture:method"]], "219": [["prior on the distribution of natural images:other scientific term", "used for", "support vector machines:method"]], "220": [["verbal and nonverbal grounding acts:other scientific term", "used for", "ECA:method"], ["verbal and nonverbal grounding acts:other scientific term", "used for", "dialogue state:other scientific term"]], "222": [["uniform sampling:method", "conjunction", "stratified sampling:method"]], "223": [["Topical blog post retrieval:task", "hyponym of", "ranking blog posts:task"], ["relevance:metric", "feature of", "blog posts:material"]], "224": [["language models:method", "used for", "them:generic"], ["them:generic", "part of", "retrieval approach:method"]], "226": [["Bayesian statistics:method", "used for", "approach:generic"], ["approach:generic", "used for", "robust-ness requirement in image understanding:task"]], "228": [["ensembles:generic", "evaluated for", "SemCor and Senseval-3 data sets:material"], ["state-of-the-art:generic", "evaluated for", "SemCor and Senseval-3 data sets:material"]], "229": [["action type:other scientific term", "conjunction", "temporal localiza-tion information:other scientific term"], ["multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method", "used for", "action type:other scientific term"], ["multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method", "used for", "temporal localiza-tion information:other scientific term"]], "230": [["machine translation -LRB- MT -RRB- evaluation:task", "conjunction", "sentence-level semantic equivalence classification:task"]], "231": [["models:generic", "evaluated for", "paraphrase classification accuracy:metric"], ["technique:generic", "compare", "models:generic"], ["technique:generic", "evaluated for", "paraphrase classification accuracy:metric"]], "232": [["trainable sentence planner:method", "evaluated for", "subjective human judgments:other scientific term"], ["trainable sentence planner:method", "used for", "spoken dialogue system:method"]], "233": [["scarce resources:material", "used for", "method:generic"]], "234": [["analogies:other scientific term", "evaluated for", "multilingual corpus:material"]], "238": [["ASR system:method", "used for", "Noise Spotting capabilities:task"], ["ASR system:method", "used for", "Word Spotting:task"]], "239": [["pixel-level labels:other scientific term", "feature of", "large datasets:material"]], "240": [["Turkish:material", "hyponym of", "agglutinative language:material"], ["productive affixations of derivational and inflectional suffixes:other scientific term", "part of", "word structures:other scientific term"], ["word structures:other scientific term", "feature of", "agglutinative language:material"]], "241": [["phonetic rules:other scientific term", "used for", "surface realizations of morphological constructions:task"], ["vowel harmony:other scientific term", "hyponym of", "phonetic rules:other scientific term"]], "242": [["persistent dynamic behavior:other scientific term", "feature of", "scene:generic"]], "243": [["weakly supervised dependency parser:task", "used for", "speech syntax:other scientific term"]], "245": [["it:generic", "used for", "real scenes:material"], ["it:generic", "used for", "shapes of the objects:other scientific term"], ["shapes of the objects:other scientific term", "evaluated for", "accuracy:metric"], ["transparent objects:other scientific term", "part of", "real scenes:material"]], "246": [["appearance information:other scientific term", "conjunction", "geometric constraints:other scientific term"], ["appearance information:other scientific term", "used for", "probabilistic framework:method"], ["geometric constraints:other scientific term", "used for", "probabilistic framework:method"], ["probabilistic framework:method", "used for", "visual models of 3D object categories:task"]], "247": [["sentence condensation systems:method", "evaluated for", "summarization quality:metric"], ["summarization quality:metric", "evaluated for", "parser evaluation methods:method"]], "248": [["method:generic", "compare", "methods:generic"], ["method:generic", "evaluated for", "separation accuracy:metric"], ["method:generic", "used for", "natural speech signals:other scientific term"], ["methods:generic", "evaluated for", "separation accuracy:metric"], ["methods:generic", "used for", "natural speech signals:other scientific term"]], "249": [["method:generic", "compare", "dependency tree kernels:method"]], "250": [["Combinatory Categorial Grammar -LRB- CCG -RRB- lexicon:other scientific term", "part of", "Turkish dependency treebank:material"]], "251": [["precision:metric", "conjunction", "recall:metric"], ["system:generic", "evaluated for", "precision:metric"], ["system:generic", "evaluated for", "recall:metric"]], "252": [["approach:generic", "compare", "state-of-the-art approaches:generic"], ["approach:generic", "used for", "outdoor surveillance settings:other scientific term"], ["multiple PTZ camera sequences:other scientific term", "used for", "approach:generic"]], "253": [["approaches:generic", "used for", "evaluation of Natural Language systems:task"]], "254": [["game records of expert players:material", "used for", "board game of Go:task"]], "255": [["training resources:material", "used for", "automatic abstracting systems:task"]], "257": [["camera motions:other scientific term", "feature of", "airborne videos:material"], ["heavy occlusion:other scientific term", "conjunction", "camera motions:other scientific term"], ["heavy occlusion:other scientific term", "feature of", "airborne videos:material"], ["numerical hybrid local and global mode-seeking tracker:method", "evaluated for", "airborne videos:material"]], "258": [["algorithm:generic", "evaluated for", "robustness:metric"], ["algorithm:generic", "used for", "spatial and temporal artefacts:other scientific term"], ["spatial and temporal artefacts:other scientific term", "used for", "long stereo video streams:material"]], "259": [["anaphora references:other scientific term", "conjunction", "syntactic ambiguities:other scientific term"], ["semantic constraints:other scientific term", "used for", "anaphora references:other scientific term"], ["semantic constraints:other scientific term", "used for", "syntactic ambiguities:other scientific term"]], "261": [["intentional structure:other scientific term", "used for", "discourse-relevant purposes:other scientific term"]], "263": [["interactive MT:task", "conjunction", "multilingual text authoring:task"], ["pivot MT:task", "conjunction", "interactive MT:task"]], "264": [["deep models:method", "used for", "person re-identification:task"]], "265": [["discrete nerve-action potentials:other scientific term", "used for", "analog pressure wave:other scientific term"], ["encoding sound:task", "used for", "neuronal processing:task"]], "268": [["random statistics:other scientific term", "part of", "analog summation of binary products:other scientific term"]], "269": [["those:generic", "compare", "features:other scientific term"]], "270": [["generative framework:method", "used for", "model:generic"]], "271": [["automatic parse-based evaluation:method", "evaluated for", "summarization quality:metric"]], "272": [["system:generic", "used for", "acquiring adjectival subcategorization frames -LRB- scfs -RRB-:task"]], "273": [["method:generic", "evaluated for", "transliteration accuracy:metric"]], "274": [["broadcast news speech:material", "hyponym of", "corpora:generic"], ["conversational telephone speech:material", "conjunction", "broadcast news speech:material"], ["conversational telephone speech:material", "hyponym of", "corpora:generic"], ["human transcriptions:other scientific term", "conjunction", "speech recognition output:other scientific term"], ["human transcriptions:other scientific term", "evaluated for", "corpora:generic"], ["speech recognition output:other scientific term", "evaluated for", "corpora:generic"]], "275": [["records:material", "evaluated for", "aggregate queries:other scientific term"]], "276": [["closed-form -LRB- analytical -RRB- solution:method", "used for", "Kullback-Leibler distance:method"], ["closed-form -LRB- analytical -RRB- solution:method", "used for", "cross-entropy:method"], ["cross-entropy:method", "part of", "Kullback-Leibler distance:method"]], "277": [["feature vectors:other scientific term", "conjunction", "word similarity:task"], ["feature weighting and selection function:method", "used for", "feature vectors:other scientific term"], ["feature weighting and selection function:method", "used for", "word similarity:task"]], "278": [["extraposition grammars:method", "hyponym of", "logic-based grammar formalism:method"], ["extraposition grammars:method", "used for", "Chat-80:method"]], "279": [["planning algorithm:method", "used for", "logical expression:other scientific term"], ["relational database:material", "used for", "query optimisation:method"]], "280": [["MT evaluation techniques:method", "used for", "entailment:task"], ["MT evaluation techniques:method", "used for", "features:other scientific term"], ["MT evaluation techniques:method", "used for", "paraphrase classification:task"], ["paraphrase classification:task", "conjunction", "entailment:task"]], "282": [["it:generic", "used for", "statistical machine translation system:method"]], "285": [["techniques:generic", "compare", "MINPRAN:method"], ["techniques:generic", "used for", "large outlier percentages:metric"]], "287": [["discrete motor control representation:method", "used for", "continuous pen motion:other scientific term"]], "289": [["geometric structures of 3D lines:task", "used for", "light field triangulation:task"], ["geometric structures of 3D lines:task", "used for", "stereo matching:task"], ["light field triangulation:task", "conjunction", "stereo matching:task"], ["ray space:other scientific term", "feature of", "geometric structures of 3D lines:task"]], "291": [["state-of-the-art solutions:generic", "evaluated for", "accuracy:metric"], ["state-of-the-art solutions:generic", "evaluated for", "synthetic and real data:material"], ["state-of-the-art solutions:generic", "evaluated for", "visual quality:metric"], ["triangulation and LAGC algorithms:method", "compare", "state-of-the-art solutions:generic"], ["triangulation and LAGC algorithms:method", "evaluated for", "accuracy:metric"], ["triangulation and LAGC algorithms:method", "evaluated for", "synthetic and real data:material"], ["triangulation and LAGC algorithms:method", "evaluated for", "visual quality:metric"]], "292": [["approach:generic", "used for", "pixel-accurate semantic label maps:other scientific term"], ["images:material", "part of", "modern computer games:other scientific term"], ["pixel-accurate semantic label maps:other scientific term", "used for", "images:material"]], "293": [["feature:other scientific term", "used for", "modeling of the dynamic characteristics:task"], ["higher dimensional space:other scientific term", "feature of", "feature:other scientific term"]], "295": [["ambiguity packing and stochastic disambiguation techniques:method", "used for", "Lexical-Functional Grammars -LRB- LFG -RRB-:method"], ["ambiguity packing and stochastic disambiguation techniques:method", "used for", "sentence condensation:task"]], "296": [["demonstrative expressions:other scientific term", "feature of", "English:material"], ["implications:generic", "used for", "discourse processing algorithms:method"]], "297": [["scanning method:method", "used for", "dense sub-pixel camera-projector correspondence:other scientific term"]], "298": [["distributional approximation:task", "feature of", "probabilistic context-free grammars:method"], ["probabilistic finite automata:method", "used for", "distributional approximation:task"]], "299": [["2D point correspondences:other scientific term", "used for", "reconstructing the motion of a 3D articulated tree:task"]], "301": [["learning in autonomous agents:task", "used for", "domain-speciic models of actions:method"], ["planning systems:task", "used for", "domain-speciic models of actions:method"]], "302": [["GOLEM:method", "used for", "action models:method"]], "303": [["images:material", "used for", "automated segmentation:task"]], "304": [["dynamic programming -LRB- DP -RRB-:method", "used for", "statistical machine translation -LRB- MT -RRB-:task"], ["search procedure:generic", "used for", "statistical machine translation -LRB- MT -RRB-:task"]], "305": [["Verbmobil task:material", "hyponym of", "limited-domain spoken-language task:task"]], "307": [["loss:other scientific term", "used for", "Mahalanobis distance:task"], ["weighted sum:other scientific term", "feature of", "precision:metric"]], "309": [["MINPRAN:method", "hyponym of", "robust operator:method"]], "311": [["generalization ability:other scientific term", "feature of", "learned metric:other scientific term"], ["metric weight constraint:other scientific term", "used for", "learning:generic"]], "312": [["full scale two-level morphological description:task", "used for", "Turkish word structures:material"]], "313": [["cascade evaluation:method", "compare", "method:generic"], ["cascade evaluation:method", "evaluated for", "PASCAL VOC 2006 dataset:material"], ["method:generic", "evaluated for", "PASCAL VOC 2006 dataset:material"]], "314": [["approach:generic", "used for", "1 distance:other scientific term"]], "315": [["it:generic", "compare", "alternatives:generic"]], "316": [["anisotropic meshing:method", "conjunction", "non-quadratic approach:method"], ["anisotropic meshing:method", "used for", "reconstruction:task"], ["non-quadratic approach:method", "used for", "reconstruction:task"], ["non-quadratic approach:method", "used for", "regularization:other scientific term"], ["triangulations:other scientific term", "used for", "reconstruction:task"]], "317": [["model:generic", "used for", "productive rules of interpretation:other scientific term"], ["morpho-syntactic and semantic characteristics:other scientific term", "feature of", "nominal constituents:other scientific term"], ["morpho-syntactic and semantic characteristics:other scientific term", "used for", "productive rules of interpretation:other scientific term"]], "318": [["kernels:method", "used for", "image processing:task"], ["mixed-signal paradigm:method", "used for", "high-resolution parallel inner-product computation:task"], ["mixed-signal paradigm:method", "used for", "kernels:method"]], "319": [["approach:generic", "evaluated for", "real image data:material"]], "320": [["method:generic", "used for", "blind separation of underdetermined instantaneous mixtures of independent signals:task"], ["nonstationarity:other scientific term", "used for", "method:generic"]], "321": [["detection of question-answer pairs:task", "used for", "email summarization:task"], ["email conversation:material", "used for", "detection of question-answer pairs:task"]], "322": [["approach:generic", "used for", "camera handoff in wide-area surveillance scenarios:task"]], "323": [["data retrieval:task", "part of", "task:generic"], ["systems:generic", "evaluated for", "approaches:generic"], ["systems:generic", "used for", "task:generic"]], "324": [["conversational context features:other scientific term", "used for", "addressee of a dialogue act:other scientific term"], ["gaze:other scientific term", "conjunction", "utterance:other scientific term"], ["gaze:other scientific term", "used for", "addressee of a dialogue act:other scientific term"], ["utterance:other scientific term", "conjunction", "conversational context features:other scientific term"], ["utterance:other scientific term", "used for", "addressee of a dialogue act:other scientific term"]], "326": [["It:generic", "used for", "move selector:method"], ["It:generic", "used for", "move sorter:method"], ["It:generic", "used for", "training tool:task"], ["move selector:method", "conjunction", "move sorter:method"], ["move selector:method", "used for", "game tree search:method"], ["move sorter:method", "used for", "game tree search:method"], ["training tool:task", "used for", "Go players:other scientific term"]], "327": [["reference problems:task", "hyponym of", "miscommunication:task"], ["techniques:generic", "used for", "failures of reference:task"]], "328": [["baselines:generic", "conjunction", "hand-crafted system:method"], ["rule-based systems:method", "conjunction", "baselines:generic"], ["trainable sentence planner:method", "compare", "baselines:generic"], ["trainable sentence planner:method", "compare", "hand-crafted system:method"], ["trainable sentence planner:method", "compare", "rule-based systems:method"]], "332": [["person re-identification:task", "hyponym of", "computer vision:task"], ["weighted rank loss:other scientific term", "used for", "computer vision:task"]], "333": [["AN fibers -LRB- ANFs -RRB-:other scientific term", "used for", "features:other scientific term"], ["OA:method", "used for", "features:other scientific term"], ["OA:method", "used for", "phase locking in the auditory nerve -LRB- AN -RRB-:task"], ["features:other scientific term", "evaluated for", "ASR accuracy:metric"]], "334": [["Gaussian mixture models -LRB- GMMs -RRB-:method", "used for", "ANF-based and ON-based auditory features:other scientific term"], ["Multi-layer perceptrons -LRB- MLPs -RRB-:method", "used for", "ANF-based and ON-based auditory features:other scientific term"]], "335": [["It:generic", "evaluated for", "dataset of scenes:material"], ["It:generic", "used for", "unsupervised object discovery:task"]], "336": [["fundamental frequency -LRB- F0 -RRB- contour of speech:other scientific term", "used for", "text-to-speech synthesis:task"], ["text input:material", "used for", "fundamental frequency -LRB- F0 -RRB- contour of speech:other scientific term"]], "337": [["them:generic", "used for", "3--D reconstruction:task"]], "338": [["unsupervised learning approach:method", "used for", "relations between named entities:other scientific term"]], "339": [["factorization:method", "used for", "tensors:generic"], ["line correspondences:other scientific term", "used for", "estimation:generic"]], "342": [["model:generic", "compare", "mixture of viewpoints models:method"]], "343": [["constraint-based parser/generator:method", "used for", "system:generic"], ["system:generic", "evaluated for", "grammaticality:metric"], ["system:generic", "evaluated for", "summarization quality:metric"]], "344": [["anaphoric expressions:other scientific term", "used for", "natural language generation system:method"]], "346": [["features:other scientific term", "used for", "lexical similarity:other scientific term"], ["lexical similarity:other scientific term", "feature of", "discourse segments:other scientific term"], ["structure of email-threads:other scientific term", "used for", "features:other scientific term"]], "347": [["SVMs:method", "used for", "overfitting:other scientific term"]], "348": [["Sentence boundary detection:task", "used for", "speech recognition output:other scientific term"], ["speech:material", "used for", "Sentence boundary detection:task"]], "349": [["illumination:task", "conjunction", "pose invariance:task"], ["illumination:task", "part of", "face recognition:task"], ["pose invariance:task", "part of", "face recognition:task"]], "350": [["pathological motion:other scientific term", "conjunction", "occlusion:other scientific term"], ["priors:other scientific term", "used for", "sparse and dense detection maps:other scientific term"]], "351": [["parallel structures:other scientific term", "part of", "human data:material"]], "352": [["FERRET:method", "hyponym of", "interactive question-answering -LRB- Q/A -RRB- system:method"], ["FERRET:method", "used for", "integrating automatic Q/A applications into real-world environments:task"]], "353": [["annotation scheme:method", "used for", "scientific articles:material"]], "355": [["cue phrases:other scientific term", "conjunction", "referring expressions:other scientific term"], ["cue phrases:other scientific term", "hyponym of", "discourse phenomena:other scientific term"], ["interruptions:other scientific term", "hyponym of", "discourse phenomena:other scientific term"], ["referring expressions:other scientific term", "conjunction", "interruptions:other scientific term"], ["referring expressions:other scientific term", "hyponym of", "discourse phenomena:other scientific term"]], "356": [["Coedition:task", "used for", "text revision:other scientific term"], ["natural language text:material", "used for", "Coedition:task"]], "357": [["language models:method", "evaluated for", "speech recognition accuracies:metric"], ["methods:generic", "used for", "preparing a segmented corpus:task"]], "358": [["context-free phrase structure rules:other scientific term", "conjunction", "metarules -LRB- MPS grammars -RRB-:other scientific term"], ["context-free phrase structure rules:other scientific term", "part of", "Metagrammatical formalisms:method"], ["metarules -LRB- MPS grammars -RRB-:other scientific term", "part of", "Metagrammatical formalisms:method"]], "360": [["OA:method", "used for", "auditory processing:task"], ["onset neurons -LRB- ONs -RRB-:other scientific term", "used for", "OA:method"]], "361": [["MT:task", "conjunction", "reference translations:task"], ["MT:task", "hyponym of", "NLP:task"], ["reference translations:task", "hyponym of", "NLP:task"]], "362": [["Fujisaki model:method", "used for", "statistical model:method"], ["statistical model:method", "used for", "speech F0 contours:other scientific term"]], "363": [["divide-and-conquer procedure:method", "used for", "method:generic"], ["method:generic", "used for", "evaluation of object detection cascades:task"], ["space of candidate regions:method", "feature of", "divide-and-conquer procedure:method"]], "365": [["Japanese:material", "used for", "morphological analysis problem:task"], ["Multi-lingual Evaluation Task -LRB- MET -RRB-:task", "used for", "Japanese text:material"], ["approach:generic", "used for", "Multi-lingual Evaluation Task -LRB- MET -RRB-:task"], ["morphological analysis problem:task", "used for", "task:generic"]], "366": [["detectors:generic", "used for", "blur:other scientific term"], ["detectors:generic", "used for", "distinctive textured patterns:other scientific term"], ["detectors:generic", "used for", "illumination variation:other scientific term"], ["detectors:generic", "used for", "large-scale structures:other scientific term"], ["detectors:generic", "used for", "rotation:other scientific term"], ["illumination variation:other scientific term", "conjunction", "blur:other scientific term"], ["large-scale structures:other scientific term", "conjunction", "distinctive textured patterns:other scientific term"], ["rotation:other scientific term", "conjunction", "illumination variation:other scientific term"]], "367": [["dags:other scientific term", "conjunction", "graphs:other scientific term"], ["dags:other scientific term", "hyponym of", "structures:generic"], ["graphs:other scientific term", "hyponym of", "structures:generic"], ["strings:other scientific term", "conjunction", "trees:other scientific term"], ["strings:other scientific term", "hyponym of", "structures:generic"], ["trees:other scientific term", "conjunction", "dags:other scientific term"], ["trees:other scientific term", "hyponym of", "structures:generic"]], "368": [["probabilistic context-free grammar:method", "compare", "probabilistic finite automaton:other scientific term"]], "369": [["expert human translation:other scientific term", "compare", "machine translation:other scientific term"]], "370": [["WSD datasets:material", "used for", "second-order vector cooccurrence algorithm:method"], ["topic signatures:other scientific term", "evaluated for", "WSD task:task"]], "371": [["Joint matrix triangularization:task", "used for", "joint eigenstructure:other scientific term"], ["signal processing:task", "conjunction", "machine learning:task"]], "372": [["active sensing devices:other scientific term", "conjunction", "synthetic scenes:other scientific term"], ["active sensing devices:other scientific term", "used for", "task:generic"], ["manual interaction:other scientific term", "conjunction", "active sensing devices:other scientific term"], ["manual interaction:other scientific term", "used for", "task:generic"], ["synthetic scenes:other scientific term", "used for", "task:generic"]], "374": [["joint classification and regression optimization objective:other scientific term", "used for", "network:generic"]], "377": [["Plume's approach:method", "used for", "parsing:task"], ["semantic caseframe instantiation:other scientific term", "used for", "Plume's approach:method"]], "379": [["detection:task", "conjunction", "classification:task"], ["image:material", "used for", "classification:task"], ["image:material", "used for", "detection:task"], ["position:other scientific term", "conjunction", "viewpoint:other scientific term"]], "380": [["IEMOCAP database:material", "used for", "discrete -LRB- categorical -RRB- and continuous -LRB- attribute -RRB- emotional assessments:task"]], "381": [["Cram\u00e9r-Rao lower bound -RRB-:other scientific term", "feature of", "separation method:method"]], "382": [["it:generic", "used for", "active reconstruction systems:task"], ["method:generic", "used for", "scene geometry:other scientific term"], ["subpixel precision:metric", "feature of", "scene geometry:other scientific term"]], "383": [["evaluation techniques:generic", "used for", "human language learning process:task"], ["evaluation techniques:generic", "used for", "machine translation systems:task"], ["evaluation techniques:generic", "used for", "translation process:task"], ["human language learning process:task", "conjunction", "translation process:task"], ["translation process:task", "conjunction", "machine translation systems:task"]], "384": [["hard combinatorial problem:task", "evaluated for", "time complexity:metric"], ["trajectory basis:other scientific term", "used for", "smooth motion:other scientific term"]], "385": [["numerical optimization problem:task", "used for", "visual object tracking:task"]], "386": [["hand-crafted template-based generation component:method", "conjunction", "rule-based sentence planners:method"], ["rule-based sentence planners:method", "conjunction", "baseline sentence planners:method"]], "387": [["Convolutional Neural Networks -LRB- CNN -RRB- architectures:method", "used for", "object recognition:task"], ["Convolutional Neural Networks -LRB- CNN -RRB- architectures:method", "used for", "pose estimation:task"], ["object recognition:task", "conjunction", "pose estimation:task"]], "389": [["PC-KIMMO environment:method", "used for", "description:generic"], ["root word lexicon:material", "used for", "description:generic"]], "390": [["statistical learning:method", "used for", "Fujisaki-model parameters:other scientific term"], ["text input:material", "used for", "Fujisaki-model parameters:other scientific term"]], "391": [["Bayesian inference:method", "used for", "rules:other scientific term"], ["complex tree structures:other scientific term", "used for", "discriminative model's posterior:other scientific term"], ["them:generic", "used for", "complex tree structures:other scientific term"], ["unlabeled corpus:material", "used for", "discriminative model's posterior:other scientific term"]], "392": [["HPSG:other scientific term", "conjunction", "LFG:other scientific term"], ["HPSG:other scientific term", "hyponym of", "grammar formalisms:method"], ["LFG:other scientific term", "hyponym of", "grammar formalisms:method"], ["TAG:other scientific term", "conjunction", "HPSG:other scientific term"], ["TAG:other scientific term", "hyponym of", "grammar formalisms:method"], ["dependency grammars:method", "conjunction", "TAG:other scientific term"], ["dependency grammars:method", "hyponym of", "grammar formalisms:method"], ["formalism:generic", "used for", "grammar formalisms:method"], ["rewriting systems:method", "conjunction", "dependency grammars:method"], ["rewriting systems:method", "hyponym of", "grammar formalisms:method"]], "393": [["first-order autoregressive model:method", "used for", "signals:generic"]], "394": [["compact lexicon:other scientific term", "part of", "treebank:generic"], ["treebank:generic", "compare", "Penn WSJ:material"]], "395": [["framework:generic", "used for", "machine transliteration/backtransliteration:task"], ["machine transliteration/backtransliteration:task", "used for", "direct orthographical mapping -LRB- DOM -RRB-:method"]], "396": [["framework:generic", "used for", "joint source-channel transliteration model:method"], ["n-gram transliteration model -LRB- n-gram TM -RRB-:method", "used for", "transliteration process:method"]], "398": [["Wizard of Oz technique:method", "used for", "NL requirements:other scientific term"], ["Wizard of Oz technique:method", "used for", "task:generic"]], "400": [["motion estimation:task", "conjunction", "object recognition:task"]], "401": [["credibility indicators:other scientific term", "evaluated for", "TREC Blog track test set:material"], ["credibility indicators:other scientific term", "evaluated for", "retrieval effectiveness:metric"]], "402": [["Text Summarisation:task", "hyponym of", "Natural Language Processing -LRB- NLP -RRB- applications:task"], ["Topic signatures:other scientific term", "used for", "Natural Language Processing -LRB- NLP -RRB- applications:task"], ["Topic signatures:other scientific term", "used for", "Text Summarisation:task"], ["Topic signatures:other scientific term", "used for", "Word Sense Disambiguation -LRB- WSD -RRB-:task"], ["Word Sense Disambiguation -LRB- WSD -RRB-:task", "conjunction", "Text Summarisation:task"], ["Word Sense Disambiguation -LRB- WSD -RRB-:task", "hyponym of", "Natural Language Processing -LRB- NLP -RRB- applications:task"]], "403": [["view points:other scientific term", "used for", "approach:generic"]], "404": [["color:other scientific term", "conjunction", "texture:other scientific term"], ["method:method", "used for", "shape constrained image segmentation:task"], ["mixtures of feature distributions:other scientific term", "used for", "color:other scientific term"], ["mixtures of feature distributions:other scientific term", "used for", "method:method"], ["mixtures of feature distributions:other scientific term", "used for", "probabilistic shape knowledge:other scientific term"], ["mixtures of feature distributions:other scientific term", "used for", "texture:other scientific term"], ["texture:other scientific term", "conjunction", "probabilistic shape knowledge:other scientific term"]], "405": [["LR-parser:method", "used for", "CF grammars:method"], ["LR-parser:method", "used for", "Extended CF grammars:method"], ["regular expressions:other scientific term", "feature of", "grammars:method"]], "406": [["Kernel space embedding:other scientific term", "used for", "inarbitrary distance measures:method"]], "408": [["moderate positive sample mining method:method", "used for", "robust CNN:method"], ["robust CNN:method", "used for", "person re-identification:task"]], "409": [["partial scene segmentation:task", "used for", "unsupervised seg-mentation of whole objects:task"], ["soft, binary mattes:other scientific term", "used for", "partial scene segmentation:task"]], "411": [["subwindow search -LRB- ESS -RRB- procedure:method", "part of", "method:generic"]], "412": [["locality-sensitive hashing -LRB- LSH -RRB-:method", "conjunction", "random projection trees:method"], ["locality-sensitive hashing -LRB- LSH -RRB-:method", "hyponym of", "random-projection based methods:method"], ["random projection trees:method", "hyponym of", "random-projection based methods:method"], ["random-projection based methods:method", "used for", "NN search:task"], ["this:generic", "conjunction", "random-projection based methods:method"]], "413": [["dictionary lookup stage:method", "used for", "rules:other scientific term"], ["rules:other scientific term", "used for", "NE items:other scientific term"]], "414": [["model:generic", "used for", "interpretation of compounds:task"]], "415": [["Plume:method", "used for", "interrogatives:other scientific term"], ["Plume:method", "used for", "passives:other scientific term"], ["Plume:method", "used for", "relative clauses:other scientific term"], ["passives:other scientific term", "conjunction", "relative clauses:other scientific term"], ["relative clauses:other scientific term", "conjunction", "interrogatives:other scientific term"]], "416": [["linguistic parser/generator:method", "conjunction", "transfer component:method"], ["linguistic parser/generator:method", "part of", "system:generic"], ["linguistic parser/generator:method", "used for", "LFG:method"], ["maximum-entropy model:method", "used for", "stochastic output selection:task"], ["packed parse forests:other scientific term", "used for", "parse reduction:task"], ["transfer component:method", "conjunction", "maximum-entropy model:method"], ["transfer component:method", "part of", "system:generic"], ["transfer component:method", "used for", "parse reduction:task"]], "417": [["features of entities:other scientific term", "used for", "recovery:task"], ["prior structure:other scientific term", "conjunction", "features of entities:other scientific term"], ["prior structure:other scientific term", "used for", "recovery:task"], ["side information:other scientific term", "used for", "robust PCA:method"]], "419": [["decision-tree classifier:method", "used for", "grammatical relations -LRB- grs -RRB-:other scientific term"]], "420": [["tool:generic", "used for", "linguistic annotation of scfs:task"], ["training and test data:material", "used for", "subcategorization acquisition:task"]], "421": [["visual pathway:method", "used for", "images:material"]], "422": [["conditional random field -LRB- CRF -RRB-:method", "used for", "task:generic"]], "424": [["Online action detection:task", "used for", "action positions:other scientific term"], ["Online action detection:task", "used for", "action type:other scientific term"], ["action type:other scientific term", "conjunction", "action positions:other scientific term"], ["untrimmed stream:material", "used for", "Online action detection:task"]], "425": [["BLEU:metric", "conjunction", "NIST:metric"], ["BLEU:metric", "hyponym of", "MT evaluation methods:metric"], ["MT evaluation methods:metric", "used for", "classifiers:method"], ["NIST:metric", "conjunction", "WER:metric"], ["NIST:metric", "hyponym of", "MT evaluation methods:metric"], ["PER:metric", "hyponym of", "MT evaluation methods:metric"], ["WER:metric", "conjunction", "PER:metric"], ["WER:metric", "hyponym of", "MT evaluation methods:metric"], ["classifiers:method", "used for", "entailment:task"], ["classifiers:method", "used for", "semantic equivalence:task"], ["semantic equivalence:task", "conjunction", "entailment:task"]], "426": [["PER:metric", "used for", "classification method:method"], ["PER:metric", "used for", "part of speech information:other scientific term"], ["part of speech information:other scientific term", "used for", "word matches and non-matches:task"]], "428": [["multinomial distributions:method", "used for", "nucleotides in a DNA sequence:material"], ["multinomial distributions:method", "used for", "text documents:material"]], "429": [["random sampling:method", "used for", "MINPRAN:method"]], "431": [["Plume:method", "used for", "declarative and imperative utterances:material"], ["it:generic", "used for", "interrogatives:other scientific term"], ["it:generic", "used for", "passives:other scientific term"], ["it:generic", "used for", "relative clauses:other scientific term"], ["passives:other scientific term", "conjunction", "relative clauses:other scientific term"], ["relative clauses:other scientific term", "conjunction", "interrogatives:other scientific term"]], "432": [["model:generic", "evaluated for", "accuracy:metric"], ["smoothing:method", "used for", "unlexicalized parser:method"]], "433": [["convex problem:task", "used for", "side information:other scientific term"], ["method:generic", "used for", "low rank matrix:other scientific term"], ["side information:other scientific term", "part of", "robust PCA:method"]], "434": [["convolution kernel over parse trees:method", "evaluated for", "ACE 2003 corpus:material"], ["feature-based methods:method", "compare", "convolution kernel over parse trees:method"]], "435": [["k-means:method", "conjunction", "k-median:method"], ["k-means:method", "hyponym of", "well-studied clustering techniques:method"], ["k-median:method", "hyponym of", "well-studied clustering techniques:method"], ["single-linkage:method", "conjunction", "sum-of-pairs:method"], ["single-linkage:method", "hyponym of", "well-studied clustering techniques:method"], ["sum-of-pairs:method", "conjunction", "k-means:method"], ["sum-of-pairs:method", "hyponym of", "well-studied clustering techniques:method"]], "436": [["cooccurrence statistics:other scientific term", "used for", "disambiguation tool:method"]], "437": [["algorithm:generic", "conjunction", "recursive ascent parsers:other scientific term"], ["algorithm:generic", "used for", "LR -LRB- 0 -RRB- grammars:method"]], "438": [["Criteria:generic", "used for", "anaphora resolution within sentence boundaries:task"], ["GB's binding theory:method", "used for", "Criteria:generic"], ["Grosz-Sidner-style focus model:method", "part of", "those:generic"], ["those:generic", "used for", "text-level anaphora:other scientific term"]], "442": [["acoustic measures:metric", "used for", "two:generic"], ["confidence tests:method", "used for", "UV procedure:method"], ["confidence tests:method", "used for", "hierarchical structure:other scientific term"], ["linguistic information:other scientific term", "used for", "one:generic"], ["one:generic", "hyponym of", "confidence tests:method"], ["two:generic", "hyponym of", "confidence tests:method"]], "443": [["It:generic", "used for", "submanifold:other scientific term"], ["adjacency graph's Laplacian:other scientific term", "feature of", "eigenvectors:other scientific term"], ["cluster number estimation:task", "used for", "It:generic"], ["cluster number estimation:task", "used for", "eigenvectors:other scientific term"], ["eigenvectors:other scientific term", "used for", "It:generic"], ["high dimensionality space:other scientific term", "used for", "submanifold:other scientific term"]], "444": [["algorithm:generic", "evaluated for", "PASCAL VOC 2006 datasets:material"], ["algorithm:generic", "used for", "detection task:task"], ["algorithm:generic", "used for", "viewpoint classification task:task"], ["detection task:task", "conjunction", "viewpoint classification task:task"]], "445": [["method:generic", "used for", "low rank matrices:other scientific term"]], "447": [["convolution tree kernel:method", "used for", "features:generic"]], "448": [["hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers:method", "used for", "detecting sentence boundaries:task"], ["textual and prosodic knowledge sources:material", "used for", "hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers:method"]], "450": [["generative model:method", "used for", "field structured text:material"], ["hidden Markov models -LRB- HMMs -RRB-:method", "used for", "generative model:method"]], "451": [["non-parallel corpus:material", "used for", "MT system:method"], ["parallel corpus:material", "conjunction", "non-parallel corpus:material"], ["parallel corpus:material", "used for", "MT system:method"]], "452": [["memo-functions:method", "used for", "parser:method"], ["parser:method", "evaluated for", "time-complexity:metric"], ["parser:method", "used for", "non-LR grammars:method"]], "454": [["algorithm:generic", "used for", "Fujisaki-model parameters:other scientific term"], ["raw F0 contours:other scientific term", "used for", "Fujisaki-model parameters:other scientific term"], ["remarkable feature:other scientific term", "feature of", "model:generic"], ["statistical methods:method", "used for", "algorithm:generic"]], "455": [["exhaustive procedure:method", "compare", "method:generic"], ["exhaustive procedure:method", "used for", "cascade evaluation:task"], ["method:generic", "used for", "search:task"]], "456": [["method:generic", "evaluated for", "noisy image classification:task"], ["side information:other scientific term", "used for", "method:generic"]], "457": [["bio-inspired model:method", "used for", "analog programmable array processor -LRB- APAP -RRB-:task"], ["bio-inspired model:method", "used for", "complex programmable spatio-temporal dynamics:other scientific term"], ["complex programmable spatio-temporal dynamics:other scientific term", "feature of", "VLSI:task"], ["vertebrate retina:other scientific term", "used for", "bio-inspired model:method"]], "458": [["logical formalism:method", "used for", "determiners:task"]], "459": [["common ground:task", "used for", "human-computer interaction:task"], ["design:generic", "used for", "embodied conversational agents:method"], ["verbal and nonverbal means:method", "used for", "grounding:task"]], "460": [["meaning-entailing substitutability:metric", "evaluated for", "human agreement:metric"], ["meaning-entailing substitutability:metric", "used for", "semantic-oriented NLP applications:task"]], "461": [["distributional word feature vectors:other scientific term", "evaluated for", "semantic criterion:metric"], ["distributional word feature vectors:other scientific term", "used for", "word similarity:task"], ["feature vector quality:metric", "evaluated for", "measure:generic"]], "462": [["approximate joint triangularizer:method", "conjunction", "exact joint triangularizer:method"]], "465": [["convolutional neural networks -LRB- CNN -RRB-:method", "used for", "feature extraction:other scientific term"], ["feature space:other scientific term", "feature of", "highly-curved manifolds:method"], ["highly-curved manifolds:method", "used for", "pedestrian data:material"]], "467": [["Recognition of proper nouns:task", "part of", "morphological analysis:task"], ["morphological analysis:task", "used for", "Japanese text processing:task"]], "468": [["histogram-based interest point detectors:method", "evaluated for", "distinctiveness:metric"], ["histogram-based interest point detectors:method", "evaluated for", "repeatability:metric"], ["histogram-based interest point detectors:method", "used for", "matching textured scenes:task"], ["repeatability:metric", "conjunction", "distinctiveness:metric"]], "469": [["fully automatic recognition system:method", "evaluated for", "video sequences:material"], ["head motion variation:other scientific term", "feature of", "video sequences:material"], ["illumination:other scientific term", "conjunction", "pose:other scientific term"], ["illumination:other scientific term", "feature of", "video sequences:material"], ["method:generic", "used for", "fully automatic recognition system:method"], ["pose:other scientific term", "conjunction", "head motion variation:other scientific term"], ["pose:other scientific term", "feature of", "video sequences:material"]], "471": [["CUHK03 datasets:material", "conjunction", "scale Market-1501:material"], ["CUHK03 datasets:material", "hyponym of", "person re-identification datasets:material"], ["method:generic", "evaluated for", "person re-identification datasets:material"], ["scale Market-1501:material", "hyponym of", "person re-identification datasets:material"]], "472": [["maximization of translation accuracy:metric", "used for", "training method:method"], ["statistical translation model:method", "evaluated for", "NIST evaluation metric:metric"], ["statistical translation model:method", "used for", "phrases:generic"]], "473": [["Euclidean distance:other scientific term", "conjunction", "graphical relationship:other scientific term"], ["Euclidean distance:other scientific term", "used for", "geodesic distance:other scientific term"], ["Euclidean distance:other scientific term", "used for", "manifold learning methods:method"], ["graphical relationship:other scientific term", "used for", "geodesic distance:other scientific term"], ["local range:other scientific term", "feature of", "Euclidean distance:other scientific term"]], "474": [["deep model:method", "compare", "state-of-the-art methods:generic"], ["deep model:method", "used for", "person re-identification:task"], ["robust deep metrics:other scientific term", "used for", "person re-identification:task"], ["state-of-the-art methods:generic", "used for", "person re-identification:task"]], "475": [["Named Entity -LRB- NE -RRB- items:other scientific term", "hyponym of", "proper names, numerical and temporal expressions:other scientific term"], ["Named Entity -LRB- NE -RRB- items:other scientific term", "part of", "Japanese text:material"], ["morphological analyzer:method", "used for", "recognition and classification of proper names, numerical and temporal expressions:task"]], "476": [["histogram-based representations:method", "part of", "detectors:generic"], ["interest point detectors:method", "evaluated for", "pixel-wise differences in image intensity:metric"]], "477": [["projective unifocal, bifo-cal, and trifocal tensors:method", "used for", "affine case:other scientific term"]], "478": [["geometric, appearance, or correlation-based information:other scientific term", "used for", "approaches:generic"]], "479": [["MAP estimation framework:method", "used for", "Multiple Instance Learning -LRB- MIL -RRB- formulation:method"], ["logistic softmax function of covariance-based region features:other scientific term", "used for", "Multiple Instance Learning -LRB- MIL -RRB- formulation:method"]], "480": [["commercial software:method", "conjunction", "methods:generic"], ["system:generic", "compare", "commercial software:method"], ["system:generic", "compare", "methods:generic"], ["system:generic", "evaluated for", "data set:generic"], ["system:generic", "evaluated for", "recognition rate:metric"]], "481": [["expert games:material", "used for", "system:generic"]], "482": [["method:generic", "used for", "raw corpus:material"], ["segmented corpus:material", "used for", "model:generic"], ["word list:other scientific term", "used for", "method:generic"]], "483": [["model:generic", "used for", "on-line handwriting:task"], ["on-line handwriting:task", "part of", "cycloidal pen motion:task"]], "484": [["tagger:method", "evaluated for", "Penn Treebank WSJ:material"], ["tagger:method", "evaluated for", "accuracy:metric"], ["tagger:method", "evaluated for", "error:metric"]], "485": [["smoothing:method", "conjunction", "suffix analysis:method"], ["smoothing:method", "used for", "unlexicalized parser:method"], ["suffix analysis:method", "used for", "unlexicalized parser:method"], ["unlexicalized parser:method", "evaluated for", "NEGRA corpus:material"], ["unlexicalized parser:method", "evaluated for", "labelled bracket F-score:metric"], ["unlexicalized parser:method", "used for", "German:material"]], "486": [["Chinese text:material", "part of", "Web:material"], ["Chinese text:material", "part of", "corpora:generic"], ["corpora:generic", "conjunction", "Web:material"]], "487": [["bibliographic citations:material", "hyponym of", "field structured extraction tasks:task"], ["classified advertisements:material", "conjunction", "bibliographic citations:material"], ["classified advertisements:material", "hyponym of", "field structured extraction tasks:task"], ["prior knowledge:other scientific term", "used for", "field structured extraction tasks:task"]], "488": [["technique:generic", "used for", "search algorithm:method"]], "491": [["intra-class variations:other scientific term", "feature of", "data:generic"]], "492": [["image information:other scientific term", "used for", "3--D shape:other scientific term"], ["priori geometric constraints:other scientific term", "part of", "3--D stereo reconstruction scheme:method"]], "494": [["Noun Classifier Associations -LRB- NCA -RRB-:method", "used for", "classifier assignment:task"], ["Noun Classifier Associations -LRB- NCA -RRB-:method", "used for", "semantic construction of noun phrase:task"], ["classifier assignment:task", "conjunction", "semantic construction of noun phrase:task"], ["corpus-based method:method", "used for", "Noun Classifier Associations -LRB- NCA -RRB-:method"], ["corpus-based method:method", "used for", "classifier assignment:task"], ["corpus-based method:method", "used for", "semantic construction of noun phrase:task"]], "495": [["linguistic information:other scientific term", "used for", "loss functions:other scientific term"], ["parse-trees:other scientific term", "part of", "syntactic structure:other scientific term"], ["syntactic structure:other scientific term", "used for", "loss functions:other scientific term"], ["word-to-word alignments:other scientific term", "part of", "MT system:method"], ["word-to-word alignments:other scientific term", "used for", "loss functions:other scientific term"]], "496": [["automated evaluation techniques:method", "used for", "evaluation of human language learners:task"]], "497": [["features:other scientific term", "feature of", "heuristic principles:method"]], "499": [["matrix rank degeneration:other scientific term", "conjunction", "non-isolated minima:other scientific term"], ["matrix rank degeneration:other scientific term", "feature of", "low-rank matrix optimization:task"], ["non-isolated minima:other scientific term", "feature of", "low-rank matrix optimization:task"], ["or-thonormality:other scientific term", "feature of", "learned matrix:other scientific term"], ["regularizer:method", "used for", "low-rank matrix optimization:task"], ["regularizer:method", "used for", "or-thonormality:other scientific term"]], "500": [["Utterance Verification -LRB- UV -RRB-:method", "hyponym of", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"]], "501": [["low rank part:other scientific term", "conjunction", "sparse residual:other scientific term"], ["low rank part:other scientific term", "part of", "data matrix:other scientific term"], ["robust principal component analysis -LRB- robust PCA -RRB- problem:method", "used for", "machine learning applications:task"], ["sparse residual:other scientific term", "part of", "data matrix:other scientific term"]], "504": [["local optimization:method", "used for", "local mode of the similarity measure:other scientific term"], ["parameter space of translation, rotation and scale:other scientific term", "used for", "local mode of the similarity measure:other scientific term"]], "505": [["Techniques:generic", "used for", "automatically training modules:method"], ["automatically training modules:method", "part of", "natural language generator:method"], ["hand-crafted template-based or rule-based approaches:method", "evaluated for", "utterances:other scientific term"], ["trainable components:method", "compare", "hand-crafted template-based or rule-based approaches:method"], ["trainable components:method", "evaluated for", "utterances:other scientific term"]], "506": [["Confidence tests:method", "used for", "decoded string hypotheses:other scientific term"], ["noises:other scientific term", "conjunction", "OOV words:other scientific term"]], "507": [["contemporary methods:generic", "used for", "unsupervised object discovery:task"]], "508": [["detector:method", "compare", "linear and kernel SVM:method"], ["detector:method", "evaluated for", "real data sets:material"]], "509": [["action model formalism:method", "used for", "methods:metric"], ["action model formalism:method", "used for", "re-active agent:method"], ["noise-handling mechanisms:method", "used for", "methods:metric"]], "511": [["TAGs:method", "used for", "automatic translation of natural language:task"], ["TAGs:method", "used for", "semantic interpretation:task"], ["semantic interpretation:task", "conjunction", "automatic translation of natural language:task"]], "512": [["automatic candidate generation:method", "conjunction", "manual judgement:method"], ["automatic candidate generation:method", "used for", "sentential paraphrases:material"], ["class-oriented framework:method", "used for", "compositional classes of paraphrases:task"], ["class-oriented framework:method", "used for", "paraphrase examples:material"], ["manual judgement:method", "used for", "sentential paraphrases:material"]], "513": [["Kalman filter:method", "part of", "prediction techniques:method"]], "514": [["algorithm:generic", "used for", "eye contact:other scientific term"], ["arbitrary position:other scientific term", "feature of", "virtual camera:other scientific term"], ["cameras:other scientific term", "used for", "video streams:material"], ["virtual camera:other scientific term", "used for", "images:material"]], "515": [["layers of distributed representations:method", "part of", "CNNs:method"], ["layers of distributed representations:method", "used for", "object pose information:other scientific term"], ["this:generic", "compare", "object category representations:method"]], "516": [["natural number recognition task:task", "evaluated for", "recognition errors:metric"], ["natural number recognition task:task", "feature of", "telephone application:task"]], "517": [["approach:generic", "used for", "FERRET:method"], ["approach:generic", "used for", "Q/A:method"]], "520": [["kernel-ized support vector machines:method", "hyponym of", "nonlinear quality functions:other scientific term"], ["method:generic", "used for", "branch-and-bound object detection:task"], ["method:generic", "used for", "cascade evaluation:task"], ["nonlinear quality functions:other scientific term", "used for", "branch-and-bound object detection:task"]], "523": [["labeled data:material", "used for", "semi-supervised methods:method"], ["labeled examples:material", "used for", "supervised methods:method"], ["supervised methods:method", "evaluated for", "accuracies:metric"], ["unlabeled examples:material", "used for", "unsupervised methods:method"], ["unsupervised methods:method", "evaluated for", "accuracies:metric"]], "524": [["deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork:method", "used for", "model:generic"], ["long-range temporal dynamics:other scientific term", "feature of", "model:generic"]], "525": [["LO-English or better a L0-UNL dictionary:material", "conjunction", "morphosyntactic parser of L0:method"], ["LO-English or better a L0-UNL dictionary:material", "hyponym of", "resources:generic"], ["canonical graph2tree transformation:other scientific term", "hyponym of", "resources:generic"], ["morphosyntactic parser of L0:method", "conjunction", "canonical graph2tree transformation:other scientific term"], ["morphosyntactic parser of L0:method", "hyponym of", "resources:generic"], ["resources:generic", "used for", "liaisons:other scientific term"]], "526": [["components:generic", "used for", "intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-:task"], ["disambiguated morphological analysis:method", "conjunction", "lemmatized indexing:method"], ["disambiguated morphological analysis:method", "hyponym of", "components:generic"], ["disambiguated morphological analysis:method", "used for", "aligned bilingual corpus:material"], ["lemmatized indexing:method", "hyponym of", "components:generic"], ["lemmatized indexing:method", "used for", "aligned bilingual corpus:material"]], "527": [["unified framework:method", "used for", "reasoning:task"]], "528": [["SLIPPER:generic", "hyponym of", "rule-based learning algorithm:method"], ["TiMBL:generic", "hyponym of", "memory-based system:method"], ["memory-based system:method", "part of", "machine learning algorithms:method"], ["rule-based learning algorithm:method", "compare", "memory-based system:method"], ["rule-based learning algorithm:method", "part of", "machine learning algorithms:method"]], "530": [["compact geometric derivation:other scientific term", "used for", "novel-view synthesis:task"], ["dense-stereo dynamic-programming:method", "used for", "occlusion labeling:task"], ["direct projection of the minimum-cost surface:method", "used for", "compact geometric derivation:other scientific term"]], "531": [["Adaptive Simulated Annealing -LRB- ASA -RRB-:method", "used for", "it:generic"], ["global optimization problem:task", "used for", "object detection:task"], ["method:generic", "compare", "exhaustive search:method"]], "532": [["algorithm:generic", "used for", "rendering of occlusions:task"], ["algorithm:generic", "used for", "temporal artefacts -LRB- flicker -RRB-:other scientific term"], ["algorithm:generic", "used for", "temporal maintenance of a background model:task"], ["cost aggregation algorithm:method", "conjunction", "algorithm:generic"], ["cost aggregation algorithm:method", "used for", "three-dimensional matching cost space:other scientific term"]], "533": [["categorization of objects:task", "conjunction", "estimating object pose:task"], ["categorization of objects:task", "part of", "Object Recognition task:task"], ["estimating object pose:task", "part of", "Object Recognition task:task"], ["representation:generic", "used for", "latter:generic"], ["representation:generic", "used for", "pose information:other scientific term"], ["view-invariant representation:method", "used for", "former:generic"]], "534": [["information:generic", "used for", "robust PCA:method"], ["low rank plus sparse structure:other scientific term", "used for", "approaches:generic"]], "536": [["CRF model:method", "compare", "HMM and Max-ent models:method"], ["CRF model:method", "evaluated for", "NIST sentence boundary detection task:material"], ["CRF model:method", "evaluated for", "error rate:metric"], ["HMM and Max-ent models:method", "evaluated for", "NIST sentence boundary detection task:material"], ["HMM and Max-ent models:method", "evaluated for", "error rate:metric"], ["classifiers:method", "used for", "three-way voting:method"], ["speech:material", "feature of", "NIST sentence boundary detection task:material"]], "537": [["lighting:other scientific term", "conjunction", "pose:other scientific term"], ["pose:other scientific term", "conjunction", "user motion pattern:other scientific term"], ["resolution:metric", "feature of", "face images:material"]], "538": [["UNL-tree + L0:other scientific term", "conjunction", "MS-L0 structure:other scientific term"], ["dictionary:material", "used for", "lattice:other scientific term"]], "540": [["approach:generic", "used for", "learned confidence measures:method"], ["automatically generated training data:material", "used for", "them:generic"], ["laser ground truth data:material", "compare", "automatically generated training data:material"], ["learned confidence measures:method", "evaluated for", "KITTI2012 dataset:material"]], "541": [["Bayesian inference techniques:method", "used for", "Gaussian models:method"], ["P\u00f3lya-gamma augmentation:task", "used for", "multinomial distribution:method"], ["jointly Gaussian likelihoods:other scientific term", "feature of", "latent variables:other scientific term"], ["latent variables:other scientific term", "part of", "multinomial distribution:method"], ["logistic stick-breaking representation:method", "used for", "multinomial distribution:method"], ["minimal overhead:other scientific term", "feature of", "Gaussian models:method"]], "542": [["Multi-view constraints:other scientific term", "conjunction", "normalized representation:method"], ["Multi-view constraints:other scientific term", "used for", "matching:task"], ["Multi-view constraints:other scientific term", "used for", "reconstruction:task"], ["images:material", "used for", "acquisition of true three-dimensional affine and Euclidean models:task"], ["matching:task", "conjunction", "reconstruction:task"], ["normalized representation:method", "used for", "matching:task"], ["normalized representation:method", "used for", "reconstruction:task"]], "543": [["TAGs:method", "used for", "syntax proper:other scientific term"], ["logical form language:other scientific term", "used for", "semantics:other scientific term"]], "544": [["automatic speech recognition -LRB- ASR -RRB-:method", "used for", "offset adaptation -LRB- OA -RRB- model:method"], ["pool models:method", "used for", "inner hair cell synapse:other scientific term"], ["visual inspection:method", "conjunction", "automatic speech recognition -LRB- ASR -RRB-:method"], ["visual inspection:method", "used for", "offset adaptation -LRB- OA -RRB- model:method"]], "546": [["attentional state:other scientific term", "part of", "components:generic"], ["components:generic", "part of", "discourse structure:other scientific term"], ["intentional structure:other scientific term", "conjunction", "attentional state:other scientific term"], ["intentional structure:other scientific term", "part of", "components:generic"], ["linguistic structure:other scientific term", "conjunction", "intentional structure:other scientific term"], ["linguistic structure:other scientific term", "part of", "components:generic"]], "547": [["sentence extraction:method", "used for", "summarization:task"]], "548": [["pattern extraction scheme:method", "conjunction", "Bayesian learning algorithm:method"]], "549": [["dependency network representation:method", "used for", "tag contexts:other scientific term"], ["fine-grained modeling of unknown word features:method", "used for", "part-of-speech tagger:method"], ["lexical features:other scientific term", "used for", "part-of-speech tagger:method"], ["priors in conditional loglinear models:other scientific term", "used for", "part-of-speech tagger:method"], ["tag contexts:other scientific term", "used for", "part-of-speech tagger:method"]], "550": [["face motion patterns:other scientific term", "feature of", "robustness:metric"], ["face motion patterns:other scientific term", "part of", "video:material"], ["geodesically local appearance manifold structure:other scientific term", "conjunction", "robust same-identity likelihood:method"], ["photometric model:method", "conjunction", "statistical model:method"], ["photometric model:method", "used for", "image formation:task"], ["smoothness:other scientific term", "feature of", "geodesically local appearance manifold structure:other scientific term"], ["statistical model:method", "used for", "extreme illumination changes:other scientific term"], ["statistical model:method", "used for", "generic face appearance variation:task"], ["video sequence\" reillumination\" algorithm:method", "evaluated for", "robustness:metric"]]}, "false_cases": {"1": [["misunderstandings:other scientific term", "hyponym of", "miscommunication:other scientific term"]], "3": [["Language resource quality:other scientific term", "feature of", "NLP:other scientific term"]], "5": [["ambiguity:other scientific term", "part of", "problem:task"], ["determiners:other scientific term", "part of", "problem:task"]], "7": [["advantages:other scientific term", "feature of", "our method:method"]], "10": [["Plume:material", "hyponym of", "restricted domain parser:method"]], "11": [["part:generic", "hyponym of", "collection of salient image features:other scientific term"]], "13": [["cameras:other scientific term", "part of", "affine projection:method"]], "15": [["Translations:material", "used for", "beam-search decoder:method"]], "20": [["new view:other scientific term", "part of", "paper:generic"], ["new view:other scientific term", "used for", "extensional reference:other scientific term"]], "21": [["Combination methods:method", "used for", "system performance:metric"]], "23": [["freely translating virtual camera:other scientific term", "used for", "synthesis:task"]], "24": [["weak equivalence:other scientific term", "compare", "two formalisms:other scientific term"]], "26": [["deep learning methods:method", "used for", "task:generic"]], "27": [["background modeling:method", "part of", "vision systems:other scientific term"], ["component:generic", "feature of", "background modeling:method"]], "29": [["automatically acquiring English topic signatures:task", "used for", "novel approach:method"]], "31": [["unsupervised WSD:task", "used for", "system combination:method"]], "33": [["Manual acquisition:task", "used for", "broad domains:other scientific term"], ["Manual acquisition:task", "used for", "semantic constraints:other scientific term"]], "34": [["It:generic", "feature of", "recursive descent parser:method"]], "35": [["dependencies:other scientific term", "feature of", "Dirichlet-multinomial formulation:method"]], "36": [["resources:material", "used for", "validation:task"]], "38": [["utility:metric", "feature of", "proposed approach:method"]], "39": [["method:generic", "used for", "histogram information:other scientific term"], ["method:generic", "used for", "interest points:other scientific term"]], "40": [["near-Bernoulli statistics:other scientific term", "feature of", "random modulation scheme:method"]], "42": [["statistical machine translation:task", "used for", "Minimum Bayes-Risk -LRB- MBR -RRB-:method"]], "44": [["evaluation criterion:metric", "used for", "word similarity measures:method"]], "47": [["demonstrations:generic", "used for", "synthesis of cyclopean views:method"]], "48": [["estimates:metric", "part of", "higher one:generic"], ["estimates:metric", "part of", "lower one:generic"], ["higher one:generic", "compare", "lower one:generic"]], "49": [["complex range and intensity data:material", "used for", "MINPRAN:method"]], "51": [["phrases:other scientific term", "used for", "method:generic"], ["word-aligned corpora:material", "part of", "method:generic"]], "52": [["novel features:other scientific term", "feature of", "MLPs:method"]], "53": [["NE items:other scientific term", "used for", "dictionary lookup:method"], ["NE items:other scientific term", "used for", "rule application:method"]], "55": [["application:task", "part of", "LCS-Marine:method"], ["application:task", "part of", "this approach:method"], ["this approach:method", "used for", "LCS-Marine:method"]], "56": [["practical feasibility:other scientific term", "feature of", "our algorithm:method"]], "57": [["Machine transliteration/back-transliteration:method", "used for", "multilingual speech and language applications:task"]], "58": [["Design challenges:other scientific term", "part of", "this paper:generic"], ["experimental results:other scientific term", "part of", "this paper:generic"], ["trade-offs:other scientific term", "part of", "this paper:generic"]], "59": [["performance:metric", "feature of", "Chinese-to-English translation task:task"]], "61": [["bare slice disambiguation:task", "used for", "dialogue:other scientific term"]], "64": [["strong detector:method", "used for", "weak detectors:method"]], "66": [["method:generic", "used for", "incremental probabilistic parser:method"]], "67": [["rhetorical moves of argumentation:other scientific term", "part of", "scheme:generic"], ["seven categories:other scientific term", "part of", "scheme:generic"]], "68": [["novel view generation:task", "part of", "algorithm:method"]], "70": [["word spotting:task", "used for", "matching of cursive scripts:task"]], "72": [["new paradigm:other scientific term", "part of", "Listen-Communicate-Show -LRB- LCS -RRB-:method"]], "73": [["classifier word:other scientific term", "used for", "algorithm:method"], ["classifier word:other scientific term", "used for", "noun:other scientific term"]], "74": [["piecewise stationary:other scientific term", "hyponym of", "signals:other scientific term"]], "75": [["event elements:other scientific term", "used for", "this paper:generic"], ["event terms:other scientific term", "used for", "this paper:generic"], ["events:other scientific term", "used for", "this paper:generic"]], "81": [["ooce domains:other scientific term", "part of", "integrated learning system:method"]], "83": [["Prolog:material", "part of", "programming language:other scientific term"], ["Prolog:material", "part of", "system:generic"], ["programming language:other scientific term", "part of", "system:generic"]], "84": [["statistics:material", "part of", "scheme:method"]], "85": [["parallel sentences:other scientific term", "used for", "method:generic"]], "86": [["theory:other scientific term", "feature of", "framework:method"], ["theory:other scientific term", "used for", "discourse:other scientific term"], ["theory:other scientific term", "used for", "processing of utterances:task"]], "87": [["linguistic expressiveness:other scientific term", "compare", "two formalisms:other scientific term"]], "89": [["resulting learning problem:task", "used for", "scalable stochastic gradient descent algorithm:method"]], "90": [["efficient non-linear extension of WARCA:method", "used for", "kernel trick:method"]], "91": [["on-line cursive handwriting analysis:task", "evaluated for", "recognition:task"], ["on-line cursive handwriting analysis:task", "part of", "model-based approach:method"]], "93": [["densely sampled rays:other scientific term", "part of", "image-based representations:other scientific term"]], "94": [["foreign language:other scientific term", "used for", "learning to read:task"], ["foreign language:other scientific term", "used for", "reading:task"], ["reading:task", "part of", "learning to read:task"]], "96": [["segment:task", "used for", "tag:task"]], "97": [["nominal compounds:other scientific term", "part of", "domain independent model:method"], ["nominal compounds:other scientific term", "used for", "automated interpretation:task"]], "99": [["blind separation of natural speech signals:task", "part of", "model:method"], ["natural speech signals:other scientific term", "used for", "blind separation of natural speech signals:task"]], "100": [["English/Chinese:material", "evaluated for", "transliteration/backtransliteration experiments:task"], ["English/Japanese:material", "evaluated for", "transliteration/backtransliteration experiments:task"]], "102": [["sampling probabilities:metric", "used for", "specialized regression problem:task"]], "104": [["Branch and bound strategies:method", "used for", "global optimality:other scientific term"]], "105": [["textual credibility indicators:other scientific term", "used for", "retrieval process:method"], ["topical blog post retrieval:task", "part of", "retrieval process:method"]], "108": [["learned confidence measures:other scientific term", "used for", "outlier removal:task"], ["learned confidence measures:other scientific term", "used for", "quality improvement:task"], ["learned confidence measures:other scientific term", "used for", "stereo vision:other scientific term"]], "110": [["annotations:material", "part of", "large streaming video dataset:material"], ["large streaming video dataset:material", "evaluated for", "model:method"]], "111": [["English:material", "used for", "translation direction:other scientific term"], ["German:material", "used for", "translation direction:other scientific term"]], "112": [["correctness proof:other scientific term", "part of", "purely functional implementation:method"]], "113": [["segments of the discourse:other scientific term", "hyponym of", "linguistic structure:other scientific term"], ["utterances:other scientific term", "part of", "linguistic structure:other scientific term"]], "114": [["complete cursive handwriting recognition:task", "used for", "dynamic representation:method"]], "116": [["mattes:other scientific term", "part of", "scene:other scientific term"], ["set of hypothesized object boundary fragments:other scientific term", "part of", "scene:other scientific term"]], "118": [["request:generic", "used for", "mobile intelligent agent:method"]], "119": [["extension:generic", "used for", "space-time interest point detection:method"]], "121": [["coherent ensemble of parts:other scientific term", "part of", "Objects:generic"]], "122": [["3D object categorization:task", "used for", "generative probabilistic framework:method"]], "123": [["hypothesis:other scientific term", "part of", "analysis:method"]], "126": [["model:other scientific term", "used for", "modeling the knowledge sources:task"]], "129": [["goal:generic", "part of", "work:generic"], ["human-machine interactions:other scientific term", "used for", "enrichment:task"]], "130": [["easily adaptable:generic", "feature of", "Chat-80:method"], ["variety of applications:task", "used for", "Chat-80:method"]], "131": [["technique:method", "used for", "stereo algorithm:method"]], "132": [["cooccurrence patterns:other scientific term", "part of", "large corpus:material"]], "133": [["compact representation:other scientific term", "feature of", "parse forest:other scientific term"], ["compact representation:other scientific term", "used for", "Memo-functions:method"]], "136": [["correspondences between languages:other scientific term", "feature of", "synchronous TAGs:method"], ["correspondences between languages:other scientific term", "part of", "variant of TAGs:method"]], "140": [["exceptions:other scientific term", "part of", "phonological and morphological rules:other scientific term"], ["special cases:other scientific term", "part of", "phonological and morphological rules:other scientific term"]], "142": [["proposed approach:method", "used for", "cluttered scenes:other scientific term"], ["segmentation stage:other scientific term", "part of", "proposed approach:method"]], "144": [["spectral clustering based approach:method", "compare", "other clustering methods:method"]], "145": [["hard problem:other scientific term", "part of", "perception of transparent objects:task"], ["images:material", "part of", "vision:other scientific term"], ["perception of transparent objects:task", "hyponym of", "hard problem:other scientific term"], ["perception of transparent objects:task", "part of", "vision:other scientific term"]], "146": [["transparent objects:other scientific term", "used for", "this paper:generic"]], "147": [["promising results:metric", "used for", "detection:task"], ["promising results:metric", "used for", "viewpoint classification:task"]], "148": [["Turkish:material", "hyponym of", "agglutinating free word order language:other scientific term"]], "149": [["small number of training examples:material", "used for", "object detection:task"]], "152": [["attentional focus:other scientific term", "used for", "direction-giving task:task"], ["eye gaze:other scientific term", "used for", "direction-giving task:task"], ["head nods:other scientific term", "used for", "direction-giving task:task"]], "154": [["four-participants face-to-face meetings:material", "used for", "addressee identification:task"]], "155": [["distribution:other scientific term", "used for", "applications:task"]], "157": [["Chat-80:material", "part of", "prototype natural language question answering system:method"]], "158": [["well-segmented 3D skeleton data:material", "part of", "Human action recognition:task"]], "160": [["MINPRAN's properties:other scientific term", "compare", "least median of squares:other scientific term"]], "162": [["English-Bulgarian:material", "part of", "four language pairs:generic"], ["English-Estonian:material", "part of", "four language pairs:generic"], ["English-Hungarian:material", "part of", "four language pairs:generic"], ["French-Dutch:material", "part of", "four language pairs:generic"]], "163": [["UNIX:material", "part of", "program:generic"], ["Windows '95:material", "part of", "program:generic"]], "164": [["Euclidean distance:metric", "feature of", "deep embedding methods:method"], ["training:task", "feature of", "deep embedding methods:method"], ["training:task", "used for", "test:task"]], "165": [["proposed approach:method", "used for", "recent advances:generic"]], "166": [["high-quality data:material", "used for", "automatic evaluations:task"], ["human translations:other scientific term", "compare", "automatic translations:other scientific term"]], "168": [["modeling and subtraction of such scenes:task", "used for", "new method:method"]], "169": [["nearest neighbor -LRB- NN -RRB-:other scientific term", "used for", "Fast algorithms:method"]], "170": [["reconstruction process:task", "part of", "constrained optimization scheme:method"], ["structural or numerical constraints:other scientific term", "used for", "constrained optimization scheme:method"], ["structural or numerical constraints:other scientific term", "used for", "reconstruction process:task"]], "173": [["Pustejovsky's principles:other scientific term", "used for", "predicative information:other scientific term"]], "176": [["different refractive indices:other scientific term", "part of", "multiple layers:other scientific term"], ["multiple layers:other scientific term", "part of", "objects:other scientific term"]], "177": [["important contents:other scientific term", "part of", "event map:other scientific term"], ["relevant approach:method", "used for", "PageRank algorithm:method"]], "178": [["expected loss of translation errors:metric", "part of", "statistical approach:method"], ["expected loss of translation errors:metric", "used for", "translation performance:metric"], ["loss functions:other scientific term", "part of", "statistical approach:method"]], "179": [["specific loss functions:other scientific term", "used for", "MBR decoding:method"]], "181": [["MT output:material", "used for", "first experiment:task"], ["first experiment:task", "part of", "series of experiments:task"], ["intelligibility:other scientific term", "part of", "series of experiments:task"]], "183": [["probability distribution:other scientific term", "used for", "legal moves:other scientific term"]], "186": [["experimental results:other scientific term", "feature of", "our scheme:method"], ["our dataset:material", "part of", "our scheme:method"], ["promising performance:metric", "feature of", "our scheme:method"], ["public G3D dataset:material", "part of", "our scheme:method"]], "189": [["sentence-level and text-level anaphora:other scientific term", "feature of", "dependency-based grammar model:method"], ["sentence-level and text-level anaphora:other scientific term", "part of", "unified account:method"], ["unified account:method", "feature of", "dependency-based grammar model:method"]], "190": [["raw corpus:material", "part of", "language model adaptation methods:method"], ["word list:material", "part of", "language model adaptation methods:method"]], "191": [["discrete data:material", "feature of", "modeling problems:task"], ["multinomial or categorical distributions:other scientific term", "feature of", "modeling problems:task"]], "192": [["cycloidal motion parameters:other scientific term", "feature of", "general procedure:method"], ["cycloidal motion parameters:other scientific term", "used for", "arbitrary handwriting:other scientific term"]], "194": [["camera view:other scientific term", "feature of", "Person re-identification:task"], ["illumination:other scientific term", "feature of", "Person re-identification:task"], ["occlusion:other scientific term", "feature of", "Person re-identification:task"], ["pose:other scientific term", "feature of", "Person re-identification:task"]], "195": [["parameter training algorithm:method", "used for", "decision tree-based context clustering:method"]], "196": [["NCA:other scientific term", "part of", "large corpus:material"], ["large corpus:material", "used for", "NCA:other scientific term"]], "197": [["single image:material", "part of", "scene:other scientific term"]], "198": [["poses:other scientific term", "used for", "model-based approach:method"], ["shapes:other scientific term", "used for", "model-based approach:method"]], "199": [["parse trees:other scientific term", "used for", "relation extraction:task"], ["parse trees:other scientific term", "used for", "syntactic structure information:other scientific term"]], "200": [["results:generic", "compare", "state of the art methods:method"]], "203": [["task dialogues:material", "part of", "prototype Natural Language system:method"]], "204": [["100 words:metric", "used for", "language learning experiment:task"]], "205": [["machine translation output:material", "used for", "duplicating the experiment:task"]], "206": [["feature points:other scientific term", "used for", "automated technique:method"], ["motion trajectories:other scientific term", "used for", "automated technique:method"], ["reflections:other scientific term", "used for", "automated technique:method"]], "207": [["Monte Carlo approach:method", "compare", "ASA:method"]], "209": [["non-contiguous phrases:other scientific term", "feature of", "phrases with gaps:other scientific term"], ["non-contiguous phrases:other scientific term", "part of", "phrase-based statistical machine translation method:method"]], "211": [["data-dependent bandwidth:method", "used for", "density estimation:method"]], "212": [["document retrieval:task", "part of", "approach:generic"], ["information extraction annotations:other scientific term", "part of", "approach:generic"], ["information extraction annotations:other scientific term", "used for", "document retrieval:task"]], "213": [["affine-invariant image patches:other scientific term", "hyponym of", "three-dimensional objects:other scientific term"], ["affine-invariant image patches:other scientific term", "part of", "representation:method"], ["spatial relationships:other scientific term", "part of", "representation:method"], ["three-dimensional objects:other scientific term", "part of", "representation:method"]], "215": [["3--D surface mesh:material", "part of", "iterative deformation:method"], ["approach:generic", "used for", "iterative deformation:method"], ["objective function:other scientific term", "part of", "iterative deformation:method"]], "217": [["binary-binary partial matrix-vector multiplication:task", "part of", "externally digital architecture:method"], ["externally digital architecture:method", "part of", "analog array:method"], ["high-density:metric", "part of", "externally digital architecture:method"]], "219": [["simple prior:other scientific term", "used for", "support vector machines:method"]], "220": [["ECA:method", "used for", "verbal and nonverbal grounding acts:method"]], "222": [["standard stratified sampling:method", "compare", "uniform sampling:method"]], "223": [["given topic:other scientific term", "used for", "topical blog post retrieval:task"], ["relevance:metric", "feature of", "topical blog post retrieval:task"]], "224": [["indicators:other scientific term", "used for", "retrieval approach:method"]], "225": [["models:method", "compare", "priming of rules:method"]], "226": [["robustness requirement:other scientific term", "feature of", "image understanding:task"]], "229": [["action type:other scientific term", "part of", "multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method"], ["temporal localization information:other scientific term", "part of", "multi-task end-to-end Joint Classification-Regression Recurrent Neural Network:method"]], "230": [["machine translation -LRB- MT -RRB-:task", "conjunction", "sentence-level semantic equivalence classification:task"]], "232": [["subjective human judgments:metric", "used for", "spoken dialogue system:method"], ["subjective human judgments:metric", "used for", "trainable sentence planner:method"], ["trainable sentence planner:method", "part of", "spoken dialogue system:method"]], "233": [["method:generic", "used for", "language pairs:other scientific term"]], "237": [["distribution:other scientific term", "compare", "geodesic distance:other scientific term"]], "238": [["ASR system:method", "feature of", "Noise Spotting:task"], ["ASR system:method", "feature of", "Word Spotting:task"], ["Noise Spotting:task", "part of", "ASR system:method"], ["Word Spotting:task", "part of", "ASR system:method"]], "239": [["large datasets:material", "part of", "creating:task"], ["pixel-level labels:other scientific term", "used for", "creating:task"]], "240": [["Turkish:material", "hyponym of", "agglutinative language:other scientific term"]], "241": [["surface realizations:other scientific term", "feature of", "morphological constructions:other scientific term"]], "242": [["persistent dynamic behavior:other scientific term", "part of", "scene:other scientific term"]], "243": [["speech syntax:other scientific term", "hyponym of", "weakly supervised dependency parser:method"], ["weakly supervised dependency parser:method", "feature of", "speech syntax:other scientific term"]], "245": [["high accuracy:metric", "feature of", "shapes of the objects:other scientific term"], ["it:generic", "part of", "real scenes:material"]], "246": [["appearance information:other scientific term", "feature of", "probabilistic framework:method"], ["appearance information:other scientific term", "part of", "visual models of 3D object categories:method"], ["geometric constraints:other scientific term", "part of", "probabilistic framework:method"], ["probabilistic framework:method", "used for", "visual models of 3D object categories:method"]], "247": [["summarization quality:metric", "evaluated for", "sentence condensation systems:task"]], "248": [["method:generic", "used for", "natural speech signals:material"], ["separation accuracy:metric", "feature of", "method:generic"]], "249": [["our method:method", "compare", "previous two dependency tree kernels:method"]], "251": [["66% recall rate:metric", "feature of", "scf types:other scientific term"], ["70% precision:metric", "feature of", "scf types:other scientific term"], ["experiments:generic", "part of", "system:generic"], ["scf types:other scientific term", "part of", "experiments:generic"], ["scf types:other scientific term", "part of", "system:generic"]], "252": [["our approach:method", "compare", "state-of-the-art approaches:method"]], "253": [["critical discussion:task", "feature of", "various approaches:method"], ["critical discussion:task", "used for", "evaluation of Natural Language systems:task"], ["evaluation of Natural Language systems:task", "part of", "various approaches:method"]], "254": [["board game of Go:material", "part of", "problem:task"], ["game records of expert players:material", "part of", "problem:task"], ["game records of expert players:material", "used for", "learning to predict moves:task"]], "255": [["better training resources:material", "used for", "robust automatic abstracting systems:task"]], "257": [["airborne videos:material", "feature of", "numerical hybrid local and global mode-seeking tracker:method"], ["heavy occlusion:other scientific term", "feature of", "numerical hybrid local and global mode-seeking tracker:method"], ["large camera motions:other scientific term", "feature of", "numerical hybrid local and global mode-seeking tracker:method"]], "259": [["statistics:other scientific term", "used for", "anaphora references:other scientific term"], ["statistics:other scientific term", "used for", "semantic constraints:other scientific term"], ["statistics:other scientific term", "used for", "syntactic ambiguities:other scientific term"]], "260": [["discourse:other scientific term", "used for", "this paper:generic"], ["new theory of discourse structure:other scientific term", "part of", "discourse:other scientific term"], ["new theory of discourse structure:other scientific term", "used for", "this paper:generic"], ["role of purpose and processing:other scientific term", "used for", "this paper:generic"]], "261": [["discourse-relevant purposes:other scientific term", "part of", "intentional structure:other scientific term"]], "263": [["central goal:generic", "part of", "research:generic"]], "264": [["person re-identification:task", "used for", "study:generic"], ["study:generic", "used for", "deep models:method"]], "265": [["analog pressure wave:other scientific term", "used for", "discrete nerve-action potentials:other scientific term"], ["analog pressure wave:other scientific term", "used for", "encoding sound:task"], ["analog pressure wave:other scientific term", "used for", "neuronal processing:task"], ["discrete nerve-action potentials:other scientific term", "used for", "encoding sound:task"], ["discrete nerve-action potentials:other scientific term", "used for", "neuronal processing:task"]], "266": [["multiple segmentations:task", "used for", "image:material"]], "268": [["full digital resolution:metric", "feature of", "low-resolution analog-to-digital conversion:other scientific term"], ["low-resolution analog-to-digital conversion:other scientific term", "used for", "analog summation of binary products:other scientific term"]], "270": [["generative framework:method", "used for", "model:method"]], "272": [["English corpus data:material", "used for", "novel system:method"], ["adjectival subcategorization frames -LRB- scfs -RRB-:other scientific term", "used for", "novel system:method"], ["frequency information:other scientific term", "used for", "novel system:method"]], "274": [["broadcast news speech:material", "part of", "two corpora:material"], ["conversational telephone speech:material", "part of", "broadcast news speech:material"], ["conversational telephone speech:material", "part of", "two corpora:material"], ["human transcriptions:material", "part of", "two corpora:material"]], "275": [["accurately:metric", "used for", "evaluating aggregate queries:task"], ["efficiently:metric", "used for", "evaluating aggregate queries:task"], ["evaluating aggregate queries:task", "part of", "goal:generic"], ["small set of records:material", "part of", "evaluating aggregate queries:task"], ["small set of records:material", "part of", "goal:generic"]], "276": [["Kullback-Leibler distance:other scientific term", "part of", "closed-form -LRB- analytical -RRB- solution:method"], ["cross-entropy:other scientific term", "part of", "closed-form -LRB- analytical -RRB- solution:method"]], "277": [["feature weighting and selection function:method", "used for", "word similarity performance:metric"], ["superior feature vectors:metric", "feature of", "word similarity performance:metric"], ["superior feature vectors:metric", "part of", "feature weighting and selection function:method"]], "280": [["useful features:other scientific term", "feature of", "MT evaluation techniques:method"], ["useful features:other scientific term", "used for", "paraphrase classification:task"]], "281": [["corpus:material", "part of", "experiment:task"], ["experiment:task", "used for", "references of the pronoun 'it':task"], ["sentences:material", "part of", "corpus:material"], ["sentences:material", "part of", "experiment:task"], ["sentences:material", "part of", "references of the pronoun 'it':task"]], "282": [["quality:metric", "evaluated for", "extracted data:material"]], "283": [["and aggregation of utterances:other scientific term", "part of", "paper:generic"], ["example discourses:material", "part of", "paper:generic"]], "284": [["method:generic", "used for", "application:task"]], "287": [["continuous pen motion:other scientific term", "feature of", "discrete motor control representation:method"], ["discrete motor control representation:method", "part of", "result:generic"], ["quantized levels of the model parameters:other scientific term", "part of", "discrete motor control representation:method"]], "288": [["Web:material", "used for", "exploring and harvesting English-Chinese bitexts:task"], ["exploring and harvesting English-Chinese bitexts:task", "part of", "piece of work:generic"], ["piece of work:generic", "used for", "foundation:generic"]], "289": [["geometric structures of 3D lines:other scientific term", "used for", "light field triangulation:task"], ["geometric structures of 3D lines:other scientific term", "used for", "ray space:other scientific term"], ["geometric structures of 3D lines:other scientific term", "used for", "stereo matching:task"]], "290": [["ray space:other scientific term", "used for", "triangulation problem:task"]], "292": [["approach:generic", "used for", "pixel-accurate semantic label maps:method"]], "294": [["capability:generic", "feature of", "technology:generic"], ["field exercises:material", "part of", "applications:task"]], "295": [["ambiguity packing:method", "used for", "stochastic disambiguation techniques:method"]], "297": [["dense sub-pixel camera-projector correspondence:other scientific term", "feature of", "scanning method:method"]], "298": [["result:generic", "used for", "probabilistic finite automata:method"]], "299": [["2D point correspondences:material", "used for", "reconstructing the motion of a 3D articulated tree:task"], ["temporal prior:other scientific term", "used for", "reconstructing the motion of a 3D articulated tree:task"]], "300": [["particular concept:other scientific term", "feature of", "topic signature:other scientific term"]], "301": [["domain-specific models of actions:method", "used for", "planning systems:method"]], "302": [["training instances:material", "part of", "action models:method"], ["variant of GOLEM:method", "used for", "action models:method"]], "303": [["semantically meaningful parts:other scientific term", "used for", "automated segmentation:task"], ["shape information:other scientific term", "used for", "automated segmentation:task"]], "304": [["statistical machine translation -LRB- MT -RRB-:other scientific term", "part of", "search procedure:method"], ["this paper:generic", "used for", "dynamic programming -LRB- DP -RRB-:method"], ["this paper:generic", "used for", "search procedure:method"]], "305": [["experimental tests:task", "used for", "limited-domain spoken-language task:task"]], "306": [["cue phrases:other scientific term", "feature of", "properties of discourse:other scientific term"]], "311": [["learned metric:other scientific term", "used for", "learning:task"], ["learned metric:other scientific term", "used for", "metric weight constraint:method"], ["metric weight constraint:method", "part of", "learning:task"]], "312": [["Turkish word structures:other scientific term", "part of", "full scale two-level morphological description:method"], ["full scale two-level morphological description:method", "part of", "poster paper:generic"]], "313": [["acceleration:metric", "used for", "our method:method"]], "314": [["approach:generic", "used for", "explicit and exactly distance-preserving embedding:method"], ["explicit and exactly distance-preserving embedding:method", "part of", "approach:generic"]], "315": [["LSH:other scientific term", "feature of", "methodology:method"]], "316": [["satisfactory reconstruction results:metric", "feature of", "triangulations:other scientific term"], ["satisfactory reconstruction results:metric", "used for", "anisotropic meshing:method"]], "317": [["morpho-syntactic:other scientific term", "used for", "productive rules of interpretation:task"], ["nominal constituents:other scientific term", "used for", "productive rules of interpretation:task"], ["semantic characteristics:other scientific term", "used for", "productive rules of interpretation:task"]], "318": [["very high dimensions:other scientific term", "part of", "high-resolution parallel inner-product computation:task"]], "320": [["blind separation of underdetermined instantaneous mixtures of independent signals:task", "used for", "method:generic"], ["nonstationarity of the original signals:other scientific term", "feature of", "blind separation of underdetermined instantaneous mixtures of independent signals:task"], ["nonstationarity of the original signals:other scientific term", "used for", "method:generic"]], "321": [["question-answer pairs:other scientific term", "used for", "email summarization:task"], ["this paper:generic", "part of", "our work:generic"]], "322": [["objects:other scientific term", "used for", "camera handoff:task"]], "323": [["data retrieval:task", "used for", "task:generic"]], "325": [["factors:other scientific term", "part of", "experiment:task"], ["results:other scientific term", "part of", "experiment:task"]], "326": [["game tree search:task", "used for", "move selector:method"], ["game tree search:task", "used for", "move sorter:method"], ["game tree search:task", "used for", "training tool:method"]], "327": [["miscommunication:other scientific term", "hyponym of", "reference problems:other scientific term"], ["reference problems:other scientific term", "hyponym of", "miscommunication:other scientific term"]], "328": [["baselines:generic", "compare", "trainable sentence planner:method"]], "330": [["processing description:other scientific term", "used for", "recognition tasks:task"]], "332": [["weighted rank loss:other scientific term", "used for", "problems in computer vision:task"]], "333": [["phase locking:other scientific term", "used for", "features derived from AN fibers -LRB- ANFs -RRB-:other scientific term"]], "335": [["dataset of scenes:material", "used for", "current work in unsupervised object discovery:task"]], "336": [["fundamental frequency -LRB- F0 -RRB- contour:other scientific term", "part of", "text-to-speech synthesis:method"], ["fundamental frequency -LRB- F0 -RRB- contour:other scientific term", "used for", "speech:other scientific term"], ["speech:other scientific term", "part of", "text-to-speech synthesis:method"], ["text input:material", "part of", "problem:task"]], "337": [["differential features:other scientific term", "feature of", "tools:generic"], ["differential features:other scientific term", "used for", "3--D reconstruction:task"], ["differential features:other scientific term", "used for", "constraints:other scientific term"]], "338": [["named entities:other scientific term", "used for", "unsupervised learning approach:method"]], "339": [["estimation from line correspondences:task", "used for", "factorization:method"], ["estimation of the tensors:task", "used for", "factorization:method"], ["point correspondences:other scientific term", "used for", "estimation from line correspondences:task"], ["point correspondences:other scientific term", "used for", "factorization:method"]], "340": [["classifier:other scientific term", "used for", "rule-based approach:method"]], "342": [["mixture of viewpoints models:method", "compare", "model:method"]], "343": [["summarization quality:metric", "feature of", "state-of-the-art:other scientific term"]], "344": [["anaphoric expressions:other scientific term", "part of", "research:generic"], ["research:generic", "part of", "results:generic"]], "346": [["features:other scientific term", "used for", "discourse segments:other scientific term"], ["features:other scientific term", "used for", "structure of email-threads:other scientific term"], ["lexical similarity:metric", "feature of", "features:other scientific term"]], "348": [["speech recognition output:other scientific term", "feature of", "speech:material"]], "349": [["illumination:other scientific term", "feature of", "face recognition:task"], ["pose invariance:other scientific term", "feature of", "face recognition:task"]], "351": [["parallel structures:other scientific term", "used for", "models:method"], ["reading time advantage:other scientific term", "used for", "models:method"]], "352": [["FERRET:method", "used for", "automatic Q/A applications:task"]], "353": [["scientific articles:material", "part of", "annotation scheme:method"], ["scientific articles:material", "part of", "resource:generic"]], "354": [["failure to understand the speaker's intention:task", "used for", "mistakes:other scientific term"], ["reference failures:other scientific term", "part of", "misunderstandings:other scientific term"]], "357": [["speech recognition accuracies:metric", "used for", "segmented corpus:material"]], "358": [["context-free phrase structure rules:other scientific term", "used for", "Metagrammatical formalisms:method"]], "360": [["OA:other scientific term", "used for", "auditory processing:task"], ["OA:other scientific term", "used for", "onset neurons -LRB- ONs -RRB-:other scientific term"], ["onset neurons -LRB- ONs -RRB-:other scientific term", "part of", "auditory brainstem:other scientific term"]], "361": [["reference translations:material", "part of", "NLP context:other scientific term"], ["resources:material", "part of", "MT:other scientific term"], ["resources:material", "part of", "NLP context:other scientific term"], ["resources:material", "part of", "human beings:other scientific term"]], "362": [["discrete-time version:other scientific term", "part of", "Fujisaki model:other scientific term"], ["speech F0 contours:other scientific term", "feature of", "Fujisaki model:other scientific term"], ["speech F0 contours:other scientific term", "feature of", "generating process:task"], ["speech F0 contours:other scientific term", "feature of", "statistical model:method"]], "363": [["candidate regions:other scientific term", "part of", "object detection cascades:method"], ["method:generic", "used for", "object detection cascades:method"]], "364": [["audio and textual document sources:material", "part of", "relevant pieces of information:other scientific term"], ["audio and textual document sources:material", "used for", "information distillation:task"], ["relevant pieces of information:other scientific term", "part of", "information distillation:task"]], "365": [["Multi-lingual Evaluation Task -LRB- MET -RRB-:task", "used for", "morphological analysis problem:task"]], "366": [["blur:other scientific term", "feature of", "proposed detectors:method"], ["distinctive textured patterns:other scientific term", "feature of", "proposed detectors:method"], ["illumination variation:other scientific term", "feature of", "proposed detectors:method"], ["large-scale structures:other scientific term", "feature of", "proposed detectors:method"], ["rotation:other scientific term", "feature of", "proposed detectors:method"], ["strong invariance:other scientific term", "feature of", "proposed detectors:method"]], "367": [["dags:other scientific term", "part of", "various structures:other scientific term"], ["strings:other scientific term", "part of", "various structures:other scientific term"], ["trees:other scientific term", "part of", "various structures:other scientific term"]], "368": [["Kullback-Leibler distance:other scientific term", "compare", "relative entropy:other scientific term"], ["Kullback-Leibler distance:other scientific term", "used for", "computing:task"], ["relative entropy:other scientific term", "used for", "computing:task"]], "370": [["topic signatures:other scientific term", "used for", "WSD task:task"]], "371": [["joint eigenstructure:other scientific term", "part of", "joint matrix triangularization:method"]], "372": [["manual interaction:method", "used for", "tedious and time consuming task:task"], ["synthetic scenes:material", "part of", "tedious and time consuming task:task"], ["training data:material", "part of", "tedious and time consuming task:task"]], "374": [["joint classification and regression optimization objective:method", "used for", "network:method"]], "376": [["segment:other scientific term", "used for", "NE item:other scientific term"], ["segment:other scientific term", "used for", "final output:other scientific term"]], "377": [["Plume's approach:method", "part of", "parsing:task"], ["parsing:task", "part of", "Plume's approach:method"], ["parsing:task", "part of", "semantic caseframe instantiation:method"]], "378": [["necessary and sufficient constraints:other scientific term", "part of", "affine cameras:other scientific term"]], "379": [["model:other scientific term", "used for", "classification:task"], ["model:other scientific term", "used for", "detection:task"], ["position:other scientific term", "part of", "model:other scientific term"]], "380": [["IEMOCAP database:material", "used for", "continuous -LRB- attribute -RRB- emotional assessments:other scientific term"], ["IEMOCAP database:material", "used for", "discrete -LRB- categorical -RRB- emotional assessments:other scientific term"], ["discrete -LRB- categorical -RRB- emotional assessments:other scientific term", "compare", "continuous -LRB- attribute -RRB- emotional assessments:other scientific term"]], "381": [["Cram\u00e9r-Rao lower bound:other scientific term", "feature of", "separation method:method"]], "382": [["active reconstruction systems:other scientific term", "part of", "our method:method"], ["high subpixel precision:metric", "feature of", "simulated and experimental results:material"], ["scene geometry:other scientific term", "part of", "our method:method"]], "385": [["object model:other scientific term", "used for", "numerical optimization problem:task"], ["object model:other scientific term", "used for", "visual object tracking:task"]], "386": [["hand-crafted template-based generation component:method", "evaluated for", "baseline sentence planners:method"], ["hand-crafted template-based generation component:method", "evaluated for", "rule-based sentence planners:method"], ["hand-crafted template-based generation component:method", "used for", "exhaustive comparison:task"]], "387": [["task of simultaneous object recognition and pose estimation:task", "used for", "Convolutional Neural Networks -LRB- CNN -RRB-:method"]], "388": [["3D line constraints:other scientific term", "used for", "light field stereo matching:task"], ["analysis:generic", "used for", "line-assisted graph-cut -LRB- LAGC -RRB-:method"]], "389": [["000 roots words:material", "part of", "description:generic"], ["description:generic", "used for", "root word lexicon:material"], ["root word lexicon:material", "part of", "description:generic"]], "392": [["grammar formalisms:other scientific term", "hyponym of", "formalism:other scientific term"]], "395": [["direct orthographical mapping -LRB- DOM -RRB-:method", "used for", "machine transliteration/backtransliteration:task"], ["novel framework:method", "used for", "machine transliteration/backtransliteration:task"]], "396": [["transliteration process:task", "used for", "joint source-channel transliteration model:method"], ["transliteration process:task", "used for", "n-gram transliteration model -LRB- n-gram TM -RRB-:method"]], "398": [["NL requirements:other scientific term", "part of", "laboratory study:method"], ["NL requirements:other scientific term", "used for", "carrying out this task:task"], ["Wizard of Oz technique:method", "part of", "second half of the paper:generic"], ["laboratory study:method", "part of", "second half of the paper:generic"]], "400": [["motion estimation:task", "used for", "image processing techniques:method"], ["object recognition:task", "used for", "image processing techniques:method"], ["one layer:other scientific term", "part of", "each examined site:other scientific term"], ["phenomenon:other scientific term", "used for", "motion estimation:task"], ["phenomenon:other scientific term", "used for", "object recognition:task"]], "401": [["TREC Blog track test set:material", "part of", "Experiments:task"], ["retrieval effectiveness:metric", "feature of", "best performance:metric"], ["retrieval effectiveness:metric", "feature of", "credibility indicators:other scientific term"]], "402": [["Text Summarisation:task", "used for", "Natural Language Processing -LRB- NLP -RRB-:method"], ["topic signatures:other scientific term", "used for", "Natural Language Processing -LRB- NLP -RRB-:method"], ["topic signatures:other scientific term", "used for", "Text Summarisation:task"], ["topic signatures:other scientific term", "used for", "Word Sense Disambiguation -LRB- WSD -RRB-:task"]], "403": [["key idea:generic", "part of", "approach:generic"]], "404": [["color:other scientific term", "used for", "shape constrained image segmentation:task"], ["method:generic", "used for", "mixtures of feature distributions:method"], ["probabilistic shape knowledge:other scientific term", "used for", "shape constrained image segmentation:task"], ["texture:other scientific term", "used for", "shape constrained image segmentation:task"]], "405": [["grammars with regular expressions:other scientific term", "part of", "normal CF grammars:other scientific term"]], "407": [["correcting the positions:task", "part of", "this paper:generic"], ["correcting the positions:task", "part of", "word as a correction unit:method"], ["word as a correction unit:method", "part of", "this paper:generic"], ["word as a correction unit:method", "used for", "correcting the positions:task"], ["words in the list:material", "part of", "this paper:generic"], ["words in the list:material", "part of", "word as a correction unit:method"], ["words in the list:material", "used for", "correcting the positions:task"]], "408": [["novel moderate positive sample mining method:method", "used for", "robust CNN:method"]], "411": [["efficient subwindow search -LRB- ESS -RRB-:method", "used for", "our method:method"], ["last stage:generic", "part of", "our method:method"]], "412": [["2 NN search:task", "used for", "random-projection based methods:method"], ["this:generic", "used for", "random-projection based methods:method"]], "413": [["segmented strings:material", "used for", "NE items:other scientific term"]], "416": [["linguistic parser/generator for LFG:method", "part of", "system:generic"], ["packed parse forests:other scientific term", "part of", "linguistic parser/generator for LFG:method"], ["packed parse forests:other scientific term", "part of", "maximum-entropy model:method"], ["packed parse forests:other scientific term", "part of", "transfer component for parse reduction:method"], ["system:generic", "used for", "linguistic parser/generator for LFG:method"], ["system:generic", "used for", "maximum-entropy model:method"], ["system:generic", "used for", "transfer component for parse reduction:method"], ["transfer component for parse reduction:method", "part of", "system:generic"]], "417": [["features of entities:other scientific term", "used for", "robust PCA:task"], ["prior structure:other scientific term", "part of", "features of entities:other scientific term"], ["prior structure:other scientific term", "used for", "robust PCA:task"], ["side information:other scientific term", "used for", "features of entities:other scientific term"], ["side information:other scientific term", "used for", "robust PCA:task"]], "419": [["30 scf types:material", "part of", "grammatical relations -LRB- grs -RRB-:other scientific term"]], "420": [["tool:method", "used for", "linguistic annotation:method"]], "421": [["visual pathway:other scientific term", "feature of", "model:method"]], "422": [["task:generic", "evaluated for", "conditional random field -LRB- CRF -RRB-:method"]], "423": [["set of stereo images:material", "used for", "and scalable way:method"], ["training data:material", "used for", "and scalable way:method"]], "424": [["action positions:other scientific term", "part of", "online action detection:task"], ["action type:other scientific term", "part of", "online action detection:task"]], "425": [["standard MT evaluation methods:method", "used for", "classifiers:method"]], "426": [["PER:other scientific term", "used for", "classification method:method"], ["part of speech information:other scientific term", "hyponym of", "PER:other scientific term"], ["word matches:other scientific term", "part of", "part of speech information:other scientific term"]], "430": [["distillation queries:other scientific term", "used for", "NIST Automatic Content Extraction -LRB- ACE -RRB-:task"], ["distillation queries:other scientific term", "used for", "task:generic"]], "432": [["model:generic", "part of", "unlexicalized parser:method"], ["smoothing:method", "feature of", "model:generic"], ["unlexicalized parser:method", "part of", "model:generic"]], "434": [["convolution kernel over parse trees:method", "compare", "previous best-reported feature-based methods:method"]], "437": [["algorithm:method", "compare", "recursive ascent parsers:method"]], "438": [["GB's binding theory:other scientific term", "used for", "anaphora resolution:task"], ["Grosz-Sidner-style focus model:other scientific term", "used for", "anaphora resolution:task"], ["sentence boundaries:other scientific term", "used for", "anaphora resolution:task"], ["text-level anaphora:other scientific term", "used for", "anaphora resolution:task"]], "442": [["three different confidence tests:other scientific term", "part of", "UV procedure:method"]], "443": [["eigenvectors:other scientific term", "used for", "cluster number estimation:task"]], "446": [["emotion:other scientific term", "hyponym of", "expressive speech communication:other scientific term"]], "447": [["syntactic structure features:other scientific term", "used for", "convolution tree kernel:method"]], "448": [["hidden Markov model -LRB- HMM -RRB-:method", "part of", "classifiers:method"], ["textual and prosodic knowledge sources:other scientific term", "feature of", "hidden Markov model -LRB- HMM -RRB-:method"], ["textual and prosodic knowledge sources:other scientific term", "used for", "detecting sentence boundaries:task"]], "453": [["10.4 M English words:material", "part of", "authoritative and comprehensive text collection:other scientific term"], ["10.4 M English words:material", "part of", "specific and special domain of HK laws:other scientific term"], ["18.3 M Chinese characters:material", "part of", "authoritative and comprehensive text collection:other scientific term"], ["18.3 M Chinese characters:material", "part of", "specific and special domain of HK laws:other scientific term"], ["bilingual corpus:material", "part of", "authoritative and comprehensive text collection:other scientific term"], ["bilingual corpus:material", "part of", "specific and special domain of HK laws:other scientific term"]], "454": [["Fujisaki-model parameters:other scientific term", "part of", "model:method"], ["model:method", "part of", "efficient algorithm:method"]], "455": [["exhaustive procedure:method", "compare", "proposed method:method"]], "456": [["side information:other scientific term", "used for", "noisy image classification:task"], ["side information:other scientific term", "used for", "our method:method"]], "457": [["bio-inspired model:method", "used for", "analog programmable array processor -LRB- APAP -RRB-:method"]], "458": [["logical formalism:method", "part of", "this paper:generic"]], "459": [["signals:other scientific term", "used for", "design for embodied conversational agents:method"], ["verbal and nonverbal means:other scientific term", "used for", "design for embodied conversational agents:method"], ["verbal and nonverbal means:other scientific term", "used for", "grounding:task"]], "460": [["criterion:other scientific term", "used for", "semantic-oriented NLP applications:task"]], "461": [["empirical quality:metric", "feature of", "distributional word feature vectors:material"]], "462": [["approximate joint triangularizer:method", "compare", "exact joint triangularizer:method"]], "465": [["pedestrian data:material", "part of", "feature space:other scientific term"]], "467": [["Japanese text processing:task", "part of", "morphological analysis:task"], ["morphological analysis:task", "part of", "proper nouns:other scientific term"], ["proper nouns:other scientific term", "part of", "Japanese text processing:task"], ["proper nouns:other scientific term", "part of", "morphological analysis:task"]], "468": [["blur:other scientific term", "feature of", "histogram-based interest point detectors:method"], ["blur:other scientific term", "used for", "matching textured scenes:task"], ["illumination changes:other scientific term", "feature of", "histogram-based interest point detectors:method"], ["illumination changes:other scientific term", "used for", "matching textured scenes:task"]], "469": [["extreme illumination:other scientific term", "feature of", "fully automatic recognition system:method"]], "471": [["new method:method", "evaluated for", "current state-of-the-art methods:method"]], "472": [["NIST evaluation metric:metric", "feature of", "maximization of translation accuracy:task"], ["NIST evaluation metric:metric", "feature of", "statistical translation model:method"], ["maximization of translation accuracy:task", "part of", "statistical translation model:method"]], "473": [["Euclidean distance:other scientific term", "used for", "local range:other scientific term"]], "474": [["deep metrics:metric", "used for", "person re-identification:task"], ["several benchmarks:material", "feature of", "person re-identification:task"]], "475": [["Named Entity -LRB- NE -RRB-:other scientific term", "used for", "morphological analyzer:method"], ["numerical and temporal expressions:other scientific term", "used for", "morphological analyzer:method"], ["numerical and temporal expressions:other scientific term", "used for", "recognition and classification:task"], ["proper names:other scientific term", "hyponym of", "Named Entity -LRB- NE -RRB-:other scientific term"], ["proper names:other scientific term", "used for", "morphological analyzer:method"], ["proper names:other scientific term", "used for", "recognition and classification:task"]], "477": [["and trifocal tensors:other scientific term", "hyponym of", "tensors:other scientific term"]], "479": [["this:generic", "used for", "Multiple Instance Learning -LRB- MIL -RRB-:method"]], "480": [["recognition rate:metric", "feature of", "state-of-the-art commercial software:method"]], "484": [["tagger:method", "used for", "Penn Treebank WSJ:material"]], "485": [["unlexicalized parser:method", "used for", "smoothing:method"], ["unlexicalized parser:method", "used for", "suffix analysis:method"]], "487": [["bibliographic citations:material", "part of", "field structured extraction tasks:task"], ["classified advertisements:material", "part of", "field structured extraction tasks:task"]], "491": [["data:material", "used for", "training the CNN embedding:task"], ["local range:other scientific term", "used for", "training the CNN embedding:task"], ["suitable positive -LRB- i.e. intra-class -RRB- training samples:material", "used for", "training the CNN embedding:task"]], "492": [["a priori geometric constraints:other scientific term", "used for", "3--D shape:other scientific term"], ["a priori geometric constraints:other scientific term", "used for", "3--D stereo reconstruction scheme:method"]], "494": [["Noun Classifier Associations -LRB- NCA -RRB-:other scientific term", "part of", "corpus-based method:method"], ["Noun Classifier Associations -LRB- NCA -RRB-:other scientific term", "used for", "problems in classifier assignment:task"], ["Noun Classifier Associations -LRB- NCA -RRB-:other scientific term", "used for", "semantic construction of noun phrase:task"]], "495": [["source and target language sentences:material", "part of", "linguistic information:other scientific term"], ["syntactic structure:other scientific term", "part of", "parse-trees:other scientific term"], ["word strings:material", "part of", "linguistic information:other scientific term"], ["word-to-word alignments:material", "part of", "linguistic information:other scientific term"]], "496": [["automated evaluation techniques:method", "part of", "research:generic"], ["output of machine translation -LRB- MT -RRB- systems:other scientific term", "used for", "evaluation of human language learners:task"], ["research:generic", "used for", "automated evaluation techniques:method"]], "497": [["features:other scientific term", "feature of", "heuristic principles:other scientific term"]], "498": [["compact high-pass filters:method", "used for", "recent work:generic"], ["dynamic programming approach:method", "used for", "recent work:generic"]], "500": [["System:generic", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB-:method"], ["Utterance Verification -LRB- UV -RRB-:task", "part of", "Automatic Speech Recognition -LRB- ASR -RRB-:method"], ["spontaneous speech:other scientific term", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB-:method"]], "501": [["robust principal component analysis -LRB- robust PCA -RRB-:other scientific term", "used for", "machine learning applications:task"]], "502": [["three important requirements:other scientific term", "used for", "database access:task"]], "503": [["matrices in M:other scientific term", "part of", "approximate joint matrix triangularization:task"]], "504": [["normal tracking conditions:other scientific term", "used for", "local optimization:method"], ["object:other scientific term", "used for", "local optimization:method"], ["parameter space:other scientific term", "used for", "local optimization:method"], ["rotation:other scientific term", "used for", "local optimization:method"], ["scale:other scientific term", "used for", "local optimization:method"], ["similarity measure:other scientific term", "used for", "local optimization:method"], ["translation:other scientific term", "used for", "local optimization:method"]], "505": [["techniques:method", "compare", "hand-crafted template-based or rule-based approaches:method"]], "506": [["Confidence tests:method", "part of", "this paper:generic"], ["UV procedure:method", "part of", "this paper:generic"], ["decoded string hypotheses:other scientific term", "part of", "UV procedure:method"], ["word and garbage models:method", "part of", "this paper:generic"]], "507": [["accurate and parsimonious delineation of scene objects:other scientific term", "used for", "unsupervised object discovery:task"], ["evaluation metrics:metric", "feature of", "accurate and parsimonious delineation of scene objects:other scientific term"], ["evaluation metrics:metric", "used for", "sets of segmentations:material"], ["evaluation metrics:metric", "used for", "unsupervised object discovery:task"]], "508": [["10 positive and 10 negative examples:material", "part of", "experiments on real data sets:task"], ["detector:other scientific term", "feature of", "linear and kernel SVM:method"], ["detector:other scientific term", "used for", "experiments on real data sets:task"]], "510": [["laws of Hong Kong:material", "part of", "legal text hierarchy:other scientific term"], ["numbering system:other scientific term", "part of", "legal text hierarchy:other scientific term"], ["subparagraph level:other scientific term", "part of", "legal text hierarchy:other scientific term"]], "511": [["tree-adjoining grammars -LRB- TAG -RRB-:other scientific term", "used for", "automatic translation of natural language:task"], ["tree-adjoining grammars -LRB- TAG -RRB-:other scientific term", "used for", "semantic interpretation:task"]], "512": [["automatic candidate generation:method", "part of", "class-oriented framework:method"], ["compositional classes of paraphrases:other scientific term", "hyponym of", "paraphrase class:other scientific term"], ["paraphrase examples:material", "part of", "compositional classes of paraphrases:other scientific term"], ["sentential paraphrases:material", "part of", "compositional classes of paraphrases:other scientific term"]], "513": [["object:other scientific term", "part of", "local tracking:task"]], "514": [["arbitrary position:other scientific term", "feature of", "proposed algorithm:method"]], "515": [["layers:other scientific term", "part of", "distributed representations:other scientific term"], ["layers:other scientific term", "part of", "object category representations:other scientific term"], ["layers:other scientific term", "part of", "object pose information:other scientific term"]], "516": [["1.5% rate of false acceptance:metric", "part of", "experimental results:generic"], ["12% rejection rate of correct utterances:metric", "part of", "experimental results:generic"], ["50% reduction in recognition errors:metric", "part of", "experimental results:generic"], ["natural number recognition task:task", "part of", "experimental results:generic"], ["real telephone application:material", "part of", "experimental results:generic"], ["real telephone application:material", "used for", "natural number recognition task:task"]], "517": [["questions:other scientific term", "part of", "Q/A:other scientific term"]], "518": [["attentional state:other scientific term", "used for", "discourse processing:task"], ["intentions:other scientific term", "used for", "discourse processing:task"], ["relationships:other scientific term", "used for", "discourse processing:task"], ["segments:other scientific term", "used for", "discourse processing:task"], ["utterances:other scientific term", "used for", "discourse processing:task"]], "520": [["method:generic", "used for", "kernel-ized support vector machines:method"], ["tool:generic", "used for", "kernel-ized support vector machines:method"]], "524": [["complex long-range temporal dynamics:other scientific term", "feature of", "proposed model:method"], ["deep Long Short-Term Memory -LRB- LSTM -RRB-:method", "feature of", "proposed model:method"]], "525": [["broadly available resources:generic", "used for", "canonical graph2tree transformation:method"], ["broadly available resources:generic", "used for", "morphosyntactic parser of L0:method"], ["canonical graph2tree transformation:method", "part of", "broadly available resources:generic"], ["liaisons:other scientific term", "part of", "elements of the text:other scientific term"], ["morphosyntactic parser of L0:method", "part of", "broadly available resources:generic"]], "526": [["aligned bilingual corpus of word examples:material", "used for", "disambiguated morphological analysis:task"], ["aligned bilingual corpus of word examples:material", "used for", "lemmatized indexing:task"]], "527": [["reasoning:other scientific term", "used for", "clustering:task"]], "528": [["domain independent features:method", "used for", "SLIPPER:method"], ["domain independent features:method", "used for", "TiMBL:method"], ["domain independent features:method", "used for", "machine learning algorithms:method"], ["domain independent features:method", "used for", "memory-based system:method"], ["domain independent features:method", "used for", "rule-based learning algorithm:method"], ["predicates:other scientific term", "used for", "clauses:other scientific term"]], "531": [["object detection:task", "part of", "global optimization problem:task"]], "536": [["CRF model:method", "compare", "HMM:method"], ["CRF model:method", "compare", "Max-ent models:method"]], "537": [["faces:other scientific term", "used for", "recognition input:task"], ["faces:other scientific term", "used for", "training:task"], ["objective:generic", "used for", "work:generic"]], "538": [["UNL-tree + L0:other scientific term", "compare", "MS-L0 structure:other scientific term"]], "540": [["performance:metric", "used for", "learned confidence measures:method"]], "543": [["formalism:other scientific term", "used for", "logical form language:other scientific term"], ["formalism:other scientific term", "used for", "natural languages:other scientific term"], ["formalism:other scientific term", "used for", "semantics:other scientific term"]], "546": [["intentional structure:other scientific term", "part of", "discourse structure:other scientific term"], ["linguistic structure:other scientific term", "part of", "discourse structure:other scientific term"], ["sequence of utterances:other scientific term", "part of", "discourse structure:other scientific term"], ["three separate but interrelated components:other scientific term", "part of", "discourse structure:other scientific term"]], "547": [["documents of certain genres:other scientific term", "used for", "summarization:task"]], "548": [["distribution over the values of a move:other scientific term", "part of", "local pattern context:other scientific term"], ["expert game records:material", "part of", "pattern extraction scheme:method"], ["method:generic", "used for", "Bayesian learning algorithm:method"], ["method:generic", "used for", "pattern extraction scheme:method"]], "549": [["lexical features:other scientific term", "feature of", "part-of-speech tagger:method"], ["multiple consecutive words:other scientific term", "part of", "lexical features:other scientific term"]]}, "error_cases": {}}