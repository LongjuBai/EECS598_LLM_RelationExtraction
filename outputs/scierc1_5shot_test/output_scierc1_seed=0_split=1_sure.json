{"micro_pc": 0.009375, "macro_pc": 0.009375, "pc_list": {"feature of": 0.009375}, "micro_rc": 0.05084745762711865, "macro_rc": 0.05084745762711865, "rc_list": {"feature of": 0.05084745762711865}, "micro_f1": 0.015831134564643797, "macro_f1": 0.015831134564643797, "f1_list": {"feature of": 0.015831134564643797}, "num_cases": 551, "accuracy": 0.5099818511796733, "correct_cases": {"0": {"text": "Experimental results are encouraging.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "2": {"text": "The analyzer is called \"Amorph\".", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "4": {"text": "Preliminary modeling and recognition results are presented.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "6": {"text": "A unique form of reg-ularization is also needed.", "true": [], "pred": [], "response": "\n"}, "8": {"text": "It is particularly valuable to empirical MT research.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "14": {"text": "Basic methodology and practical techniques are reported in detail.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "15": {"text": "Translations are produced by means of a beam-search decoder.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "16": {"text": "Basically, there is no exact rule for classifier selection.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "17": {"text": "Therefore, self-assessments will be closer to the intended emotions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "18": {"text": "We investigate independent and relevant event-based extractive mutli-document summarization approaches.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "19": {"text": "The classifiers show little gain from information about meeting context.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "24": {"text": "We briefly investigate the weak equivalence of the two formalisms.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "25": {"text": "Unconstrained MPS grammars, unfortunately, are not computationally safe.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "26": {"text": "Deep learning methods have achieved wide success in this task.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "28": {"text": "The result theoretically justifies the effectiveness of features in robust PCA.", "true": [["features:other scientific term", "feature of", "robust PCA:method"]], "pred": [["features:other scientific term", "feature of", "robust PCA:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "30": {"text": "Such mistakes can slow, and possibly break down, communication.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "31": {"text": "This paper examines the benefits of system combination for unsupervised WSD.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "32": {"text": "Finally, the Prolog form is executed to yield the answer.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "33": {"text": "Manual acquisition of semantic constraints in broad domains is very expensive.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "34": {"text": "It is presented as a generalization of the recursive descent parser.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "35": {"text": "These dependencies are not naturally captured by the typical Dirichlet-multinomial formulation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "38": {"text": "Extensive experiments demonstrate the utility and performance of the proposed approach.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "40": {"text": "A random modulation scheme produces near-Bernoulli statistics even for highly correlated inputs.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "41": {"text": "With independent approach, we identify important contents by frequency of events.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "42": {"text": "We present Minimum Bayes-Risk -LRB- MBR -RRB- decoding for statistical machine translation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "43": {"text": "We discuss how these might be satisfied by future Natural Language systems.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "44": {"text": "We suggest a new goal and evaluation criterion for word similarity measures.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "46": {"text": "Our goal is to recognize and isolate such miscommunications and circumvent them.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "47": {"text": "These include demonstrations of synthesis of cyclopean views of extended conversational sequences.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "51": {"text": "A method for producing such phrases from a word-aligned corpora is proposed.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "52": {"text": "Thus we believe researchers working with novel features should consider trying MLPs.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "59": {"text": "We report the performance of the MBR decoders on a Chinese-to-English translation task.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "60": {"text": "Even more illuminating was the factors on which the assessors made their decisions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "62": {"text": "Both learners perform well, yielding similar success rates of approx 90%.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "63": {"text": "It models reflection as regions containing two different layers moving over each other.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "65": {"text": "However, they provide no guarantee of being more efficient than exhaustive search.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "69": {"text": "For various reasons, UNL graphs are the best candidates in this context.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "71": {"text": "Labeled data is replaced by a few hand-crafted rules that encode basic syntactic knowledge.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "73": {"text": "This paper presents an algorithm for selecting an appropriate classifier word for a noun.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "76": {"text": "Unlike standard regression problems, the loss is inversely proportional to the regressed-to values.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "78": {"text": "Subjects were given a set of up to six extracts of translated newswire text.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "79": {"text": "Some of the extracts were expert human translations, others were machine translation outputs.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "80": {"text": "We demonstrate the bound on synthetic data for which the ground truth is known.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "82": {"text": "Our combination methods rely on predominant senses which are derived automatically from raw text.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "84": {"text": "The scheme was implemented by gathering statistics on the output of other linguistic tools.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "88": {"text": "The modified graph is then sent to the UNL-L0 deconverter and the result shown.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "89": {"text": "We then derive a scalable stochastic gradient descent algorithm for the resulting learning problem.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "92": {"text": "In contrast, object pose estimation using these approaches has received relatively less attention.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "95": {"text": "Surprisingly enough, similar scores are obtained in many cases regardless of the quality.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "96": {"text": "First, it uses several kinds of dictionaries to segment and tag Japanese character strings.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "98": {"text": "The results indicate that there is a mismatch between the expression and perception of emotion.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "102": {"text": "This paper solves a specialized regression problem to obtain sampling probabilities for records in databases.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "103": {"text": "Additionally, they were asked to mark the word at which they made this decision.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "106": {"text": "The bound depends only on the observable matrices in M' and the noise level.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "107": {"text": "To our knowledge, this is the first a posteriori bound for joint matrix decomposition.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "111": {"text": "A search restriction especially useful for the translation direction from German to English is presented.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "112": {"text": "A purely functional implementation of LR-parsers is given, together with a simple correctness proof.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "115": {"text": "Recent progress in computer vision has been driven by high-capacity models trained on large datasets.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "116": {"text": "These mattes are implied by a set of hypothesized object boundary fragments in the scene.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "118": {"text": "The request is passed to a mobile, intelligent agent for execution at the appropriate database.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "120": {"text": "The polarization of the objects of the elementary structures controls the saturation of the final structure.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "123": {"text": "The analysis is based on the hypothesis that people are better decoders of their own emotions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "126": {"text": "This probably occurs because each model has different strengths and weaknesses for modeling the knowledge sources.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "134": {"text": "We examine the relationship between the two grammatical formalisms: Tree Adjoining Grammars and Head Grammars.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "137": {"text": "These parameters are then quantized into a small number of values without altering the writing intelligibility.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "138": {"text": "With the rise of deep archi-tectures, the prime focus has been on object category recognition.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "142": {"text": "The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "144": {"text": "Experiment results on ACE corpora show that this spectral clustering based approach outperforms the other clustering methods.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "145": {"text": "The perception of transparent objects from images is known to be a very hard problem in vision.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "146": {"text": "In this paper, we explore what can be said about transparent objects by a moving observer.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "147": {"text": "We show promising results in both the detection and viewpoint classification tasks on these two challenging datasets.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "150": {"text": "Thus the resulting detectors are not robust and highly depend on the choice of the training examples.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "153": {"text": "Moreover, a cost zero solution always exists and can only be excluded by hard budget constraints.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "154": {"text": "We present results on addressee identification in four-participants face-to-face meetings using Bayesian Network and Naive Bayes classifiers.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "156": {"text": "We investigate several voting - and arbiter-based combination strategies over a diverse pool of unsupervised WSD systems.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "157": {"text": "This paper gives an overall account of a prototype natural language question answering system, called Chat-80.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "158": {"text": "Human action recognition from well-segmented 3D skeleton data has been intensively studied and attracting an increasing attention.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "159": {"text": "In this paper, we study the problem of online action detection from the streaming skeleton data.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "160": {"text": "MINPRAN's properties are connrmed experimentally on synthetic data and compare favorably to least median of squares.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "161": {"text": "We evaluate several proposals for constraining them, basing our assessment on computational tractability and explanatory adequacy.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "167": {"text": "Thus, the limitations of the automatic metrics used within MT are also discussed in this regard.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "170": {"text": "Structural or numerical constraints can then be added locally to the reconstruction process through a constrained optimization scheme.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "171": {"text": "We integrate a spoken language understanding system with intelligent mobile agents that mediate between users and information sources.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "172": {"text": "Using LCS-Marine, tactical personnel can converse with their logistics system to place a supply or information request.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "174": {"text": "We argue that it is necessary to draw a line between generalizable semantic principles and domain-specific semantic information.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "177": {"text": "With relevant approach, we identify important contents by PageRank algorithm on the event map constructed from documents.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "178": {"text": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "180": {"text": "Both classifiers perform the best when conversational context and utterance features are combined with speaker's gaze information.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "181": {"text": "This, the first experiment in a series of experiments, looks at the intelligibility of MT output.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "183": {"text": "In particular, we obtain a probability distribution over legal moves for professional play in a given position.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "184": {"text": "The applicability of many current information extraction techniques is severely limited by the need for supervised training data.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "185": {"text": "Furthermore, the subtask of regression optimization provides the ability to forecast the action prior to its occurrence.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "186": {"text": "Experimental results on our dataset and the public G3D dataset both demonstrate very promising performance of our scheme.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "187": {"text": "We apply cluster analysis on the sampled parameter space to redetect the object and renew the local tracker.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "192": {"text": "A general procedure for the estimation and quantization of these cycloidal motion parameters for arbitrary handwriting is presented.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "193": {"text": "We extensively experiment on two recent large and challenging multi-view datasets and we achieve better than the state-of-the-art.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "194": {"text": "Person re-identification is challenging due to the large variations of pose, illumination, occlusion and camera view.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "196": {"text": "The NCA is created statistically from a large corpus and recomposed under concept hierarchy constraints and frequency of occurrences.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "197": {"text": "Given a single image, it is difficult to even detect the presence of transparent objects in the scene.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "198": {"text": "We present a novel model-based approach to recover the shapes and the poses of transparent objects from known motion.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "199": {"text": "This paper proposes to use a convolution kernel over parse trees to model syntactic structure information for relation extraction.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "200": {"text": "We compare our results to state of the art methods such as mi-cro phase shifting and modulated phase shifting.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "201": {"text": "It uses a powerful pattern-matching language to classify grs into frames hierarchically in a way that mirrors inheritance-based lexica.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "202": {"text": "We provide a principled and provable solution for this problem; it is parameterless and requires no data insights.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "205": {"text": "We tested this to see if similar criteria could be elicited from duplicating the experiment using machine translation output.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "212": {"text": "In this paper, we present our approach for using information extraction annotations to augment document retrieval for distillation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "214": {"text": "It has also been studied in the framework of Japanese information extraction -LRB- -LSB- 3 -RSB- -RRB- in recent years.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "217": {"text": "At the core of the externally digital architecture is a high-density, low-power analog array performing binary-binary partial matrix-vector multiplication.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "218": {"text": "We examine a broad range of texts to show how the distribution of demonstrative forms and functions is genre dependent.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "219": {"text": "Specifically, we show how to incorporate a simple prior on the distribution of natural images into support vector machines.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "221": {"text": "We provide an efficient and simple regularized Empirical Risk Minimization -LRB- ERM -RRB- algorithm along with a theoretical generalization result.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"\n"}, "222": {"text": "Our extensive experimental results significantly improve over both uniform sampling and standard stratified sampling which are de-facto the industry standards.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "224": {"text": "We describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "225": {"text": "Three models are compared, which involve priming of rules between sentences, within sentences, and within coordinate structures.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "226": {"text": "The combined approach is formulated in the framework of Bayesian statistics to account for the robust-ness requirement in image understanding.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "227": {"text": "Experimental evidence shows that semantically meaningful segments are inferred, even when image data alone gives rise to ambiguous segmentations.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "229": {"text": "We propose a multi-task end-to-end Joint Classification-Regression Recurrent Neural Network to better explore the action type and temporal localiza-tion information.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "235": {"text": "Instead it assumes that the bad data are randomly -LRB- uniformly -RRB- distributed within the dynamic range of the sensor.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "236": {"text": "We show that none of them satisfies both criteria, and suggest new directions for research on alternative metagrammatical formalisms.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "237": {"text": "However, the distribution is unknown, so it is difficult to use the geodesic distance when comparing two samples.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "241": {"text": "The surface realizations of morphological constructions are constrained and modified by a number of phonetic rules such as vowel harmony.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "243": {"text": "It is based on a weakly supervised dependency parser that can model speech syntax without relying on any annotated training corpus.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "244": {"text": "This enables us to obtain an affine specialization of known projective relations connecting points and lines across two or three views.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "245": {"text": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "247": {"text": "Furthermore, we propose the use of standard parser evaluation methods for automatically evaluating the summarization quality of sentence condensation systems.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "250": {"text": "This paper presents the results of automatically inducing a Combinatory Categorial Grammar -LRB- CCG -RRB- lexicon from a Turkish dependency treebank.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "251": {"text": "The experiments show that the system is able to detect scf types with 70% precision and 66% recall rate.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "252": {"text": "We demonstrate our approach with multiple PTZ camera sequences in typical outdoor surveillance settings and show a comparison with state-of-the-art approaches.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "254": {"text": "We investigate the problem of learning to predict moves in the board game of Go from game records of expert players.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "255": {"text": "In order to build robust automatic abstracting systems, there is a need for better training resources than are currently available.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "256": {"text": "However, one can dramatically improve the quality of the learned structure by exploiting simple prior knowledge of the desired solutions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "259": {"text": "To a large extent, these statistics reflect semantic constraints and thus are used to disambiguate anaphora references and syntactic ambiguities.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "262": {"text": "Versions in some other languages known by the user may be displayed, so that improvement sharing is visible and encouraging.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "263": {"text": "A central goal of this research is to merge approaches from pivot MT, interactive MT, and multilingual text authoring.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "265": {"text": "A critical step in encoding sound for neuronal processing occurs when the analog pressure wave is coded into discrete nerve-action potentials.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "267": {"text": "Requestors can also instruct the system to notify them when the status of a request changes or when a request is complete.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "269": {"text": "We show how features that are imaged through a transparent object behave differently from those that are rigidly attached to the scene.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "270": {"text": "A generative framework is used for learning a model that captures the relative position of parts within each of the discretized viewpoints.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "271": {"text": "An experimental evaluation of summarization quality shows a close correlation between the automatic parse-based evaluation and a manual evaluation of generated strings.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "275": {"text": "The goal is to sample a small set of records over which evaluating aggregate queries can be done both efficiently and accurately.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "276": {"text": "We show that there is a closed-form -LRB- analytical -RRB- solution for one part of the Kullback-Leibler distance, viz the cross-entropy.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "279": {"text": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog, cf. query optimisation in a relational database.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "281": {"text": "An experiment was performed to resolve references of the pronoun \"it\" in sentences that were randomly selected from the corpus.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "284": {"text": "This method allows us to avoid these problems and go directly to capturing the statistical behavior of specific words in the application.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "285": {"text": "Unlike other techniques that handle large outlier percentages, MINPRAN does not rely on a known error bound for the good data.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "286": {"text": "By slow modulations of the amplitudes and phase lags of the two oscillators, a general pen trajectory can be efficiently encoded.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "287": {"text": "The result is a discrete motor control representation of the continuous pen motion, via the quantized levels of the model parameters.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "290": {"text": "The triangulation problem aims to fill in the ray space with continuous and non-overlapping simplices anchored at sampled points -LRB- rays -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "291": {"text": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"\n"}, "292": {"text": "In this paper, we present an approach to rapidly creating pixel-accurate semantic label maps for images extracted from modern computer games.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "294": {"text": "We have demonstrated this capability in several field exercises with the Marines and are currently developing applications of this technology in new domains.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "295": {"text": "We present an application of ambiguity packing and stochastic disambiguation techniques for Lexical-Functional Grammars -LRB- LFG -RRB- to the domain of sentence condensation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "299": {"text": "This paper considers the problem of reconstructing the motion of a 3D articulated tree from 2D point correspondences subject to some temporal prior.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "302": {"text": "Training instances are generated from experience and observation, and a variant of GOLEM is used to learn action models from these instances.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "303": {"text": "The automated segmentation of images into semantically meaningful parts requires shape information since low-level feature analysis alone often fails to reach this goal.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "308": {"text": "In this sentence-by-sentence error correction method, however, the annotator encounters grammatically complicated positions and this results in a decrease of productivity.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "310": {"text": "We discuss the application of synchronous TAGs to concrete examples, mentioning primarily in passing some computational issues that arise in its interpretation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "315": {"text": "We rigorously establish the correctness of the methodology and show by experimentation using LSH that it is competitive in practice with available alternatives.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "318": {"text": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation in very high dimensions, suitable for efficient implementation of kernels in image processing.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "320": {"text": "The problem of blind separation of underdetermined instantaneous mixtures of independent signals is addressed through a method relying on nonstationarity of the original signals.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "322": {"text": "We propose a novel approach to associate objects across multiple PTZ cameras that can be used to perform camera handoff in wide-area surveillance scenarios.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "323": {"text": "We conclude that previous approaches have neglected to evaluate systems in the context of their use, e.g. solving a task requiring data retrieval.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "324": {"text": "First, we investigate how well the addressee of a dialogue act can be predicted based on gaze, utterance and conversational context features.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "325": {"text": "The results of this experiment, along with a preliminary analysis of the factors involved in the decision making process will be presented here.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "326": {"text": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "327": {"text": "This paper highlights a particular class of miscommunication--reference problems--by describing a case study and techniques for avoiding failures of reference.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "328": {"text": "We show that the trainable sentence planner performs better than the rule-based systems and the baselines, and as well as the hand-crafted system.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "330": {"text": "This processing description specifies in these recognition tasks the role of information from the discourse and from the participants' knowledge of the domain.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "331": {"text": "But computational linguists seem to be quite dubious about analogies between sentences: they would not be enough numerous to be of any use.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "332": {"text": "Our core motivation is that minimizing a weighted rank loss is a natural criterion for many problems in computer vision such as person re-identification.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "334": {"text": "Multi-layer perceptrons -LRB- MLPs -RRB- performed much better than standard Gaussian mixture models -LRB- GMMs -RRB- for both our ANF-based and ON-based auditory features.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "335": {"text": "It is demonstrated qualitatively and quantitatively on a dataset of scenes and is suitable for current work in unsupervised object discovery without top-down knowledge.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "341": {"text": "Registration of classifier for each noun is limited to the type of unit classifier because other types are open due to the meaning of representation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "342": {"text": "Contrary to most of the existing mixture of viewpoints models, our model establishes explicit correspondences of parts across different viewpoints of the object class.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "343": {"text": "Overall summarization quality of the proposed system is state-of-the-art, with guaranteed grammaticality of the system output due to the use of a constraint-based parser/generator.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "344": {"text": "This research is part of a larger study of anaphoric expressions, the results of which will be incorporated into a natural language generation system.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "345": {"text": "The speakers in the database assigned their own emotions to more specific emotional categories, which led to more extreme values in the activation-valence space.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "349": {"text": "In spite of over two decades of intense research, illumination and pose invariance remain prohibitively challenging aspects of face recognition for most practical applications.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "355": {"text": "The distinction among these components is essential to provide an adequate explanation of such discourse phenomena as cue phrases, referring expressions, and interruptions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "356": {"text": "Coedition of a natural language text and its representation in some interlingual form seems the best and simplest way to share text revision across languages.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "357": {"text": "In the experiments, we used a variety of methods for preparing a segmented corpus and compared the language models by their speech recognition accuracies.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "359": {"text": "We instead present a simple but effective algorithm to first map bilinear subspaces to line constraints and then apply Constrained Delaunay Triangulation -LRB- CDT -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "361": {"text": "Many of the resources used are derived from data created by human beings out of an NLP context, especially regarding MT and reference translations.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "362": {"text": "We have previously introduced a statistical model describing the generating process of speech F0 contours, based on the discrete-time version of the Fujisaki model.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "365": {"text": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "372": {"text": "However, acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction, active sensing devices and/or synthetic scenes.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "373": {"text": "In this paper, we present methods by which an agent learns action models from its own experience and from its observation of a domain expert.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "375": {"text": "We train a maximum entropy classifier that, given a pair of sentences, can reliably determine whether or not they are translations of each other.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "376": {"text": "When a segment is found to be an NE item, this information is added to the segment and it is used to generate the final output.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "378": {"text": "In the simpler case of affine cameras we give neccessary and sufficient constraints on the components of the trifocal tensor, together with a simple geometric interpretation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "379": {"text": "Given a new image, detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "380": {"text": "Using the IEMOCAP database, discrete -LRB- categorical -RRB- and continuous -LRB- attribute -RRB- emotional assessments evaluated by the actors and na \u00a8 \u0131ve listeners are compared.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "383": {"text": "We believe that these evaluation techniques will provide information about both the human language learning process, the translation process and the development of machine translation systems.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "384": {"text": "Hitherto, smooth motion has been encouraged using a trajectory basis, yielding a hard combinatorial problem with time complexity growing exponentially in the number of frames.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "385": {"text": "Given an object model and a black-box measure of similarity between the model and candidate targets, we consider visual object tracking as a numerical optimization problem.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "386": {"text": "In order to perform an exhaustive comparison, we also evaluate a hand-crafted template-based generation component, two rule-based sentence planners, and two baseline sentence planners.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "389": {"text": "The description has been implemented using the PC-KIMMO environment -LRB- Antworth, 1990 -RRB- and is based on a root word lexicon of about 23,000 roots words.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "390": {"text": "To associate a sequence of the Fujisaki-model parameters with a text input based on statistical learning, this paper proposes extending this model to a context-dependent one.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "391": {"text": "Bayesian inference then samples the rules, disambiguating and combining them to create complex tree structures that maximize a discriminative model's posterior on a target unlabeled corpus.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "392": {"text": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms, such as rewriting systems, dependency grammars, TAG, HPSG and LFG.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "393": {"text": "In comparison with previous works, in this paper it is assumed that the signals are not i.i.d. in each epoch, but obey a first-order autoregressive model.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "394": {"text": "We explored possible ways to obtain a compact lexicon, consistent with CCG principles, from a treebank which is an order of magnitude smaller than Penn WSJ.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "397": {"text": "The distribution of nonverbal behaviors differed depending on the type of dialogue move being grounded, and the overall pattern reflected a monitoring of lack of negative feedback.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "398": {"text": "In the second half of the paper, we report a laboratory study using the Wizard of Oz technique to identify NL requirements for carrying out this task.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "400": {"text": "This phenomenon causes many image processing techniques to fail as they assume the presence of only one layer at each examined site e.g. motion estimation and object recognition.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "403": {"text": "The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "407": {"text": "In this paper, we propose to concentrate on correcting the positions in which the words in the list appear by taking a word as a correction unit.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "409": {"text": "We propose a novel step toward the unsupervised seg-mentation of whole objects by combining\" hints\" of partial scene segmentation offered by multiple soft, binary mattes.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "413": {"text": "Second, based on the information resulting from the dictionary lookup stage, a set of rules is applied to the segmented strings in order to identify NE items.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "414": {"text": "We explain this distinction and we show how this model may be applied to the interpretation of compounds in real texts, provided that complementary semantic information are retrieved.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "415": {"text": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives, relative clauses, and interrogatives in a general manner.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "417": {"text": "Thus, in this paper, we study the problem of robust PCA with side information, where both prior structure and features of entities are exploited for recovery.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "418": {"text": "This paper analyzes the validity of this assumption by comparing the mismatches between the assessments made by na \u00a8 \u0131ve listeners and by the speakers that generated the data.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "422": {"text": "In this paper, we evaluate the use of a conditional random field -LRB- CRF -RRB- for this task and relate results with this model to our prior work.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "424": {"text": "Online action detection goes one step further and is more challenging, which identifies the action type and localizes the action positions on the fly from the untrimmed stream.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "427": {"text": "If is is satisfactory, the errors were probably due to the graph, not to the deconverter, and the graph is sent to deconverters in other languages.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "429": {"text": "Based on this, MINPRAN uses random sampling to search for the t and the number of inliers to the t that are least likely to have occurred randomly.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "430": {"text": "We take advantage of the fact that some of the distillation queries can be associated with annotation elements introduced for the NIST Automatic Content Extraction -LRB- ACE -RRB- task.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "432": {"text": "In addition to the high accuracy of the model, the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "433": {"text": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "434": {"text": "Evaluation on the ACE 2003 corpus shows that the convolution kernel over parse trees can achieve comparable performance with the previous best-reported feature-based methods on the 24 ACE relation subtypes.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "437": {"text": "For LR -LRB- 0 -RRB- grammars, our algorithm is closely related to the recursive ascent parsers recently discovered by Kruse-man Aretz -LSB- 1 -RSB- and Roberts -LSB- 2 -RSB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "438": {"text": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB's binding theory, while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "439": {"text": "As new versions are added with appropriate tags and attributes in the original multilingual document, nothing is ever lost, and cooperative working on a document is rendered feasible.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "440": {"text": "It runs in time O -LRB- N 2 + SN log N -RRB-, where S is the number of random samples and N is the number of data points.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "441": {"text": "We show that the light field space is largely bi-linear due to 3D line segments in the scene, and direct tri-angulation of these bilinear subspaces leads to large errors.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "442": {"text": "b -RRB- The UV procedure is based on three different confidence tests, two based on acoustic measures and one founded on linguistic information, applied in a hierarchical structure.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "444": {"text": "We test our algorithm on the detection task and the viewpoint classification task by using\" car\" category from both the Savarese et al. 2007 and PASCAL VOC 2006 datasets.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "449": {"text": "We consider two groups of indicators: post level -LRB- determined using information about individual blog posts only -RRB- and blog level -LRB- determined using information from the underlying blogs -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "452": {"text": "For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions, i.e. functions that memorize the results of previous invocations.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "458": {"text": "In this paper we propose a logical formalism, which, among other things, is suitable for representing determiners without forcing a particular interpretation when their meaning is still not clear.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "460": {"text": "The new criterion--meaning-entailing substitutability--fits the needs of semantic-oriented NLP applications and can be evaluated directly -LRB- independent of an application -RRB- at a good level of human agreement.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "461": {"text": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results, proposing an objective measure for evaluating feature vector quality.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "462": {"text": "Our main result is a first-order upper bound on the distance between any approximate joint triangularizer of the matrices in M' and any exact joint triangularizer of the matrices in M.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "463": {"text": "In particular, it does not depend on optimization specific properties of the triangularizer, such as its proximity to critical points, that are typical of existing bounds in the literature.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "464": {"text": "We want to illustrate a framework less restrictive than earlier ones by allowing a speaker leeway in forming an utterance about a task and in determining the conversational vehicle to deliver it.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "466": {"text": "We experimentally show that using the ACE events to constrain the document set returned by an information retrieval engine significantly improves the precision at various recall rates for two different query templates.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "468": {"text": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes, in terms of repeatability and distinctiveness.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "471": {"text": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "472": {"text": "A statistical translation model is also presented that deals such phrases, as well as a training method based on the maximization of translation accuracy, as measured with the NIST evaluation metric.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "474": {"text": "Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification, and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "475": {"text": "Our morphological analyzer has done all the necessary work for the recognition and classification of proper names, numerical and temporal expressions, i.e. Named Entity -LRB- NE -RRB- items in the Japanese text.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "476": {"text": "Unlike existing interest point detectors, which measure pixel-wise differences in image intensity, our detectors incorporate histogram-based representations, and thus can find image regions that present a distinct distribution in the neighborhood.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "477": {"text": "In this paper we specialize the projective unifocal, bifo-cal, and trifocal tensors to the affine case, and show how the tensors obtained relate to the registered tensors encountered in previous work.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "478": {"text": "While previous approaches relied on geometric, appearance, or correlation-based information for establishing correspondences between static cameras, they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}, "479": {"text": "Towards this goal, we also propose a novel Multiple Instance Learning -LRB- MIL -RRB- formulation for the problem based on the logistic softmax function of covariance-based region features within a MAP estimation framework.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "480": {"text": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7% on all three databases -RRB-, significantly out-performing state-of-the-art commercial software and methods from the literature.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "482": {"text": "In this situation, the general method is to segment the raw corpus automatically using a word list, correct the output sentences by hand, and build a model from the segmented corpus.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "486": {"text": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese, and also exploits the large amount of Chinese text available in corpora and on the Web.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "487": {"text": "We demonstrate that for certain field structured extraction tasks, such as classified advertisements and bibliographic citations, small amounts of prior knowledge can be used to learn effective models in a primarily unsupervised fashion.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "489": {"text": "As an analogy must be valid on the level of form as well as on the level of meaning, we relied on the idea that translation should preserve meaning to test for similar meanings.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "490": {"text": "We demonstrate analytically that MINPRAN distinguishes good ts from ts to random data, and that MINPRAN nds accurate ts and nearly the correct number of inliers, regardless of the percentage of true inliers.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "493": {"text": "In Thai language, it frequently happens that there is fluctuation in the choice of classifier for a given concrete noun, both from the point of view of the whole speech community and individual speakers.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "495": {"text": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings, word-to-word alignments from an MT system, and syntactic structure from parse-trees of source and target language sentences.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "498": {"text": "Inspired by recent work which reconstructs general trajectories using compact high-pass filters, we develop a dynamic programming approach which scales linearly in the number of frames, leveraging the intrinsically local nature of filter interactions.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "502": {"text": "We identify three important requirements which arose from the task that we gave our subjects: operators specific to the task of database access, complex contextual reference and reference to the structure of the information source.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "503": {"text": "We consider the problem of approximate joint matrix triangularization when the matrices in M are jointly diagonalizable and real, but we only observe a set M' of noise perturbed versions of the matrices in M.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "505": {"text": "Techniques for automatically training modules of a natural language generator have recently been proposed, but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "507": {"text": "This reflects contemporary methods for unsupervised object discovery from groups of images, and it allows us to define intuitive evaluation met-rics for our sets of segmentations based on the accurate and parsimonious delineation of scene objects.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "509": {"text": "These methods diier from previous work in the area in two ways: the use of an action model formalism which is better suited to the needs of a re-active agent, and successful implementation of noise-handling mechanisms.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "510": {"text": "In this paper we present our recent work on harvesting English-Chinese bitexts of the laws of Hong Kong from the Web and aligning them to the subparagraph level via utilizing the numbering system in the legal text hierarchy.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "511": {"text": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax, for instance, to the task of semantic interpretation or automatic translation of natural language.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "513": {"text": "However, when the object becomes partially or totally occluded, such local tracking is prone to failure, especially when common prediction techniques like the Kalman filter do not provide a good estimate of object parameters in future frames.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "517": {"text": "FERRET utilizes a novel approach to Q/A known as predictive questioning which attempts to identify the questions -LRB- and answers -RRB- that users need by analyzing how a user interacts with a system while gathering information related to a particular scenario.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n"}, "519": {"text": "The reality of analogies between words is refuted by noone -LRB- e.g., I walked is to to walk as I laughed is to to laugh, noted I walked: to walk:: I laughed: to laugh -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "520": {"text": "This allows us to use our method to act not only as a faster procedure for cascade evaluation, but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions, in particular kernel-ized support vector machines.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "521": {"text": "We incorporate the prior on natural images by requiring that the separating hyperplane will not only yield a wide margin, but also that the corresponding positive half space will have a low probability to contain natural images -LRB- the background -RRB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "522": {"text": "Here we suggest a formal perspective on the difficulty in finding such a unification, in the form of an impossibility theorem: for a set of three simple properties, we show that there is no clustering function satisfying all three.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "523": {"text": "In both domains, we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples, and that semi-supervised methods can make good use of small amounts of labeled data.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "525": {"text": "On the internal side, liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary, a morphosyntactic parser of L0, and a canonical graph2tree transformation.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "526": {"text": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-, including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "529": {"text": "Because a speaker and listener cannot be assured to have the same beliefs, contexts, perceptions, backgrounds, or goals, at each point in a conversation, difficulties and mistakes arise when a listener interprets a speaker's utterance.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n(91) \"none\"  \n(92) \"none\"  \n(93) \"none\"  \n(94) \"none\"  \n(95) \"none\"  \n(96) \"none\"  \n(97) \"none\"  \n(98) \"none\"  \n(99) \"none\"  \n(100) \"none\"  \n(101) \"none\"  \n(102) \"none\"  \n(103) \"none\"  \n(104) \"none\"  \n(105) \"none\"  \n(106) \"none\"  \n(107) \"none\"  \n(108) \"none\"  \n(109) \"none\"  \n(110) \"none\"  \n"}, "530": {"text": "The two main contributions of this paper are: i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming, that encourages correct occlusion labeling; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "532": {"text": "Furthermore, this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB-; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "534": {"text": "While current approaches are developed by only considering the low rank plus sparse structure, in many applications, side information of row and/or column entities may also be given, and it is still unclear to what extent could such information help robust PCA.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "535": {"text": "Determiners play an important role in conveying the meaning of an utterance, but they have often been disregarded, perhaps because it seemed more important to devise methods to grasp the global meaning of a sentence, even if not in a precise way.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "538": {"text": "Establishing a \"best\" correspondence between the\" UNL-tree + L0\" and the\" MS-L0 structure\", a lattice, may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "539": {"text": "In our approach, the slave camera only passively follows the target -LRB- by loose registration with the master -RRB- and bootstraps itself from its own incoming imagery, thus effectively circumventing the problems faced by previous approaches and avoiding the need to perform any model transfer.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}, "542": {"text": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction, allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n"}, "544": {"text": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus, so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB-.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "545": {"text": "In all of these cases, we expect some form of dependency between the draws: the nucleotide at one position in the DNA strand may depend on the preceding nucleotides, children's names are highly correlated from year to year, and topics in text may be correlated and dynamic.", "true": [], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n"}}, "fail_cases": {"1": {"text": "We call these misunderstandings miscommunication.", "true": [], "pred": [["miscommunication:other scientific term", "feature of", "misunderstandings:other scientific term"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "3": {"text": "Language resource quality is crucial in NLP.", "true": [["Language resource quality:metric", "feature of", "NLP:task"]], "pred": [["Language resource quality:other scientific term", "feature of", "NLP:other scientific term"]], "response": "(1) \"feature of\"  \n(2) \"none\"\n"}, "5": {"text": "Another problem with determiners is their inherent ambiguity.", "true": [["ambiguity:other scientific term", "feature of", "determiners:method"]], "pred": [["ambiguity:other scientific term", "feature of", "determiners:other scientific term"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "7": {"text": "The results showed the advantages of our method.", "true": [], "pred": [["results:generic", "feature of", "our method:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "9": {"text": "Turkish has finite-state but nevertheless rather complex morphotactics.", "true": [], "pred": [["complex morphotactics:other scientific term", "feature of", "Turkish:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "10": {"text": "We have implemented a restricted domain parser called Plume.", "true": [], "pred": [["Plume:material", "feature of", "restricted domain parser:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "11": {"text": "Each part is a collection of salient image features.", "true": [], "pred": [["collection of salient image features:other scientific term", "feature of", "part:generic"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "12": {"text": "This raises questions about the validity of such approaches.", "true": [], "pred": [["validity:other scientific term", "feature of", "questions:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "13": {"text": "Extension to affine projection enables reconstruction without estimating cameras.", "true": [], "pred": [["affine projection:method", "feature of", "reconstruction:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "20": {"text": "The paper also promotes a new view for extensional reference.", "true": [], "pred": [["new view:other scientific term", "feature of", "paper:generic"], ["extensional reference:other scientific term", "feature of", "paper:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"feature of\"  \n"}, "21": {"text": "Combination methods are an effective way of improving system performance.", "true": [], "pred": [["system performance:metric", "feature of", "Combination methods:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "22": {"text": "Our approach outperforms state-of-the-art trackers on the VIVID benchmark datasets.", "true": [], "pred": [["state-of-the-art trackers:method", "feature of", "approach:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "23": {"text": "We further demonstrate synthesis from a freely translating virtual camera.", "true": [], "pred": [["freely translating virtual camera:other scientific term", "feature of", "synthesis:task"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "27": {"text": "Background modeling is an important component of many vision systems.", "true": [], "pred": [["Background modeling:method", "feature of", "vision systems:other scientific term"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "29": {"text": "We present a novel approach for automatically acquiring English topic signatures.", "true": [], "pred": [["automatically acquiring English topic signatures:task", "feature of", "novel approach:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "36": {"text": "The validation of these resources is widely recommended before being used.", "true": [], "pred": [["validation:task", "feature of", "resources:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"\n"}, "37": {"text": "This paper describes the impact of using different-quality references on evaluation.", "true": [], "pred": [["evaluation:task", "feature of", "different-quality references:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "39": {"text": "We present a new method for detecting interest points using histogram information.", "true": [], "pred": [["histogram information:other scientific term", "feature of", "method:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n"}, "45": {"text": "Reflections in image sequences consist of several layers superimposed over each other.", "true": [], "pred": [["layers:other scientific term", "feature of", "Reflections in image sequences:other scientific term"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "48": {"text": "We give two estimates, a lower one and a higher one.", "true": [], "pred": [["lower one:generic", "feature of", "estimates:metric"], ["higher one:generic", "feature of", "estimates:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"feature of\"  \n"}, "49": {"text": "Related work applies MINPRAN to complex range and intensity data 23 -RSB-.", "true": [], "pred": [["MINPRAN:method", "feature of", "complex range and intensity data:material"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "50": {"text": "Such a triangulation provides a piecewise-linear interpolant useful for light field super-resolution.", "true": [], "pred": [["piecewise-linear interpolant:other scientific term", "feature of", "light field super-resolution:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"\n"}, "53": {"text": "Amorph recognizes NE items in two stages: dictionary lookup and rule application.", "true": [], "pred": [["dictionary lookup:method", "feature of", "Amorph:method"], ["Amorph:method", "feature of", "NE items:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "54": {"text": "This posterior encodes sparse se-lectional preferences between a head word and its dependents.", "true": [], "pred": [["sparse selectional preferences:other scientific term", "feature of", "posterior:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "55": {"text": "We have built and will demonstrate an application of this approach called LCS-Marine.", "true": [], "pred": [["this approach:generic", "feature of", "LCS-Marine:method"], ["application:task", "feature of", "this approach:generic"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"\n"}, "56": {"text": "We have conducted numerous simulations to verify the practical feasibility of our algorithm.", "true": [], "pred": [["practical feasibility:other scientific term", "feature of", "our algorithm:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "57": {"text": "Machine transliteration/back-transliteration plays an important role in many multilingual speech and language applications.", "true": [], "pred": [["Machine transliteration/back-transliteration:method", "feature of", "multilingual speech and language applications:task"]], "response": "(1) \"feature of\"  \n(2) \"none\"\n"}, "58": {"text": "Design challenges, trade-offs and some experimental results are presented in this paper.", "true": [], "pred": [["Design challenges:other scientific term", "feature of", "this paper:generic"], ["experimental results:other scientific term", "feature of", "this paper:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"feature of\"  \n(11) \"none\"  \n(12) \"feature of\"  \n"}, "61": {"text": "This paper presents a machine learning approach to bare slice disambiguation in dialogue.", "true": [], "pred": [["machine learning approach:method", "feature of", "bare slice disambiguation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "64": {"text": "We present a strong detector based on combining a set of weak detectors.", "true": [], "pred": [["weak detectors:method", "feature of", "strong detector:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "66": {"text": "This paper describes a method for incorporating priming into an incremental probabilistic parser.", "true": [], "pred": [["incremental probabilistic parser:method", "feature of", "method:generic"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "67": {"text": "The seven categories of the scheme are based on rhetorical moves of argumentation.", "true": [], "pred": [["seven categories:other scientific term", "feature of", "scheme:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"\n"}, "68": {"text": "A new algorithm is proposed for novel view generation in one-to-one teleconferencing applications.", "true": [], "pred": [["algorithm:method", "feature of", "novel view generation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "70": {"text": "This motor control representation enables successful word spotting and matching of cursive scripts.", "true": [], "pred": [["motor control representation:method", "feature of", "matching of cursive scripts:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "72": {"text": "Listen-Communicate-Show -LRB- LCS -RRB- is a new paradigm for human interaction with data sources.", "true": [], "pred": [["new paradigm:other scientific term", "feature of", "Listen-Communicate-Show -LRB- LCS -RRB-:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "74": {"text": "The signals are assumed to be piecewise stationary with varying variances in different epochs.", "true": [], "pred": [["piecewise stationary:other scientific term", "feature of", "signals:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "75": {"text": "In this paper, events are defined as event terms and associated event elements.", "true": [], "pred": [["event terms:other scientific term", "feature of", "events:other scientific term"], ["event elements:other scientific term", "feature of", "events:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "77": {"text": "Then, we explore whether information about meeting context can aid classifiers' performances.", "true": [], "pred": [["classifiers' performances:metric", "feature of", "information about meeting context:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "81": {"text": "The integrated learning system has been experimentally validated in simulated construction and ooce domains.", "true": [], "pred": [["ooce domains:other scientific term", "feature of", "integrated learning system:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "83": {"text": "The system is implemented entirely in Prolog, a programming language based on logic.", "true": [], "pred": [["programming language:other scientific term", "feature of", "Prolog:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "85": {"text": "We present a novel method for discovering parallel sentences in comparable, non-parallel corpora.", "true": [], "pred": [["parallel sentences:other scientific term", "feature of", "method:generic"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "86": {"text": "This theory provides a framework for describing the processing of utterances in a discourse.", "true": [], "pred": [["framework:method", "feature of", "theory:other scientific term"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "87": {"text": "We then turn to a discussion comparing the linguistic expressiveness of the two formalisms.", "true": [["linguistic expressiveness:other scientific term", "feature of", "formalisms:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "90": {"text": "We also derive an efficient non-linear extension of WARCA by using the kernel trick.", "true": [], "pred": [["kernel trick:method", "feature of", "efficient non-linear extension of WARCA:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "91": {"text": "A model-based approach to on-line cursive handwriting analysis and recognition is presented and evaluated.", "true": [], "pred": [["model-based approach:method", "feature of", "on-line cursive handwriting analysis:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "93": {"text": "Light fields are image-based representations that use densely sampled rays as a scene description.", "true": [], "pred": [["image-based representations:other scientific term", "feature of", "Light fields:other scientific term"], ["densely sampled rays:other scientific term", "feature of", "image-based representations:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "94": {"text": "GLOSSER is designed to support reading and learning to read in a foreign language.", "true": [], "pred": [["foreign language:other scientific term", "feature of", "GLOSSER:method"], ["GLOSSER:method", "feature of", "reading:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "97": {"text": "A domain independent model is proposed for the automated interpretation of nominal compounds in English.", "true": [["English:material", "feature of", "nominal compounds:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "99": {"text": "This model was shown to be more appropriate for blind separation of natural speech signals.", "true": [], "pred": [["model:method", "feature of", "blind separation of natural speech signals:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "100": {"text": "We evaluate the proposed methods through several transliteration/backtransliteration experiments for English/Chinese and English/Japanese language pairs.", "true": [], "pred": [["proposed methods:method", "feature of", "transliteration/backtransliteration experiments:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "101": {"text": "A prototype chip has been designed and fabricated in a 0.5 \u00b5m standard CMOS process.", "true": [], "pred": [["0.5 \u00b5m standard CMOS process:material", "feature of", "prototype chip:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "104": {"text": "Branch and bound strategies have previously attempted to curb this complexity whilst maintaining global optimality.", "true": [["global optimality:other scientific term", "feature of", "Branch and bound strategies:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "105": {"text": "To improve topical blog post retrieval we incorporate textual credibility indicators in the retrieval process.", "true": [], "pred": [["retrieval process:method", "feature of", "topical blog post retrieval:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "108": {"text": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision.", "true": [], "pred": [["learned confidence measures:other scientific term", "feature of", "stereo vision:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "109": {"text": "Our experimental results show that the scheme is stable, reproducible and intuitive to use.", "true": [], "pred": [["stable:metric", "feature of", "scheme:other scientific term"], ["reproducible:metric", "feature of", "scheme:other scientific term"], ["intuitive:metric", "feature of", "scheme:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"feature of\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "110": {"text": "To evaluate our proposed model, we build a large streaming video dataset with annotations.", "true": [], "pred": [["large streaming video dataset:material", "feature of", "model:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "113": {"text": "The linguistic structure consists of segments of the discourse into which the utterances naturally aggregate.", "true": [], "pred": [["segments of the discourse:other scientific term", "feature of", "linguistic structure:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "114": {"text": "Our experiments clearly indicate the potential of this dynamic representation for complete cursive handwriting recognition.", "true": [], "pred": [["dynamic representation:method", "feature of", "complete cursive handwriting recognition:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "117": {"text": "They improve the reconstruction results and enforce their consistency with a priori knowledge about object shape.", "true": [["object shape:other scientific term", "feature of", "priori knowledge:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "119": {"text": "An extension of our method to space-time interest point detection for action classification is also presented.", "true": [], "pred": [["extension:generic", "feature of", "method:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "121": {"text": "Objects are represented as a coherent ensemble of parts that are consistent under 3D viewpoint transformations.", "true": [], "pred": [["Objects:generic", "feature of", "coherent ensemble of parts:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "122": {"text": "Our approach is among the first to propose a generative proba-bilistic framework for 3D object categorization.", "true": [], "pred": [["generative probabilistic framework:method", "feature of", "approach:generic"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "124": {"text": "We use gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities.", "true": [["indirect lighting:other scientific term", "feature of", "robustness:metric"], ["scene discontinuities:other scientific term", "feature of", "robustness:metric"]], "pred": [["gray-level band-pass white noise patterns:material", "feature of", "scene discontinuities:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "125": {"text": "Computing power per area and power consumption is amongst the highest reported for a single chip.", "true": [], "pred": [["power consumption:metric", "feature of", "single chip:other scientific term"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "127": {"text": "The psycholinguistic literature provides evidence for syntactic priming, i.e., the tendency to repeat structures.", "true": [], "pred": [["structures:other scientific term", "feature of", "syntactic priming:other scientific term"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "128": {"text": "This enables us to generate a huge amount of training data in a fully automated manner.", "true": [], "pred": [["training data:material", "feature of", "fully automated manner:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"\n"}, "129": {"text": "The goal of this work is the enrichment of human-machine interactions in a natural language environment.", "true": [["natural language environment:other scientific term", "feature of", "human-machine interactions:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "130": {"text": "Chat-80 has been designed to be both efficient and easily adaptable to a variety of applications.", "true": [], "pred": [["efficient:generic", "feature of", "Chat-80:method"], ["easily adaptable:generic", "feature of", "Chat-80:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "131": {"text": "Our technique is based on an improved, dynamic-programming, stereo algorithm for efficient novel-view generation.", "true": [], "pred": [["stereo algorithm:method", "feature of", "technique:method"], ["efficient novel-view generation:task", "feature of", "technique:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"\n"}, "132": {"text": "This paper presents an automatic scheme for collecting statistics on cooccurrence patterns in a large corpus.", "true": [], "pred": [["large corpus:material", "feature of", "automatic scheme:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "133": {"text": "Memo-functions also facilitate a simple way to construct a very compact representation of the parse forest.", "true": [], "pred": [["compact representation:other scientific term", "feature of", "Memo-functions:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "135": {"text": "We propose a novel metric learning formulation called Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-.", "true": [], "pred": [["Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-:method", "feature of", "metric learning formulation:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "136": {"text": "We present a variant of TAGs, called synchronous TAGs, which characterize correspondences between languages.", "true": [], "pred": [["synchronous TAGs:method", "feature of", "variant of TAGs:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "139": {"text": "Similar results were previously obtained with MSG -LRB- Modulation-filtered Spec-troGram -RRB- auditory features -LSB- 2 -RSB-.", "true": [], "pred": [["MSG -LRB- Modulation-filtered Spec-troGram -RRB- auditory features:other scientific term", "feature of", "results:generic"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "140": {"text": "Almost all the special cases of and exceptions to phonological and morphological rules have been implemented.", "true": [], "pred": [["special cases:other scientific term", "feature of", "phonological and morphological rules:other scientific term"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "141": {"text": "Existing work in the area has mostly addressed scenes that consist of static or quasi-static structures.", "true": [], "pred": [["static or quasi-static structures:other scientific term", "feature of", "scenes:other scientific term"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "143": {"text": "This work proposes a new research direction to address the lack of structures in traditional n-gram models.", "true": [], "pred": [["lack of structures:other scientific term", "feature of", "traditional n-gram models:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "148": {"text": "The fact that Turkish is an agglutinating free word order language presents a challenge for language theories.", "true": [], "pred": [["agglutinating free word order language:other scientific term", "feature of", "Turkish:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n\nFinal Answer: (8) \"feature of\"\n"}, "149": {"text": "In this paper we discuss object detection when only a small number of training examples are given.", "true": [], "pred": [["object detection:task", "feature of", "this paper:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "151": {"text": "Subpixel accuracy is achieved by considering several zero-crossings defined by the difference between pairs of unstructured patterns.", "true": [], "pred": [["subpixel accuracy:metric", "feature of", "zero-crossings:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "152": {"text": "We analyzed eye gaze, head nods and attentional focus in the context of a direction-giving task.", "true": [], "pred": [["eye gaze:other scientific term", "feature of", "direction-giving task:task"], ["head nods:other scientific term", "feature of", "direction-giving task:task"], ["attentional focus:other scientific term", "feature of", "direction-giving task:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"feature of\"  \n(11) \"feature of\"  \n(12) \"feature of\"  \n"}, "155": {"text": "This distribution has numerous applications in computer Go, including serving as an efficient stand-alone Go player.", "true": [], "pred": [["efficient stand-alone Go player:method", "feature of", "computer Go:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "162": {"text": "There are four language pairs currently supported by GLOSSER: English-Bulgarian, English-Estonian, English-Hungarian and French-Dutch.", "true": [], "pred": [["four language pairs:generic", "feature of", "GLOSSER:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "163": {"text": "The program is operational on UNIX and Windows '95 platforms, and has undergone a pilot user-study.", "true": [], "pred": [["program:generic", "feature of", "UNIX:material"], ["program:generic", "feature of", "Windows '95:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "164": {"text": "In practice, the current deep embedding methods use the Euclidean distance for the training and test.", "true": [], "pred": [["Euclidean distance:other scientific term", "feature of", "deep embedding methods:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "165": {"text": "Our proposed approach builds on recent advances in spectral clustering, image matting, and boundary detection.", "true": [], "pred": [["spectral clustering:method", "feature of", "proposed approach:method"], ["spectral clustering:method", "feature of", "recent advances:generic"], ["image matting:method", "feature of", "recent advances:generic"], ["boundary detection:method", "feature of", "recent advances:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"feature of\"  \n(15) \"feature of\"  \n(16) \"feature of\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "166": {"text": "Indeed, automatic evaluations need high-quality data that allow the comparison of both automatic and human translations.", "true": [], "pred": [["high-quality data:material", "feature of", "automatic evaluations:task"], ["human translations:other scientific term", "feature of", "high-quality data:material"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "168": {"text": "In this paper, we propose a new method for the modeling and subtraction of such scenes.", "true": [], "pred": [["modeling and subtraction of such scenes:task", "feature of", "method:generic"]], "response": "(1) \"feature of\"  \n(2) \"none\"\n"}, "169": {"text": "Fast algorithms for nearest neighbor -LRB- NN -RRB- search have in large part focused on 2 distance.", "true": [], "pred": [["Fast algorithms:method", "feature of", "nearest neighbor -LRB- NN -RRB- search:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "173": {"text": "In particular, we make extensive use of Pustejovsky's principles concerning the predicative information associated with nominals.", "true": [["nominals:other scientific term", "feature of", "predicative information:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "175": {"text": "This has the advantages of efficiency on grammatical input, and robustness in the face of ungrammatical input.", "true": [["ungrammatical input:other scientific term", "feature of", "robustness:metric"]], "pred": [["efficiency:metric", "feature of", "grammatical input:other scientific term"], ["robustness:metric", "feature of", "grammatical input:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "176": {"text": "The objects can be complex in that they may be composed of multiple layers with different refractive indices.", "true": [["refractive indices:other scientific term", "feature of", "multiple layers:other scientific term"]], "pred": [["multiple layers:other scientific term", "feature of", "objects:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "179": {"text": "Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions.", "true": [], "pred": [["MBR decoding:method", "feature of", "statistical MT performance:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "182": {"text": "We extract a set of heuristic principles from a corpus-based sample and formulate them as probabilistic Horn clauses.", "true": [["probabilistic Horn clauses:other scientific term", "feature of", "heuristic principles:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "188": {"text": "The attentional state is an abstraction of the focus of attention of the participants as the discourse unfolds.", "true": [], "pred": [["focus of attention:other scientific term", "feature of", "attentional state:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "189": {"text": "We provide a unified account of sentence-level and text-level anaphora within the framework of a dependency-based grammar model.", "true": [], "pred": [["unified account:method", "feature of", "dependency-based grammar model:method"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "190": {"text": "In this paper, we discuss language model adaptation methods given a word list and a raw corpus.", "true": [], "pred": [["language model adaptation methods:method", "feature of", "this paper:generic"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "191": {"text": "Many practical modeling problems involve discrete data that are best represented as draws from multinomial or categorical distributions.", "true": [], "pred": [["multinomial or categorical distributions:other scientific term", "feature of", "discrete data:material"], ["multinomial or categorical distributions:other scientific term", "feature of", "modeling problems:task"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"\n"}, "195": {"text": "We further propose a parameter training algorithm for the present model based on a decision tree-based context clustering.", "true": [], "pred": [["parameter training algorithm:method", "feature of", "present model:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "203": {"text": "We evaluate the demands that task dialogues collected using this technique, place upon a prototype Natural Language system.", "true": [], "pred": [["this technique:method", "feature of", "task dialogues:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "204": {"text": "A language learning experiment showed that assessors can differentiate native from non-native language essays in less than 100 words.", "true": [], "pred": [["non-native language essays:material", "feature of", "language learning experiment:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "206": {"text": "This work presents an automated technique for detecting reflections in image sequences by analyzing motion trajectories of feature points.", "true": [["feature points:other scientific term", "feature of", "motion trajectories:other scientific term"]], "pred": [["reflections:other scientific term", "feature of", "automated technique:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "207": {"text": "As a Monte Carlo approach, ASA stochastically samples the parameter space, in contrast to local deterministic search.", "true": [], "pred": [["ASA:method", "feature of", "Monte Carlo approach:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "208": {"text": "Using this approach, we extract parallel data from large Chinese, Arabic, and English non-parallel newspaper corpora.", "true": [], "pred": [["parallel data:material", "feature of", "approach:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "209": {"text": "This paper presents a phrase-based statistical machine translation method, based on non-contiguous phrases, i.e. phrases with gaps.", "true": [], "pred": [["phrases with gaps:other scientific term", "feature of", "phrase-based statistical machine translation method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "210": {"text": "Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data.", "true": [], "pred": [["experimental results:material", "feature of", "proposed method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "211": {"text": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels.", "true": [["ambiguities:other scientific term", "feature of", "computation of features:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "213": {"text": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships.", "true": [["affine-invariant image patches:other scientific term", "feature of", "three-dimensional objects:other scientific term"], ["spatial relationships:other scientific term", "feature of", "affine-invariant image patches:other scientific term"]], "pred": [["three-dimensional objects:other scientific term", "feature of", "novel representation:method"], ["affine-invariant image patches:other scientific term", "feature of", "three-dimensional objects:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "215": {"text": "Our approach is based on the iterative deformation of a 3--D surface mesh to minimize an objective function.", "true": [], "pred": [["iterative deformation:method", "feature of", "approach:generic"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "216": {"text": "The model is evaluated on English and Czech newspaper texts, and is then validated on French broadcast news transcriptions.", "true": [], "pred": [["English and Czech newspaper texts:material", "feature of", "model:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "220": {"text": "Based on these results, we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state.", "true": [], "pred": [["verbal and nonverbal grounding acts:method", "feature of", "ECA:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "223": {"text": "Topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic.", "true": [["relevance:metric", "feature of", "blog posts:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "228": {"text": "Experiments using the SemCor and Senseval-3 data sets demonstrate that our ensembles yield significantly better results when compared with state-of-the-art.", "true": [], "pred": [["ensembles:method", "feature of", "significantly better results:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "230": {"text": "The task of machine translation -LRB- MT -RRB- evaluation is closely related to the task of sentence-level semantic equivalence classification.", "true": [], "pred": [["sentence-level semantic equivalence classification:task", "feature of", "machine translation -LRB- MT -RRB-:task"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "231": {"text": "Our technique gives a substantial improvement in paraphrase classification accuracy over all of the other models used in the experiments.", "true": [], "pred": [["technique:method", "feature of", "accuracy:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "232": {"text": "In this paper We experimentally evaluate a trainable sentence planner for a spoken dialogue system by eliciting subjective human judgments.", "true": [], "pred": [["trainable sentence planner:method", "feature of", "spoken dialogue system:method"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "233": {"text": "Thus, our method can be applied with great benefit to language pairs for which only scarce resources are available.", "true": [], "pred": [["language pairs:other scientific term", "feature of", "method:generic"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "234": {"text": "We report experiments conducted on a multilingual corpus to estimate the number of analogies among the sentences that it contains.", "true": [], "pred": [["multilingual corpus:material", "feature of", "experiments:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "238": {"text": "Thus the ASR system is designed to deal with what we refer to as Word Spotting and Noise Spotting capabilities.", "true": [], "pred": [["ASR system:method", "feature of", "Word Spotting:task"], ["ASR system:method", "feature of", "Noise Spotting:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "239": {"text": "Unfortunately, creating large datasets with pixel-level labels has been extremely costly due to the amount of human effort required.", "true": [["pixel-level labels:other scientific term", "feature of", "large datasets:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "240": {"text": "Turkish is an agglutinative language with word structures formed by productive affixations of derivational and inflectional suffixes to root words.", "true": [["word structures:other scientific term", "feature of", "agglutinative language:material"]], "pred": [["word structures:other scientific term", "feature of", "agglutinative language:other scientific term"], ["productive affixations:other scientific term", "feature of", "agglutinative language:other scientific term"], ["productive affixations:other scientific term", "feature of", "word structures:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"feature of\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "242": {"text": "When the scene exhibits a persistent dynamic behavior in time, such an assumption is violated and detection performance deteriorates.", "true": [["persistent dynamic behavior:other scientific term", "feature of", "scene:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "246": {"text": "We propose a novel probabilistic framework for learning visual models of 3D object categories by combining appearance information and geometric constraints.", "true": [], "pred": [["visual models of 3D object categories:method", "feature of", "probabilistic framework:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "248": {"text": "In the case of natural speech signals, the method is shown to have separation accuracy better than the state-of-the-art methods.", "true": [], "pred": [["separation accuracy:metric", "feature of", "method:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "249": {"text": "It also shows that our method significantly outperforms the previous two dependency tree kernels on the 5 ACE relation major types.", "true": [], "pred": [["dependency tree kernels:method", "feature of", "method:generic"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "253": {"text": "This paper presents a critical discussion of the various approaches that have been used in the evaluation of Natural Language systems.", "true": [], "pred": [["evaluation of Natural Language systems:task", "feature of", "critical discussion:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "257": {"text": "Our numerical hybrid local and global mode-seeking tracker is validated on challenging airborne videos with heavy occlusion and large camera motions.", "true": [["heavy occlusion:other scientific term", "feature of", "airborne videos:material"], ["camera motions:other scientific term", "feature of", "airborne videos:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "258": {"text": "Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams.", "true": [], "pred": [["spatial and temporal artefacts:other scientific term", "feature of", "new algorithm:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "260": {"text": "In this paper we explore a new theory of discourse structure that stresses the role of purpose and processing in discourse.", "true": [], "pred": [["theory of discourse structure:other scientific term", "feature of", "this paper:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"feature of\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "261": {"text": "The intentional structure captures the discourse-relevant purposes, expressed in each of the linguistic segments as well as relationships among them.", "true": [], "pred": [["discourse-relevant purposes:other scientific term", "feature of", "intentional structure:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "264": {"text": "Therefore, the study presented in this paper may be useful in inspiring new designs of deep models for person re-identification.", "true": [], "pred": [["deep models:method", "feature of", "study:generic"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n"}, "266": {"text": "Rather than trying to find or define a single\" best\" segmentation, we generate multiple segmentations of an image.", "true": [], "pred": [["multiple segmentations:task", "feature of", "image:material"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "268": {"text": "Full digital resolution is maintained even with low-resolution analog-to-digital conversion, owing to random statistics in the analog summation of binary products.", "true": [], "pred": [["full digital resolution:metric", "feature of", "low-resolution analog-to-digital conversion:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "272": {"text": "This paper describes a novel system for acquiring adjectival subcategorization frames -LRB- scfs -RRB- and associated frequency information from English corpus data.", "true": [], "pred": [["adjectival subcategorization frames -LRB- scfs -RRB-:other scientific term", "feature of", "novel system:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "273": {"text": "Our study reveals that the proposed method not only reduces an extensive system development effort but also improves the transliteration accuracy significantly.", "true": [], "pred": [["transliteration accuracy:metric", "feature of", "proposed method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "274": {"text": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output.", "true": [], "pred": [["conversational telephone speech:material", "feature of", "two corpora:material"], ["broadcast news speech:material", "feature of", "two corpora:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "277": {"text": "Finally, a novel feature weighting and selection function is presented, which yields superior feature vectors and better word similarity performance.", "true": [], "pred": [["word similarity performance:metric", "feature of", "feature weighting and selection function:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "278": {"text": "With the aid of a logic-based grammar formalism called extraposition grammars, Chat-80 translates English questions into the Prolog subset of logic.", "true": [], "pred": [["extraposition grammars:method", "feature of", "logic-based grammar formalism:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "280": {"text": "Our results show that MT evaluation techniques are able to produce useful features for paraphrase classification and to a lesser extent entailment.", "true": [], "pred": [["useful features:other scientific term", "feature of", "MT evaluation techniques:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "282": {"text": "We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system.", "true": [], "pred": [["state-of-the-art statistical machine translation system:method", "feature of", "extracted data:material"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "283": {"text": "The theory of attention, intention, and aggregation of utterances is illustrated in the paper with a number of example discourses.", "true": [], "pred": [["example discourses:material", "feature of", "paper:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n"}, "288": {"text": "This piece of work has also laid a foundation for exploring and harvesting English-Chinese bitexts in a larger volume from the Web.", "true": [], "pred": [["foundation:generic", "feature of", "piece of work:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "289": {"text": "In this paper, we explore geometric structures of 3D lines in ray space for improving light field triangulation and stereo matching.", "true": [["ray space:other scientific term", "feature of", "geometric structures of 3D lines:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "293": {"text": "Towards the modeling of the dynamic characteristics, optical flow is computed and utilized as a feature in a higher dimensional space.", "true": [["higher dimensional space:other scientific term", "feature of", "feature:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "296": {"text": "This paper presents necessary and sufficient conditions for the use of demonstrative expressions in English and discusses implications for current discourse processing algorithms.", "true": [["demonstrative expressions:other scientific term", "feature of", "English:material"]], "pred": [["necessary and sufficient conditions:other scientific term", "feature of", "demonstrative expressions in English:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "297": {"text": "We present a scanning method that recovers dense sub-pixel camera-projector correspondence without requiring any photometric calibration nor preliminary knowledge of their relative geometry.", "true": [], "pred": [["dense sub-pixel camera-projector correspondence:other scientific term", "feature of", "scanning method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "298": {"text": "We discuss several applications of the result to the problem of distributional approximation of probabilistic context-free grammars by means of probabilistic finite automata.", "true": [["distributional approximation:task", "feature of", "probabilistic context-free grammars:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "300": {"text": "Given a particular concept, or word sense, a topic signature is a set of words that tend to co-occur with it.", "true": [], "pred": [["topic signature:other scientific term", "feature of", "particular concept:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "301": {"text": "An important area of learning in autonomous agents is the ability to learn domain-speciic models of actions to be used by planning systems.", "true": [], "pred": [["domain-specific models of actions:method", "feature of", "autonomous agents:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "304": {"text": "In this paper, we describe a search procedure for statistical machine translation -LRB- MT -RRB- based on dynamic programming -LRB- DP -RRB-.", "true": [], "pred": [["search procedure:method", "feature of", "statistical machine translation -LRB- MT -RRB-:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "305": {"text": "The experimental tests are carried out on the Verbmobil task -LRB- German-English, 8000-word vocabulary -RRB-, which is a limited-domain spoken-language task.", "true": [], "pred": [["experimental tests:task", "feature of", "limited-domain spoken-language task:task"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "306": {"text": "Various properties of discourse are described, and explanations for the behaviour of cue phrases, referring expressions, and interruptions are explored.", "true": [], "pred": [["cue phrases:other scientific term", "feature of", "properties of discourse:other scientific term"], ["referring expressions:other scientific term", "feature of", "properties of discourse:other scientific term"], ["interruptions:other scientific term", "feature of", "properties of discourse:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"feature of\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "307": {"text": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks.", "true": [["weighted sum:other scientific term", "feature of", "precision:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "309": {"text": "MINPRAN, a new robust operator, nds good ts in data sets where more than 50% of the points are outliers.", "true": [], "pred": [["robust operator:other scientific term", "feature of", "MINPRAN:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "311": {"text": "In addition, we improve the learning by a metric weight constraint, so that the learned metric has a better generalization ability.", "true": [["generalization ability:other scientific term", "feature of", "learned metric:other scientific term"]], "pred": [["learned metric:other scientific term", "feature of", "better generalization ability:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "312": {"text": "This poster paper describes a full scale two-level morphological description -LRB- Karttunen, 1983; Koskenniemi, 1983 -RRB- of Turkish word structures.", "true": [], "pred": [["full scale two-level morphological description:method", "feature of", "Turkish word structures:other scientific term"], ["full scale two-level morphological description:method", "feature of", "poster paper:generic"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "313": {"text": "Experiments on the PASCAL VOC 2006 dataset show an acceleration of more than 50% by our method compared to standard cascade evaluation.", "true": [], "pred": [["standard cascade evaluation:method", "feature of", "our method:method"], ["acceleration:metric", "feature of", "our method:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "314": {"text": "Here we develop an approach for 1 distance that begins with an explicit and exactly distance-preserving embedding of the points into 2 2.", "true": [], "pred": [["explicit and exactly distance-preserving embedding:method", "feature of", "approach:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "316": {"text": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices.", "true": [], "pred": [["anisotropic meshing:method", "feature of", "satisfactory reconstruction results:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "317": {"text": "This model is meant to account for productive rules of interpretation which are inferred from the morpho-syntactic and semantic characteristics of the nominal constituents.", "true": [["morpho-syntactic and semantic characteristics:other scientific term", "feature of", "nominal constituents:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "319": {"text": "The approach is validated with real image data, and with experimental results from a CID/DRAM analog array prototype in 0.5 cents m CMOS.", "true": [], "pred": [["experimental results:metric", "feature of", "approach:generic"], ["real image data:material", "feature of", "approach:generic"], ["CID/DRAM analog array prototype:material", "feature of", "approach:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"feature of\"  \n(11) \"feature of\"  \n(12) \"feature of\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "321": {"text": "In this paper, we present our work on the detection of question-answer pairs in an email conversation for the task of email summarization.", "true": [], "pred": [["question-answer pairs:other scientific term", "feature of", "our work:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "329": {"text": "The attentional state, being dynamic, records the objects, properties, and relations that are salient at each point of the discourse.", "true": [], "pred": [["attentional state:other scientific term", "feature of", "discourse:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "333": {"text": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB-.", "true": [], "pred": [["phase locking:other scientific term", "feature of", "OA:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "336": {"text": "This paper deals with the problem of generating the fundamental frequency -LRB- F0 -RRB- contour of speech from a text input for text-to-speech synthesis.", "true": [], "pred": [["text-to-speech synthesis:method", "feature of", "fundamental frequency -LRB- F0 -RRB- contour:other scientific term"], ["speech:material", "feature of", "text-to-speech synthesis:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "337": {"text": "The strong description and modeling properties of differential features make them useful tools that can be efficiently used as constraints for 3--D reconstruction.", "true": [], "pred": [["constraints:other scientific term", "feature of", "differential features:other scientific term"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "338": {"text": "This paper presents an unsupervised learning approach to disambiguate various relations between named entities by use of various lexical and syntactic features from the contexts.", "true": [], "pred": [["lexical and syntactic features:other scientific term", "feature of", "unsupervised learning approach:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "339": {"text": "Finally, we show how the estimation of the tensors from point correspondences is achieved through factorization, and discuss the estimation from line correspondences.", "true": [], "pred": [["factorization:method", "feature of", "estimation of the tensors:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "340": {"text": "As far as we can do in the rule-based approach is to give a default rule to pick up a corresponding classifier of each noun.", "true": [], "pred": [["default rule:method", "feature of", "rule-based approach:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "346": {"text": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing.", "true": [["lexical similarity:other scientific term", "feature of", "discourse segments:other scientific term"]], "pred": [["features:other scientific term", "feature of", "structure of email-threads:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "347": {"text": "SVMs are known to be robust to overfitting; however, a few training examples usually do not represent well the structure of the class.", "true": [], "pred": [["overfitting:other scientific term", "feature of", "SVMs:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "348": {"text": "Sentence boundary detection in speech is important for enriching speech recognition output, making it easier for humans to read and downstream modules to process.", "true": [], "pred": [["speech:material", "feature of", "speech recognition output:other scientific term"], ["sentence boundary detection:task", "feature of", "speech recognition output:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"feature of\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"feature of\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "350": {"text": "We use novel priors, generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion.", "true": [], "pred": [["sparse and dense detection maps:other scientific term", "feature of", "novel priors:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "351": {"text": "These models simulate the reading time advantage for parallel structures found in human data, and also yield a small increase in overall parsing accuracy.", "true": [], "pred": [["reading time advantage:other scientific term", "feature of", "models:method"], ["overall parsing accuracy:metric", "feature of", "models:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"feature of\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "352": {"text": "This paper describes FERRET, an interactive question-answering -LRB- Q/A -RRB- system designed to address the challenges of integrating automatic Q/A applications into real-world environments.", "true": [], "pred": [["interactive question-answering -LRB- Q/A -RRB-:method", "feature of", "FERRET:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "353": {"text": "In this paper, we introduce an annotation scheme for scientific articles which can be used to build such a resource in a consistent way.", "true": [], "pred": [["annotation scheme:method", "feature of", "resource:generic"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "354": {"text": "These mistakes can lead to various kinds of misunderstandings between speaker and listener, including reference failures or failure to understand the speaker's intention.", "true": [], "pred": [["reference failures:other scientific term", "feature of", "misunderstandings:other scientific term"], ["failure to understand the speaker's intention:task", "feature of", "misunderstandings:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"feature of\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "358": {"text": "Metagrammatical formalisms that combine context-free phrase structure rules and metarules -LRB- MPS grammars -RRB- allow concise statement of generalizations about the syntax of natural languages.", "true": [], "pred": [["context-free phrase structure rules:other scientific term", "feature of", "Metagrammatical formalisms:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "360": {"text": "We also found that OA is crucial for auditory processing by onset neurons -LRB- ONs -RRB- in the next neuronal stage, the auditory brainstem.", "true": [], "pred": [["OA:other scientific term", "feature of", "auditory processing:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"feature of\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "363": {"text": "We introduce a method to accelerate the evaluation of object detection cascades with the help of a divide-and-conquer procedure in the space of candidate regions.", "true": [["space of candidate regions:method", "feature of", "divide-and-conquer procedure:method"]], "pred": [["object detection cascades:method", "feature of", "method:generic"], ["divide-and-conquer procedure:method", "feature of", "method:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "364": {"text": "Information distillation aims to extract relevant pieces of information related to a given query from massive, possibly multilingual, audio and textual document sources.", "true": [], "pred": [["relevant pieces of information:other scientific term", "feature of", "information distillation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"feature of\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "366": {"text": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns, and exhibit strong invariance to rotation, illumination variation, and blur.", "true": [], "pred": [["large-scale structures:other scientific term", "feature of", "detectors:method"], ["distinctive textured patterns:other scientific term", "feature of", "detectors:method"], ["strong invariance:other scientific term", "feature of", "detectors:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"feature of\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "367": {"text": "This paper proposes a generic mathematical formalism for the combination of various structures: strings, trees, dags, graphs, and products of them.", "true": [], "pred": [["various structures:other scientific term", "feature of", "generic mathematical formalism:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "368": {"text": "We consider the problem of computing the Kullback-Leibler distance, also called the relative entropy, between a probabilistic context-free grammar and a probabilistic finite automaton.", "true": [], "pred": [["relative entropy:other scientific term", "feature of", "Kullback-Leibler distance:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "369": {"text": "The subjects were given three minutes per extract to determine whether they believed the sample output to be an expert human translation or a machine translation.", "true": [], "pred": [["sample output:other scientific term", "feature of", "extract:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "370": {"text": "We evaluated the topic signatures on a WSD task, where we trained a second-order vector cooccurrence algorithm on standard WSD datasets, with promising results.", "true": [], "pred": [["standard WSD datasets:material", "feature of", "WSD task:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "371": {"text": "Joint matrix triangularization is often used for estimating the joint eigenstructure of a set M of matrices, with applications in signal processing and machine learning.", "true": [], "pred": [["joint matrix triangularization:method", "feature of", "set M of matrices:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "374": {"text": "By employing a joint classification and regression optimization objective, this network is capable of automatically localizing the start and end points of actions more accurately.", "true": [], "pred": [["joint classification and regression optimization objective:method", "feature of", "network:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "377": {"text": "Building on previous work at Carnegie-Mellon University e.g. -LSB- 4, 5, 8 -RSB-, Plume's approach to parsing is based on semantic caseframe instantiation.", "true": [], "pred": [["semantic caseframe instantiation:method", "feature of", "Plume's approach to parsing:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "381": {"text": "A separation method is proposed that is nearly statistically efficient -LRB- approaching the corresponding Cram\u00e9r-Rao lower bound -RRB-, if the separated signals obey the assumed model.", "true": [["Cram\u00e9r-Rao lower bound -RRB-:other scientific term", "feature of", "separation method:method"]], "pred": [["separated signals:other scientific term", "feature of", "separation method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "382": {"text": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision, and that it can handle many challenges of active reconstruction systems.", "true": [["subpixel precision:metric", "feature of", "scene geometry:other scientific term"]], "pred": [["scene geometry:other scientific term", "feature of", "our method:method"], ["high subpixel precision:metric", "feature of", "our method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"feature of\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "387": {"text": "In this work, we study how Convolutional Neural Networks -LRB- CNN -RRB- architectures can be adapted to the task of simultaneous object recognition and pose estimation.", "true": [], "pred": [["task of simultaneous object recognition and pose estimation:task", "feature of", "Convolutional Neural Networks -LRB- CNN -RRB-:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"\n"}, "388": {"text": "Based on our analysis, we further develop a novel line-assisted graph-cut -LRB- LAGC -RRB- algorithm that effectively encodes 3D line constraints into light field stereo matching.", "true": [], "pred": [["3D line constraints:other scientific term", "feature of", "line-assisted graph-cut -LRB- LAGC -RRB-:method"], ["line-assisted graph-cut -LRB- LAGC -RRB-:method", "feature of", "light field stereo matching:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "395": {"text": "In this paper, a novel framework for machine transliteration/backtransliteration that allows us to carry out direct orthographical mapping -LRB- DOM -RRB- between two different languages is presented.", "true": [], "pred": [["direct orthographical mapping -LRB- DOM -RRB-:method", "feature of", "novel framework:method"], ["novel framework:method", "feature of", "machine transliteration/backtransliteration:task"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "396": {"text": "Under this framework, a joint source-channel transliteration model, also called n-gram transliteration model -LRB- n-gram TM -RRB-, is further proposed to model the transliteration process.", "true": [], "pred": [["joint source-channel transliteration model:method", "feature of", "framework:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "399": {"text": "Our preliminary experiments on building a paraphrase corpus have so far been producing promising results, which we have evaluated according to cost-efficiency, exhaustiveness, and reliability.", "true": [], "pred": [["promising results:metric", "feature of", "preliminary experiments:task"], ["paraphrase corpus:material", "feature of", "preliminary experiments:task"]], "response": "(1) \"feature of\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "401": {"text": "Experiments on the TREC Blog track test set show that both groups of credibility indicators significantly improve retrieval effectiveness; the best performance is achieved when combining them.", "true": [], "pred": [["TREC Blog track test set:material", "feature of", "Experiments:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "402": {"text": "Topic signatures can be useful in a number of Natural Language Processing -LRB- NLP -RRB- applications, such as Word Sense Disambiguation -LRB- WSD -RRB- and Text Summarisation.", "true": [], "pred": [["topic signatures:other scientific term", "feature of", "Natural Language Processing -LRB- NLP -RRB-:method"], ["Natural Language Processing -LRB- NLP -RRB-:method", "feature of", "Text Summarisation:task"], ["Text Summarisation:task", "feature of", "Natural Language Processing -LRB- NLP -RRB-:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "404": {"text": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge.", "true": [], "pred": [["mixtures of feature distributions:method", "feature of", "method:generic"], ["mixtures of feature distributions:method", "feature of", "shape constrained image segmentation:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"feature of\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "405": {"text": "Extended CF grammars -LRB- grammars with regular expressions at the right hand side -RRB- can be parsed with a simple modification of the LR-parser for normal CF grammars.", "true": [["regular expressions:other scientific term", "feature of", "grammars:method"]], "pred": [["Extended CF grammars:method", "feature of", "grammars with regular expressions:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "406": {"text": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features.", "true": [], "pred": [["training and prediction costs:other scientific term", "feature of", "Kernel space embedding:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "408": {"text": "In this paper, we propose a novel moderate positive sample mining method to train robust CNN for person re-identification, dealing with the problem of large variation.", "true": [], "pred": [["moderate positive sample mining method:method", "feature of", "person re-identification:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "410": {"text": "Morphemes added to a root word or a stem can convert the word from a nominal to a verbal structure or vice-versa, or can create adverbial constructs.", "true": [], "pred": [["root word:other scientific term", "feature of", "morphemes:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "411": {"text": "Furthermore, we show how the recently developed efficient subwindow search -LRB- ESS -RRB- procedure -LSB- 11 -RSB- can be integrated into the last stage of our method.", "true": [], "pred": [["last stage:generic", "feature of", "our method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"\n"}, "412": {"text": "We show how this can efficiently be combined with random-projection based methods for 2 NN search, such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees.", "true": [], "pred": [["locality-sensitive hashing -LRB- LSH -RRB-:method", "feature of", "random-projection based methods:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"\n"}, "416": {"text": "Our system incorporates a linguistic parser/generator for LFG, a transfer component for parse reduction operating on packed parse forests, and a maximum-entropy model for stochastic output selection.", "true": [], "pred": [["linguistic parser/generator for LFG:method", "feature of", "system:generic"], ["transfer component for parse reduction:method", "feature of", "system:generic"], ["maximum-entropy model:method", "feature of", "system:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"feature of\"  \n(11) \"feature of\"  \n(12) \"feature of\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "419": {"text": "The system incorporates a decision-tree classifier for 30 scf types which tests for the presence of grammatical relations -LRB- grs -RRB- in the output of a robust statistical parser.", "true": [], "pred": [["decision-tree classifier:method", "feature of", "system:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "420": {"text": "A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition.", "true": [], "pred": [["tool:method", "feature of", "linguistic annotation:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "421": {"text": "This model mimics the way in which images are processed in the visual pathway, rendering a feasible alternative for the implementation of early vision applications in standard technologies.", "true": [], "pred": [["model:method", "feature of", "visual pathway:other scientific term"], ["images:material", "feature of", "model:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"feature of\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "423": {"text": "To overcome this problem, we propose a new, flexible, and scalable way for generating training data that only requires a set of stereo images as input.", "true": [], "pred": [["and scalable way:method", "feature of", "training data:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "425": {"text": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU, NIST, WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment.", "true": [], "pred": [["standard MT evaluation methods:method", "feature of", "classifiers:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"feature of\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "426": {"text": "We also introduce a novel classification method based on PER which leverages part of speech information of the words contributing to the word matches and non-matches in the sentence.", "true": [], "pred": [["PER:other scientific term", "feature of", "classification method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "428": {"text": "For example, nucleotides in a DNA sequence, children's names in a given state and year, and text documents are all commonly modeled with multinomial distributions.", "true": [], "pred": [["nucleotides in a DNA sequence:material", "feature of", "multinomial distributions:other scientific term"], ["text documents:material", "feature of", "multinomial distributions:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "431": {"text": "While Plume is well adapted to simple declarative and imperative utterances, it handles passives, relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage.", "true": [], "pred": [["simple declarative and imperative utterances:other scientific term", "feature of", "Plume:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "435": {"text": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage, sum-of-pairs, k-means, and k-median.", "true": [], "pred": [["single-linkage:method", "feature of", "clustering techniques:method"], ["sum-of-pairs:method", "feature of", "clustering techniques:method"], ["k-means:method", "feature of", "clustering techniques:method"], ["k-median:method", "feature of", "clustering techniques:method"], ["clustering techniques:method", "feature of", "trade-offs:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"feature of\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"feature of\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"feature of\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "436": {"text": "The results of the experiment show that in most of the cases the cooccurrence statistics indeed reflect the semantic constraints and thus provide a basis for a useful disambiguation tool.", "true": [], "pred": [["cooccurrence statistics:other scientific term", "feature of", "semantic constraints:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "443": {"text": "It works by calculating eigenvectors of an adjacency graph's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors.", "true": [["adjacency graph's Laplacian:other scientific term", "feature of", "eigenvectors:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "445": {"text": "In particular, our guarantee suggests that a substantial amount of low rank matrices, which cannot be recovered by standard robust PCA, become re-coverable by our proposed method.", "true": [], "pred": [["low rank matrices:other scientific term", "feature of", "our proposed method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "446": {"text": "In the study of expressive speech communication, it is commonly accepted that the emotion perceived by the listener is a good approximation of the intended emotion conveyed by the speaker.", "true": [], "pred": [["emotion:other scientific term", "feature of", "expressive speech communication:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "447": {"text": "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel.", "true": [["syntactic structure features:other scientific term", "feature of", "parse tree:other scientific term"]], "pred": [["syntactic structure features:other scientific term", "feature of", "parse tree:other scientific term"], ["convolution tree kernel:method", "feature of", "relation extraction:task"], ["syntactic structure features:other scientific term", "feature of", "relation extraction:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"feature of\"  \n(12) \"none\"\n"}, "448": {"text": "In previous work, we have developed hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers that integrate textual and prosodic knowledge sources for detecting sentence boundaries.", "true": [], "pred": [["hidden Markov model -LRB- HMM -RRB-:method", "feature of", "classifiers:method"], ["maximum entropy -LRB- Maxent -RRB-:method", "feature of", "classifiers:method"], ["hidden Markov model -LRB- HMM -RRB-:method", "feature of", "detecting sentence boundaries:task"], ["maximum entropy -LRB- Maxent -RRB-:method", "feature of", "detecting sentence boundaries:task"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"feature of\"  \n(14) \"feature of\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "450": {"text": "Although hidden Markov models -LRB- HMMs -RRB- provide a suitable generative model for field structured text, general unsupervised HMM learning fails to learn useful structure in either of our domains.", "true": [], "pred": [["hidden Markov models -LRB- HMMs -RRB-:method", "feature of", "field structured text:other scientific term"], ["generative model:other scientific term", "feature of", "hidden Markov models -LRB- HMMs -RRB-:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"feature of\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "451": {"text": "We also show that a good-quality MT system can be built from scratch by starting with a very small parallel corpus -LRB- 100,000 words -RRB- and exploiting a large non-parallel corpus.", "true": [], "pred": [["large non-parallel corpus:material", "feature of", "good-quality MT system:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"\n"}, "453": {"text": "The resultant bilingual corpus, 10.4 M English words and 18.3 M Chinese characters, is an authoritative and comprehensive text collection covering the specific and special domain of HK laws.", "true": [], "pred": [["authoritative and comprehensive text collection:other scientific term", "feature of", "bilingual corpus:material"], ["specific and special domain of HK laws:other scientific term", "feature of", "bilingual corpus:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "454": {"text": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours.", "true": [["remarkable feature:other scientific term", "feature of", "model:generic"]], "pred": [["efficient algorithm:method", "feature of", "model:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "455": {"text": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation, the proposed method requires fewer evaluations of the classifier functions, thereby speeding up the search.", "true": [], "pred": [["proposed method:method", "feature of", "search:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"feature of\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "456": {"text": "In addition, we conduct synthetic experiments as well as a real application on noisy image classification to show that our method also improves the performance in practice by exploiting side information.", "true": [], "pred": [["our method:method", "feature of", "side information:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "457": {"text": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB-, based on studies on the vertebrate retina, has permitted the realization of complex programmable spatio-temporal dynamics in VLSI.", "true": [["complex programmable spatio-temporal dynamics:other scientific term", "feature of", "VLSI:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "459": {"text": "We investigate the verbal and nonverbal means for grounding, and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction.", "true": [], "pred": [["verbal and nonverbal means:other scientific term", "feature of", "design for embodied conversational agents:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "465": {"text": "Owing to these variations, the pedestrian data is distributed as highly-curved manifolds in the feature space, despite the current convolutional neural networks -LRB- CNN -RRB-'s capability of feature extraction.", "true": [["feature space:other scientific term", "feature of", "highly-curved manifolds:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "467": {"text": "Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB-.", "true": [], "pred": [["morphological analysis:other scientific term", "feature of", "Japanese text processing:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"feature of\"  \n(12) \"none\"  \n"}, "469": {"text": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination, pose and head motion variation.", "true": [["illumination:other scientific term", "feature of", "video sequences:material"], ["pose:other scientific term", "feature of", "video sequences:material"], ["head motion variation:other scientific term", "feature of", "video sequences:material"]], "pred": [["fully automatic recognition system:method", "feature of", "proposed method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "470": {"text": "We are developing a prototype where, in the simplest sharing scenario, naive users interact directly with the text in their language -LRB- L0 -RRB-, and indirectly with the associated graph.", "true": [], "pred": [["associated graph:other scientific term", "feature of", "prototype:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"feature of\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "473": {"text": "On the other hand, the manifold learning methods suggest to use the Euclidean distance in the local range, combining with the graphical relationship between samples, for approximating the geodesic distance.", "true": [["local range:other scientific term", "feature of", "Euclidean distance:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "481": {"text": "The system is trained on 181,000 expert games and shows excellent prediction performance as indicated by its ability to perfectly predict the moves made by professional Go players in 34% of test positions.", "true": [], "pred": [["prediction performance:metric", "feature of", "system:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "483": {"text": "In this model, on-line handwriting is considered as a modulation of a simple cycloidal pen motion, described by two coupled oscillations with a constant linear drift along the line of the writing.", "true": [], "pred": [["on-line handwriting:other scientific term", "feature of", "model:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "484": {"text": "Using these ideas together, the resulting tagger gives a 97.24% accuracy on the Penn Treebank WSJ, an error reduction of 4.4% on the best previous single automatically learned tagging result.", "true": [], "pred": [["best previous single automatically learned tagging result:other scientific term", "feature of", "tagger:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "485": {"text": "In this paper, we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2, higher than previously reported results on the NEGRA corpus.", "true": [], "pred": [["unlexicalized parser:method", "feature of", "German:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"feature of\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "488": {"text": "Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm.", "true": [], "pred": [["DP-based solution:method", "feature of", "traveling salesman problem:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"feature of\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "491": {"text": "From this point of view, selecting suitable positive -LRB- i.e. intra-class -RRB- training samples within a local range is critical for training the CNN embedding, especially when the data has large intra-class variations.", "true": [["intra-class variations:other scientific term", "feature of", "data:generic"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "492": {"text": "We propose to incorporate a priori geometric constraints in a 3--D stereo reconstruction scheme to cope with the many cases where image information alone is not sufficient to accurately recover 3--D shape.", "true": [], "pred": [["a priori geometric constraints:other scientific term", "feature of", "3--D stereo reconstruction scheme:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "494": {"text": "We propose a corpus-based method -LRB- Biber,1993; Nagao,1993; Smadja,1993 -RRB- which generates Noun Classifier Associations -LRB- NCA -RRB- to overcome the problems in classifier assignment and semantic construction of noun phrase.", "true": [], "pred": [["Noun Classifier Associations -LRB- NCA -RRB-:other scientific term", "feature of", "corpus-based method:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n"}, "496": {"text": "The purpose of this research is to test the efficacy of applying automated evaluation techniques, originally devised for the evaluation of human language learners, to the output of machine translation -LRB- MT -RRB- systems.", "true": [], "pred": [["automated evaluation techniques:method", "feature of", "research:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"feature of\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "497": {"text": "The results show that the features in terms of which we formulate our heuristic principles have significant predictive power, and that rules that closely resemble our Horn clauses can be learnt automatically from these features.", "true": [["features:other scientific term", "feature of", "heuristic principles:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "499": {"text": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently.", "true": [["matrix rank degeneration:other scientific term", "feature of", "low-rank matrix optimization:task"], ["non-isolated minima:other scientific term", "feature of", "low-rank matrix optimization:task"], ["or-thonormality:other scientific term", "feature of", "learned matrix:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "500": {"text": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech, out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present.", "true": [], "pred": [["spontaneous speech:other scientific term", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"], ["out-of-vocabulary -LRB- OOV -RRB- words:other scientific term", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"], ["acoustic noises:other scientific term", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"], ["real applications:generic", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"], ["Utterance Verification -LRB- UV -RRB-:task", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"feature of\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"feature of\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"feature of\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "501": {"text": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications, where the goal is to decompose the data matrix to a low rank part plus a sparse residual.", "true": [], "pred": [["robust principal component analysis -LRB- robust PCA -RRB-:other scientific term", "feature of", "machine learning applications:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"feature of\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "504": {"text": "During normal tracking conditions when the object is visible from frame to frame, local optimization is used to track the local mode of the similarity measure in a parameter space of translation, rotation and scale.", "true": [], "pred": [["normal tracking conditions:other scientific term", "feature of", "local optimization:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "506": {"text": "In this paper we present a new UV procedure with two major features: a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises.", "true": [], "pred": [["Confidence tests:method", "feature of", "UV procedure:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "508": {"text": "Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples, and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples.", "true": [], "pred": [["detector:other scientific term", "feature of", "training examples:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "512": {"text": "Towards deep analysis of compositional classes of paraphrases, we have examined a class-oriented framework for collecting paraphrase examples, in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement.", "true": [], "pred": [["automatic candidate generation:method", "feature of", "class-oriented framework:method"], ["class-oriented framework:method", "feature of", "paraphrase examples:material"], ["class-oriented framework:method", "feature of", "sentential paraphrases:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"feature of\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"feature of\"  \n(14) \"feature of\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "514": {"text": "Given the video streams acquired by two cameras placed on either side of a computer monitor, the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact.", "true": [["arbitrary position:other scientific term", "feature of", "virtual camera:other scientific term"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "515": {"text": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations.", "true": [], "pred": [["layers:other scientific term", "feature of", "CNN models:method"], ["distributed representations:other scientific term", "feature of", "CNN models:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"feature of\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "516": {"text": "Experimental results from a real telephone application on a natural number recognition task show an 50% reduction in recognition errors with a moderate 12% rejection rate of correct utterances and a low 1.5% rate of false acceptance.", "true": [["natural number recognition task:task", "feature of", "telephone application:task"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "518": {"text": "Discourse processing requires recognizing how the utterances of the discourse aggregate into segments, recognizing the intentions expressed in the discourse and the relationships among intentions, and tracking the discourse through the operation of the mechanisms associated with attentional state.", "true": [], "pred": [["segments:other scientific term", "feature of", "utterances:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"feature of\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "524": {"text": "Specifically, by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork, the proposed model automatically captures the complex long-range temporal dynamics, which naturally avoids the typical sliding window design and thus ensures high computational efficiency.", "true": [["long-range temporal dynamics:other scientific term", "feature of", "model:generic"]], "pred": [["complex long-range temporal dynamics:other scientific term", "feature of", "proposed model:method"], ["proposed model:method", "feature of", "high computational efficiency:metric"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"feature of\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n"}, "527": {"text": "Although the study of clustering is centered around an intuitively compelling goal, it has been very difficult to develop a unified framework for reasoning about it at a technical level, and profoundly diverse approaches to clustering abound in the research community.", "true": [], "pred": [["unified framework:method", "feature of", "clustering:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"feature of\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "528": {"text": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset, and run two different machine learning algorithms: SLIPPER, a rule-based learning algorithm, and TiMBL, a memory-based system.", "true": [], "pred": [["SLIPPER:method", "feature of", "machine learning algorithms:method"], ["rule-based learning algorithm:method", "feature of", "machine learning algorithms:method"], ["TiMBL:method", "feature of", "machine learning algorithms:method"], ["memory-based system:method", "feature of", "machine learning algorithms:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"feature of\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"feature of\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"feature of\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"feature of\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}, "531": {"text": "To recover from these inevitable tracking failures, we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB-, a method that avoids becoming trapped at local modes and is much faster than exhaustive search.", "true": [], "pred": [["Adaptive Simulated Annealing -LRB- ASA -RRB-:method", "feature of", "object detection:task"], ["Adaptive Simulated Annealing -LRB- ASA -RRB-:method", "feature of", "global optimization problem:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"feature of\"  \n(16) \"feature of\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "533": {"text": "In the Object Recognition task, there exists a di-chotomy between the categorization of objects and estimating object pose, where the former necessitates a view-invariant representation, while the latter requires a representation capable of capturing pose information over different categories of objects.", "true": [], "pred": [["categorization of objects:task", "feature of", "Object Recognition task:task"], ["estimating object pose:task", "feature of", "Object Recognition task:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"feature of\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "536": {"text": "In general, our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech, although it is interesting to note that the best results are achieved by three-way voting among the classifiers.", "true": [["speech:material", "feature of", "NIST sentence boundary detection task:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "537": {"text": "The objective of this work is to recognize faces using video sequences both for training and recognition input, in a realistic, unconstrained setup in which lighting, pose and user motion pattern have a wide variability and face images are of low resolution.", "true": [["resolution:metric", "feature of", "face images:material"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n(73) \"none\"  \n(74) \"none\"  \n(75) \"none\"  \n(76) \"none\"  \n(77) \"none\"  \n(78) \"none\"  \n(79) \"none\"  \n(80) \"none\"  \n(81) \"none\"  \n(82) \"none\"  \n(83) \"none\"  \n(84) \"none\"  \n(85) \"none\"  \n(86) \"none\"  \n(87) \"none\"  \n(88) \"none\"  \n(89) \"none\"  \n(90) \"none\"  \n(91) \"none\"  \n(92) \"none\"  \n(93) \"none\"  \n(94) \"none\"  \n(95) \"none\"  \n(96) \"none\"  \n(97) \"none\"  \n(98) \"none\"  \n(99) \"none\"  \n(100) \"none\"  \n(101) \"none\"  \n(102) \"none\"  \n(103) \"none\"  \n(104) \"none\"  \n(105) \"none\"  \n(106) \"none\"  \n(107) \"none\"  \n(108) \"none\"  \n(109) \"none\"  \n(110) \"none\"  \n(111) \"none\"  \n(112) \"none\"  \n(113) \"none\"  \n(114) \"none\"  \n(115) \"none\"  \n(116) \"none\"  \n(117) \"none\"  \n(118) \"none\"  \n(119) \"none\"  \n(120) \"none\"  \n(121) \"none\"  \n(122) \"none\"  \n(123) \"none\"  \n(124) \"none\"  \n(125) \"none\"  \n(126) \"none\"  \n(127) \"none\"  \n(128) \"none\"  \n(129) \"none\"  \n(130) \"none\"  \n(131) \"none\"  \n(132) \"none\"  \n(133) \"none\"  \n(134) \"none\"  \n(135) \"none\"  \n(136) \"none\"  \n(137) \"none\"  \n(138) \"none\"  \n(139) \"none\"  \n(140) \"none\"  \n(141) \"none\"  \n(142) \"none\"  \n(143) \"none\"  \n(144) \"none\"  \n(145) \"none\"  \n(146) \"none\"  \n(147\n"}, "540": {"text": "Among other experiments, we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data.", "true": [], "pred": [["learned confidence measures:method", "feature of", "performance:metric"], ["performance:metric", "feature of", "experiments:generic"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"feature of\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "541": {"text": "Here, we leverage a logistic stick-breaking representation and recent innovations in P\u00f3lya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods, enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead.", "true": [["jointly Gaussian likelihoods:other scientific term", "feature of", "latent variables:other scientific term"], ["minimal overhead:other scientific term", "feature of", "Gaussian models:method"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "543": {"text": "The formalism's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language, or to their translates in another natural language; in summary, we intend it to allow TAGs to be used beyond their role in syntax proper.", "true": [], "pred": [["formalism:other scientific term", "feature of", "TAGs:method"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "546": {"text": "In this theory, discourse structure is composed of three separate but interrelated components: the structure of the sequence of utterances -LRB- called the linguistic structure -RRB-, a structure of purposes -LRB- called the intentional structure -RRB-, and the state of focus of attention -LRB- called the attentional state -RRB-.", "true": [], "pred": [["three separate but interrelated components:other scientific term", "feature of", "discourse structure:other scientific term"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "547": {"text": "While sentence extraction as an approach to summarization has been shown to work in documents of certain genres, because of the conversational nature of email communication where utterances are made in relation to one made previously, sentence extraction may not capture the necessary segments of dialogue that would make a summary coherent.", "true": [], "pred": [["sentence extraction:method", "feature of", "summarization:task"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"feature of\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n"}, "548": {"text": "Our method has two major components: a -RRB- a pattern extraction scheme for efficiently harvesting patterns of given size and shape from expert game records and b -RRB- a Bayesian learning algorithm -LRB- in two variants -RRB- that learns a distribution over the values of a move given a board position based on the local pattern context.", "true": [], "pred": [["pattern extraction scheme:method", "feature of", "method:generic"], ["pattern extraction scheme:method", "feature of", "expert game records:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"feature of\"  \n(10) \"none\"  \n(11) \"feature of\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n"}, "549": {"text": "We present a new part-of-speech tagger that demonstrates the following ideas: -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation, -LRB- ii -RRB- broad use of lexical features, including jointly conditioning on multiple consecutive words, -LRB- iii -RRB- effective use of priors in conditional loglinear models, and -LRB- iv -RRB- fine-grained modeling of unknown word features.", "true": [], "pred": [["dependency network representation:method", "feature of", "part-of-speech tagger:method"], ["lexical features:other scientific term", "feature of", "part-of-speech tagger:method"], ["priors in conditional loglinear models:other scientific term", "feature of", "part-of-speech tagger:method"], ["unknown word features:other scientific term", "feature of", "part-of-speech tagger:method"]], "response": "(1) \"none\"  \n(2) \"feature of\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"feature of\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"feature of\"  \n(16) \"none\"  \n(17) \"feature of\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n"}, "550": {"text": "In particular there are three areas of novelty: -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation, learnt offline, to generalize in the presence of extreme illumination changes; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses; and -LRB- iii -RRB- we introduce an accurate video sequence\" reillumination\" algorithm to achieve robustness to face motion patterns in video.", "true": [["smoothness:other scientific term", "feature of", "geodesically local appearance manifold structure:other scientific term"], ["face motion patterns:other scientific term", "feature of", "robustness:metric"]], "pred": [], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"none\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n(21) \"none\"  \n(22) \"none\"  \n(23) \"none\"  \n(24) \"none\"  \n(25) \"none\"  \n(26) \"none\"  \n(27) \"none\"  \n(28) \"none\"  \n(29) \"none\"  \n(30) \"none\"  \n(31) \"none\"  \n(32) \"none\"  \n(33) \"none\"  \n(34) \"none\"  \n(35) \"none\"  \n(36) \"none\"  \n(37) \"none\"  \n(38) \"none\"  \n(39) \"none\"  \n(40) \"none\"  \n(41) \"none\"  \n(42) \"none\"  \n(43) \"none\"  \n(44) \"none\"  \n(45) \"none\"  \n(46) \"none\"  \n(47) \"none\"  \n(48) \"none\"  \n(49) \"none\"  \n(50) \"none\"  \n(51) \"none\"  \n(52) \"none\"  \n(53) \"none\"  \n(54) \"none\"  \n(55) \"none\"  \n(56) \"none\"  \n(57) \"none\"  \n(58) \"none\"  \n(59) \"none\"  \n(60) \"none\"  \n(61) \"none\"  \n(62) \"none\"  \n(63) \"none\"  \n(64) \"none\"  \n(65) \"none\"  \n(66) \"none\"  \n(67) \"none\"  \n(68) \"none\"  \n(69) \"none\"  \n(70) \"none\"  \n(71) \"none\"  \n(72) \"none\"  \n"}}, "missing_cases": {"3": [["Language resource quality:metric", "feature of", "NLP:task"]], "5": [["ambiguity:other scientific term", "feature of", "determiners:method"]], "87": [["linguistic expressiveness:other scientific term", "feature of", "formalisms:generic"]], "97": [["English:material", "feature of", "nominal compounds:other scientific term"]], "104": [["global optimality:other scientific term", "feature of", "Branch and bound strategies:method"]], "117": [["object shape:other scientific term", "feature of", "priori knowledge:other scientific term"]], "124": [["indirect lighting:other scientific term", "feature of", "robustness:metric"], ["scene discontinuities:other scientific term", "feature of", "robustness:metric"]], "129": [["natural language environment:other scientific term", "feature of", "human-machine interactions:task"]], "173": [["nominals:other scientific term", "feature of", "predicative information:other scientific term"]], "175": [["ungrammatical input:other scientific term", "feature of", "robustness:metric"]], "176": [["refractive indices:other scientific term", "feature of", "multiple layers:other scientific term"]], "182": [["probabilistic Horn clauses:other scientific term", "feature of", "heuristic principles:method"]], "206": [["feature points:other scientific term", "feature of", "motion trajectories:other scientific term"]], "211": [["ambiguities:other scientific term", "feature of", "computation of features:task"]], "213": [["spatial relationships:other scientific term", "feature of", "affine-invariant image patches:other scientific term"]], "223": [["relevance:metric", "feature of", "blog posts:material"]], "239": [["pixel-level labels:other scientific term", "feature of", "large datasets:material"]], "240": [["word structures:other scientific term", "feature of", "agglutinative language:material"]], "242": [["persistent dynamic behavior:other scientific term", "feature of", "scene:generic"]], "257": [["camera motions:other scientific term", "feature of", "airborne videos:material"], ["heavy occlusion:other scientific term", "feature of", "airborne videos:material"]], "289": [["ray space:other scientific term", "feature of", "geometric structures of 3D lines:task"]], "293": [["higher dimensional space:other scientific term", "feature of", "feature:other scientific term"]], "296": [["demonstrative expressions:other scientific term", "feature of", "English:material"]], "298": [["distributional approximation:task", "feature of", "probabilistic context-free grammars:method"]], "307": [["weighted sum:other scientific term", "feature of", "precision:metric"]], "311": [["generalization ability:other scientific term", "feature of", "learned metric:other scientific term"]], "317": [["morpho-syntactic and semantic characteristics:other scientific term", "feature of", "nominal constituents:other scientific term"]], "346": [["lexical similarity:other scientific term", "feature of", "discourse segments:other scientific term"]], "363": [["space of candidate regions:method", "feature of", "divide-and-conquer procedure:method"]], "381": [["Cram\u00e9r-Rao lower bound -RRB-:other scientific term", "feature of", "separation method:method"]], "382": [["subpixel precision:metric", "feature of", "scene geometry:other scientific term"]], "405": [["regular expressions:other scientific term", "feature of", "grammars:method"]], "443": [["adjacency graph's Laplacian:other scientific term", "feature of", "eigenvectors:other scientific term"]], "454": [["remarkable feature:other scientific term", "feature of", "model:generic"]], "457": [["complex programmable spatio-temporal dynamics:other scientific term", "feature of", "VLSI:task"]], "465": [["feature space:other scientific term", "feature of", "highly-curved manifolds:method"]], "469": [["head motion variation:other scientific term", "feature of", "video sequences:material"], ["illumination:other scientific term", "feature of", "video sequences:material"], ["pose:other scientific term", "feature of", "video sequences:material"]], "473": [["local range:other scientific term", "feature of", "Euclidean distance:other scientific term"]], "491": [["intra-class variations:other scientific term", "feature of", "data:generic"]], "497": [["features:other scientific term", "feature of", "heuristic principles:method"]], "499": [["matrix rank degeneration:other scientific term", "feature of", "low-rank matrix optimization:task"], ["non-isolated minima:other scientific term", "feature of", "low-rank matrix optimization:task"], ["or-thonormality:other scientific term", "feature of", "learned matrix:other scientific term"]], "514": [["arbitrary position:other scientific term", "feature of", "virtual camera:other scientific term"]], "516": [["natural number recognition task:task", "feature of", "telephone application:task"]], "524": [["long-range temporal dynamics:other scientific term", "feature of", "model:generic"]], "536": [["speech:material", "feature of", "NIST sentence boundary detection task:material"]], "537": [["resolution:metric", "feature of", "face images:material"]], "541": [["jointly Gaussian likelihoods:other scientific term", "feature of", "latent variables:other scientific term"], ["minimal overhead:other scientific term", "feature of", "Gaussian models:method"]], "550": [["face motion patterns:other scientific term", "feature of", "robustness:metric"], ["smoothness:other scientific term", "feature of", "geodesically local appearance manifold structure:other scientific term"]]}, "false_cases": {"1": [["miscommunication:other scientific term", "feature of", "misunderstandings:other scientific term"]], "3": [["Language resource quality:other scientific term", "feature of", "NLP:other scientific term"]], "5": [["ambiguity:other scientific term", "feature of", "determiners:other scientific term"]], "7": [["results:generic", "feature of", "our method:method"]], "9": [["complex morphotactics:other scientific term", "feature of", "Turkish:material"]], "10": [["Plume:material", "feature of", "restricted domain parser:method"]], "11": [["collection of salient image features:other scientific term", "feature of", "part:generic"]], "12": [["validity:other scientific term", "feature of", "questions:generic"]], "13": [["affine projection:method", "feature of", "reconstruction:task"]], "20": [["extensional reference:other scientific term", "feature of", "paper:generic"], ["new view:other scientific term", "feature of", "paper:generic"]], "21": [["system performance:metric", "feature of", "Combination methods:method"]], "22": [["state-of-the-art trackers:method", "feature of", "approach:method"]], "23": [["freely translating virtual camera:other scientific term", "feature of", "synthesis:task"]], "27": [["Background modeling:method", "feature of", "vision systems:other scientific term"]], "29": [["automatically acquiring English topic signatures:task", "feature of", "novel approach:method"]], "36": [["validation:task", "feature of", "resources:material"]], "37": [["evaluation:task", "feature of", "different-quality references:other scientific term"]], "39": [["histogram information:other scientific term", "feature of", "method:generic"]], "45": [["layers:other scientific term", "feature of", "Reflections in image sequences:other scientific term"]], "48": [["higher one:generic", "feature of", "estimates:metric"], ["lower one:generic", "feature of", "estimates:metric"]], "49": [["MINPRAN:method", "feature of", "complex range and intensity data:material"]], "50": [["piecewise-linear interpolant:other scientific term", "feature of", "light field super-resolution:task"]], "53": [["Amorph:method", "feature of", "NE items:other scientific term"], ["dictionary lookup:method", "feature of", "Amorph:method"]], "54": [["sparse selectional preferences:other scientific term", "feature of", "posterior:other scientific term"]], "55": [["application:task", "feature of", "this approach:generic"], ["this approach:generic", "feature of", "LCS-Marine:method"]], "56": [["practical feasibility:other scientific term", "feature of", "our algorithm:method"]], "57": [["Machine transliteration/back-transliteration:method", "feature of", "multilingual speech and language applications:task"]], "58": [["Design challenges:other scientific term", "feature of", "this paper:generic"], ["experimental results:other scientific term", "feature of", "this paper:generic"]], "61": [["machine learning approach:method", "feature of", "bare slice disambiguation:task"]], "64": [["weak detectors:method", "feature of", "strong detector:method"]], "66": [["incremental probabilistic parser:method", "feature of", "method:generic"]], "67": [["seven categories:other scientific term", "feature of", "scheme:generic"]], "68": [["algorithm:method", "feature of", "novel view generation:task"]], "70": [["motor control representation:method", "feature of", "matching of cursive scripts:task"]], "72": [["new paradigm:other scientific term", "feature of", "Listen-Communicate-Show -LRB- LCS -RRB-:method"]], "74": [["piecewise stationary:other scientific term", "feature of", "signals:other scientific term"]], "75": [["event elements:other scientific term", "feature of", "events:other scientific term"], ["event terms:other scientific term", "feature of", "events:other scientific term"]], "77": [["classifiers' performances:metric", "feature of", "information about meeting context:other scientific term"]], "81": [["ooce domains:other scientific term", "feature of", "integrated learning system:method"]], "83": [["programming language:other scientific term", "feature of", "Prolog:material"]], "85": [["parallel sentences:other scientific term", "feature of", "method:generic"]], "86": [["framework:method", "feature of", "theory:other scientific term"]], "90": [["kernel trick:method", "feature of", "efficient non-linear extension of WARCA:method"]], "91": [["model-based approach:method", "feature of", "on-line cursive handwriting analysis:task"]], "93": [["densely sampled rays:other scientific term", "feature of", "image-based representations:other scientific term"], ["image-based representations:other scientific term", "feature of", "Light fields:other scientific term"]], "94": [["GLOSSER:method", "feature of", "reading:task"], ["foreign language:other scientific term", "feature of", "GLOSSER:method"]], "99": [["model:method", "feature of", "blind separation of natural speech signals:task"]], "100": [["proposed methods:method", "feature of", "transliteration/backtransliteration experiments:task"]], "101": [["0.5 \u00b5m standard CMOS process:material", "feature of", "prototype chip:method"]], "105": [["retrieval process:method", "feature of", "topical blog post retrieval:task"]], "108": [["learned confidence measures:other scientific term", "feature of", "stereo vision:other scientific term"]], "109": [["intuitive:metric", "feature of", "scheme:other scientific term"], ["reproducible:metric", "feature of", "scheme:other scientific term"], ["stable:metric", "feature of", "scheme:other scientific term"]], "110": [["large streaming video dataset:material", "feature of", "model:method"]], "113": [["segments of the discourse:other scientific term", "feature of", "linguistic structure:other scientific term"]], "114": [["dynamic representation:method", "feature of", "complete cursive handwriting recognition:task"]], "119": [["extension:generic", "feature of", "method:generic"]], "121": [["Objects:generic", "feature of", "coherent ensemble of parts:other scientific term"]], "122": [["generative probabilistic framework:method", "feature of", "approach:generic"]], "124": [["gray-level band-pass white noise patterns:material", "feature of", "scene discontinuities:other scientific term"]], "125": [["power consumption:metric", "feature of", "single chip:other scientific term"]], "127": [["structures:other scientific term", "feature of", "syntactic priming:other scientific term"]], "128": [["training data:material", "feature of", "fully automated manner:other scientific term"]], "130": [["easily adaptable:generic", "feature of", "Chat-80:method"], ["efficient:generic", "feature of", "Chat-80:method"]], "131": [["efficient novel-view generation:task", "feature of", "technique:method"], ["stereo algorithm:method", "feature of", "technique:method"]], "132": [["large corpus:material", "feature of", "automatic scheme:method"]], "133": [["compact representation:other scientific term", "feature of", "Memo-functions:method"]], "135": [["Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-:method", "feature of", "metric learning formulation:method"]], "136": [["synchronous TAGs:method", "feature of", "variant of TAGs:method"]], "139": [["MSG -LRB- Modulation-filtered Spec-troGram -RRB- auditory features:other scientific term", "feature of", "results:generic"]], "140": [["special cases:other scientific term", "feature of", "phonological and morphological rules:other scientific term"]], "141": [["static or quasi-static structures:other scientific term", "feature of", "scenes:other scientific term"]], "143": [["lack of structures:other scientific term", "feature of", "traditional n-gram models:method"]], "148": [["agglutinating free word order language:other scientific term", "feature of", "Turkish:material"]], "149": [["object detection:task", "feature of", "this paper:generic"]], "151": [["subpixel accuracy:metric", "feature of", "zero-crossings:other scientific term"]], "152": [["attentional focus:other scientific term", "feature of", "direction-giving task:task"], ["eye gaze:other scientific term", "feature of", "direction-giving task:task"], ["head nods:other scientific term", "feature of", "direction-giving task:task"]], "155": [["efficient stand-alone Go player:method", "feature of", "computer Go:task"]], "162": [["four language pairs:generic", "feature of", "GLOSSER:method"]], "163": [["program:generic", "feature of", "UNIX:material"], ["program:generic", "feature of", "Windows '95:material"]], "164": [["Euclidean distance:other scientific term", "feature of", "deep embedding methods:method"]], "165": [["boundary detection:method", "feature of", "recent advances:generic"], ["image matting:method", "feature of", "recent advances:generic"], ["spectral clustering:method", "feature of", "proposed approach:method"], ["spectral clustering:method", "feature of", "recent advances:generic"]], "166": [["high-quality data:material", "feature of", "automatic evaluations:task"], ["human translations:other scientific term", "feature of", "high-quality data:material"]], "168": [["modeling and subtraction of such scenes:task", "feature of", "method:generic"]], "169": [["Fast algorithms:method", "feature of", "nearest neighbor -LRB- NN -RRB- search:task"]], "175": [["efficiency:metric", "feature of", "grammatical input:other scientific term"], ["robustness:metric", "feature of", "grammatical input:other scientific term"]], "176": [["multiple layers:other scientific term", "feature of", "objects:other scientific term"]], "179": [["MBR decoding:method", "feature of", "statistical MT performance:metric"]], "188": [["focus of attention:other scientific term", "feature of", "attentional state:other scientific term"]], "189": [["unified account:method", "feature of", "dependency-based grammar model:method"]], "190": [["language model adaptation methods:method", "feature of", "this paper:generic"]], "191": [["multinomial or categorical distributions:other scientific term", "feature of", "discrete data:material"], ["multinomial or categorical distributions:other scientific term", "feature of", "modeling problems:task"]], "195": [["parameter training algorithm:method", "feature of", "present model:other scientific term"]], "203": [["this technique:method", "feature of", "task dialogues:material"]], "204": [["non-native language essays:material", "feature of", "language learning experiment:task"]], "206": [["reflections:other scientific term", "feature of", "automated technique:method"]], "207": [["ASA:method", "feature of", "Monte Carlo approach:method"]], "208": [["parallel data:material", "feature of", "approach:generic"]], "209": [["phrases with gaps:other scientific term", "feature of", "phrase-based statistical machine translation method:method"]], "210": [["experimental results:material", "feature of", "proposed method:method"]], "213": [["three-dimensional objects:other scientific term", "feature of", "novel representation:method"]], "215": [["iterative deformation:method", "feature of", "approach:generic"]], "216": [["English and Czech newspaper texts:material", "feature of", "model:method"]], "220": [["verbal and nonverbal grounding acts:method", "feature of", "ECA:method"]], "228": [["ensembles:method", "feature of", "significantly better results:metric"]], "230": [["sentence-level semantic equivalence classification:task", "feature of", "machine translation -LRB- MT -RRB-:task"]], "231": [["technique:method", "feature of", "accuracy:metric"]], "232": [["trainable sentence planner:method", "feature of", "spoken dialogue system:method"]], "233": [["language pairs:other scientific term", "feature of", "method:generic"]], "234": [["multilingual corpus:material", "feature of", "experiments:task"]], "238": [["ASR system:method", "feature of", "Noise Spotting:task"], ["ASR system:method", "feature of", "Word Spotting:task"]], "240": [["productive affixations:other scientific term", "feature of", "agglutinative language:other scientific term"], ["productive affixations:other scientific term", "feature of", "word structures:other scientific term"], ["word structures:other scientific term", "feature of", "agglutinative language:other scientific term"]], "246": [["visual models of 3D object categories:method", "feature of", "probabilistic framework:method"]], "248": [["separation accuracy:metric", "feature of", "method:generic"]], "249": [["dependency tree kernels:method", "feature of", "method:generic"]], "253": [["evaluation of Natural Language systems:task", "feature of", "critical discussion:task"]], "258": [["spatial and temporal artefacts:other scientific term", "feature of", "new algorithm:method"]], "260": [["theory of discourse structure:other scientific term", "feature of", "this paper:generic"]], "261": [["discourse-relevant purposes:other scientific term", "feature of", "intentional structure:other scientific term"]], "264": [["deep models:method", "feature of", "study:generic"]], "266": [["multiple segmentations:task", "feature of", "image:material"]], "268": [["full digital resolution:metric", "feature of", "low-resolution analog-to-digital conversion:other scientific term"]], "272": [["adjectival subcategorization frames -LRB- scfs -RRB-:other scientific term", "feature of", "novel system:method"]], "273": [["transliteration accuracy:metric", "feature of", "proposed method:method"]], "274": [["broadcast news speech:material", "feature of", "two corpora:material"], ["conversational telephone speech:material", "feature of", "two corpora:material"]], "277": [["word similarity performance:metric", "feature of", "feature weighting and selection function:method"]], "278": [["extraposition grammars:method", "feature of", "logic-based grammar formalism:method"]], "280": [["useful features:other scientific term", "feature of", "MT evaluation techniques:method"]], "282": [["state-of-the-art statistical machine translation system:method", "feature of", "extracted data:material"]], "283": [["example discourses:material", "feature of", "paper:generic"]], "288": [["foundation:generic", "feature of", "piece of work:generic"]], "296": [["necessary and sufficient conditions:other scientific term", "feature of", "demonstrative expressions in English:other scientific term"]], "297": [["dense sub-pixel camera-projector correspondence:other scientific term", "feature of", "scanning method:method"]], "300": [["topic signature:other scientific term", "feature of", "particular concept:other scientific term"]], "301": [["domain-specific models of actions:method", "feature of", "autonomous agents:other scientific term"]], "304": [["search procedure:method", "feature of", "statistical machine translation -LRB- MT -RRB-:other scientific term"]], "305": [["experimental tests:task", "feature of", "limited-domain spoken-language task:task"]], "306": [["cue phrases:other scientific term", "feature of", "properties of discourse:other scientific term"], ["interruptions:other scientific term", "feature of", "properties of discourse:other scientific term"], ["referring expressions:other scientific term", "feature of", "properties of discourse:other scientific term"]], "309": [["robust operator:other scientific term", "feature of", "MINPRAN:method"]], "311": [["learned metric:other scientific term", "feature of", "better generalization ability:other scientific term"]], "312": [["full scale two-level morphological description:method", "feature of", "Turkish word structures:other scientific term"], ["full scale two-level morphological description:method", "feature of", "poster paper:generic"]], "313": [["acceleration:metric", "feature of", "our method:method"], ["standard cascade evaluation:method", "feature of", "our method:method"]], "314": [["explicit and exactly distance-preserving embedding:method", "feature of", "approach:generic"]], "316": [["anisotropic meshing:method", "feature of", "satisfactory reconstruction results:metric"]], "319": [["CID/DRAM analog array prototype:material", "feature of", "approach:generic"], ["experimental results:metric", "feature of", "approach:generic"], ["real image data:material", "feature of", "approach:generic"]], "321": [["question-answer pairs:other scientific term", "feature of", "our work:generic"]], "329": [["attentional state:other scientific term", "feature of", "discourse:other scientific term"]], "333": [["phase locking:other scientific term", "feature of", "OA:method"]], "336": [["speech:material", "feature of", "text-to-speech synthesis:method"], ["text-to-speech synthesis:method", "feature of", "fundamental frequency -LRB- F0 -RRB- contour:other scientific term"]], "337": [["constraints:other scientific term", "feature of", "differential features:other scientific term"]], "338": [["lexical and syntactic features:other scientific term", "feature of", "unsupervised learning approach:method"]], "339": [["factorization:method", "feature of", "estimation of the tensors:task"]], "340": [["default rule:method", "feature of", "rule-based approach:method"]], "346": [["features:other scientific term", "feature of", "structure of email-threads:other scientific term"]], "347": [["overfitting:other scientific term", "feature of", "SVMs:other scientific term"]], "348": [["sentence boundary detection:task", "feature of", "speech recognition output:other scientific term"], ["speech:material", "feature of", "speech recognition output:other scientific term"]], "350": [["sparse and dense detection maps:other scientific term", "feature of", "novel priors:method"]], "351": [["overall parsing accuracy:metric", "feature of", "models:method"], ["reading time advantage:other scientific term", "feature of", "models:method"]], "352": [["interactive question-answering -LRB- Q/A -RRB-:method", "feature of", "FERRET:method"]], "353": [["annotation scheme:method", "feature of", "resource:generic"]], "354": [["failure to understand the speaker's intention:task", "feature of", "misunderstandings:other scientific term"], ["reference failures:other scientific term", "feature of", "misunderstandings:other scientific term"]], "358": [["context-free phrase structure rules:other scientific term", "feature of", "Metagrammatical formalisms:method"]], "360": [["OA:other scientific term", "feature of", "auditory processing:task"]], "363": [["divide-and-conquer procedure:method", "feature of", "method:generic"], ["object detection cascades:method", "feature of", "method:generic"]], "364": [["relevant pieces of information:other scientific term", "feature of", "information distillation:task"]], "366": [["distinctive textured patterns:other scientific term", "feature of", "detectors:method"], ["large-scale structures:other scientific term", "feature of", "detectors:method"], ["strong invariance:other scientific term", "feature of", "detectors:method"]], "367": [["various structures:other scientific term", "feature of", "generic mathematical formalism:method"]], "368": [["relative entropy:other scientific term", "feature of", "Kullback-Leibler distance:other scientific term"]], "369": [["sample output:other scientific term", "feature of", "extract:other scientific term"]], "370": [["standard WSD datasets:material", "feature of", "WSD task:task"]], "371": [["joint matrix triangularization:method", "feature of", "set M of matrices:material"]], "374": [["joint classification and regression optimization objective:method", "feature of", "network:method"]], "377": [["semantic caseframe instantiation:method", "feature of", "Plume's approach to parsing:method"]], "381": [["separated signals:other scientific term", "feature of", "separation method:method"]], "382": [["high subpixel precision:metric", "feature of", "our method:method"], ["scene geometry:other scientific term", "feature of", "our method:method"]], "387": [["task of simultaneous object recognition and pose estimation:task", "feature of", "Convolutional Neural Networks -LRB- CNN -RRB-:method"]], "388": [["3D line constraints:other scientific term", "feature of", "line-assisted graph-cut -LRB- LAGC -RRB-:method"], ["line-assisted graph-cut -LRB- LAGC -RRB-:method", "feature of", "light field stereo matching:task"]], "395": [["direct orthographical mapping -LRB- DOM -RRB-:method", "feature of", "novel framework:method"], ["novel framework:method", "feature of", "machine transliteration/backtransliteration:task"]], "396": [["joint source-channel transliteration model:method", "feature of", "framework:generic"]], "399": [["paraphrase corpus:material", "feature of", "preliminary experiments:task"], ["promising results:metric", "feature of", "preliminary experiments:task"]], "401": [["TREC Blog track test set:material", "feature of", "Experiments:task"]], "402": [["Natural Language Processing -LRB- NLP -RRB-:method", "feature of", "Text Summarisation:task"], ["Text Summarisation:task", "feature of", "Natural Language Processing -LRB- NLP -RRB-:method"], ["topic signatures:other scientific term", "feature of", "Natural Language Processing -LRB- NLP -RRB-:method"]], "404": [["mixtures of feature distributions:method", "feature of", "method:generic"], ["mixtures of feature distributions:method", "feature of", "shape constrained image segmentation:task"]], "405": [["Extended CF grammars:method", "feature of", "grammars with regular expressions:other scientific term"]], "406": [["training and prediction costs:other scientific term", "feature of", "Kernel space embedding:method"]], "408": [["moderate positive sample mining method:method", "feature of", "person re-identification:task"]], "410": [["root word:other scientific term", "feature of", "morphemes:other scientific term"]], "411": [["last stage:generic", "feature of", "our method:method"]], "412": [["locality-sensitive hashing -LRB- LSH -RRB-:method", "feature of", "random-projection based methods:method"]], "416": [["linguistic parser/generator for LFG:method", "feature of", "system:generic"], ["maximum-entropy model:method", "feature of", "system:generic"], ["transfer component for parse reduction:method", "feature of", "system:generic"]], "419": [["decision-tree classifier:method", "feature of", "system:generic"]], "420": [["tool:method", "feature of", "linguistic annotation:method"]], "421": [["images:material", "feature of", "model:method"], ["model:method", "feature of", "visual pathway:other scientific term"]], "423": [["and scalable way:method", "feature of", "training data:material"]], "425": [["standard MT evaluation methods:method", "feature of", "classifiers:method"]], "426": [["PER:other scientific term", "feature of", "classification method:method"]], "428": [["nucleotides in a DNA sequence:material", "feature of", "multinomial distributions:other scientific term"], ["text documents:material", "feature of", "multinomial distributions:other scientific term"]], "431": [["simple declarative and imperative utterances:other scientific term", "feature of", "Plume:method"]], "435": [["clustering techniques:method", "feature of", "trade-offs:other scientific term"], ["k-means:method", "feature of", "clustering techniques:method"], ["k-median:method", "feature of", "clustering techniques:method"], ["single-linkage:method", "feature of", "clustering techniques:method"], ["sum-of-pairs:method", "feature of", "clustering techniques:method"]], "436": [["cooccurrence statistics:other scientific term", "feature of", "semantic constraints:other scientific term"]], "445": [["low rank matrices:other scientific term", "feature of", "our proposed method:method"]], "446": [["emotion:other scientific term", "feature of", "expressive speech communication:other scientific term"]], "447": [["convolution tree kernel:method", "feature of", "relation extraction:task"], ["syntactic structure features:other scientific term", "feature of", "relation extraction:task"]], "448": [["hidden Markov model -LRB- HMM -RRB-:method", "feature of", "classifiers:method"], ["hidden Markov model -LRB- HMM -RRB-:method", "feature of", "detecting sentence boundaries:task"], ["maximum entropy -LRB- Maxent -RRB-:method", "feature of", "classifiers:method"], ["maximum entropy -LRB- Maxent -RRB-:method", "feature of", "detecting sentence boundaries:task"]], "450": [["generative model:other scientific term", "feature of", "hidden Markov models -LRB- HMMs -RRB-:method"], ["hidden Markov models -LRB- HMMs -RRB-:method", "feature of", "field structured text:other scientific term"]], "451": [["large non-parallel corpus:material", "feature of", "good-quality MT system:method"]], "453": [["authoritative and comprehensive text collection:other scientific term", "feature of", "bilingual corpus:material"], ["specific and special domain of HK laws:other scientific term", "feature of", "bilingual corpus:material"]], "454": [["efficient algorithm:method", "feature of", "model:method"]], "455": [["proposed method:method", "feature of", "search:task"]], "456": [["our method:method", "feature of", "side information:other scientific term"]], "459": [["verbal and nonverbal means:other scientific term", "feature of", "design for embodied conversational agents:method"]], "467": [["morphological analysis:other scientific term", "feature of", "Japanese text processing:task"]], "469": [["fully automatic recognition system:method", "feature of", "proposed method:method"]], "470": [["associated graph:other scientific term", "feature of", "prototype:method"]], "481": [["prediction performance:metric", "feature of", "system:generic"]], "483": [["on-line handwriting:other scientific term", "feature of", "model:method"]], "484": [["best previous single automatically learned tagging result:other scientific term", "feature of", "tagger:method"]], "485": [["unlexicalized parser:method", "feature of", "German:material"]], "488": [["DP-based solution:method", "feature of", "traveling salesman problem:task"]], "492": [["a priori geometric constraints:other scientific term", "feature of", "3--D stereo reconstruction scheme:method"]], "494": [["Noun Classifier Associations -LRB- NCA -RRB-:other scientific term", "feature of", "corpus-based method:method"]], "496": [["automated evaluation techniques:method", "feature of", "research:generic"]], "500": [["Utterance Verification -LRB- UV -RRB-:task", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"], ["acoustic noises:other scientific term", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"], ["out-of-vocabulary -LRB- OOV -RRB- words:other scientific term", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"], ["real applications:generic", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"], ["spontaneous speech:other scientific term", "feature of", "Automatic Speech Recognition -LRB- ASR -RRB- System:method"]], "501": [["robust principal component analysis -LRB- robust PCA -RRB-:other scientific term", "feature of", "machine learning applications:task"]], "504": [["normal tracking conditions:other scientific term", "feature of", "local optimization:method"]], "506": [["Confidence tests:method", "feature of", "UV procedure:method"]], "508": [["detector:other scientific term", "feature of", "training examples:other scientific term"]], "512": [["automatic candidate generation:method", "feature of", "class-oriented framework:method"], ["class-oriented framework:method", "feature of", "paraphrase examples:material"], ["class-oriented framework:method", "feature of", "sentential paraphrases:material"]], "515": [["distributed representations:other scientific term", "feature of", "CNN models:method"], ["layers:other scientific term", "feature of", "CNN models:method"]], "518": [["segments:other scientific term", "feature of", "utterances:other scientific term"]], "524": [["complex long-range temporal dynamics:other scientific term", "feature of", "proposed model:method"], ["proposed model:method", "feature of", "high computational efficiency:metric"]], "527": [["unified framework:method", "feature of", "clustering:task"]], "528": [["SLIPPER:method", "feature of", "machine learning algorithms:method"], ["TiMBL:method", "feature of", "machine learning algorithms:method"], ["memory-based system:method", "feature of", "machine learning algorithms:method"], ["rule-based learning algorithm:method", "feature of", "machine learning algorithms:method"]], "531": [["Adaptive Simulated Annealing -LRB- ASA -RRB-:method", "feature of", "global optimization problem:task"], ["Adaptive Simulated Annealing -LRB- ASA -RRB-:method", "feature of", "object detection:task"]], "533": [["categorization of objects:task", "feature of", "Object Recognition task:task"], ["estimating object pose:task", "feature of", "Object Recognition task:task"]], "540": [["learned confidence measures:method", "feature of", "performance:metric"], ["performance:metric", "feature of", "experiments:generic"]], "543": [["formalism:other scientific term", "feature of", "TAGs:method"]], "546": [["three separate but interrelated components:other scientific term", "feature of", "discourse structure:other scientific term"]], "547": [["sentence extraction:method", "feature of", "summarization:task"]], "548": [["pattern extraction scheme:method", "feature of", "expert game records:material"], ["pattern extraction scheme:method", "feature of", "method:generic"]], "549": [["dependency network representation:method", "feature of", "part-of-speech tagger:method"], ["lexical features:other scientific term", "feature of", "part-of-speech tagger:method"], ["priors in conditional loglinear models:other scientific term", "feature of", "part-of-speech tagger:method"], ["unknown word features:other scientific term", "feature of", "part-of-speech tagger:method"]]}, "error_cases": {"148": {"error": "list index out of range", "text": "The fact that Turkish is an agglutinating free word order language presents a challenge for language theories.", "true": [], "pred": [["agglutinating free word order language:other scientific term", "feature of", "Turkish:material"]], "response": "(1) \"none\"  \n(2) \"none\"  \n(3) \"none\"  \n(4) \"none\"  \n(5) \"none\"  \n(6) \"none\"  \n(7) \"none\"  \n(8) \"feature of\"  \n(9) \"none\"  \n(10) \"none\"  \n(11) \"none\"  \n(12) \"none\"  \n(13) \"none\"  \n(14) \"none\"  \n(15) \"none\"  \n(16) \"none\"  \n(17) \"none\"  \n(18) \"none\"  \n(19) \"none\"  \n(20) \"none\"  \n\nFinal Answer: (8) \"feature of\"\n"}}}